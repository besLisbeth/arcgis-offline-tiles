(function(){(this||window).webpackJsonp.registerAbsMids({"esri/views/3d/webgl-engine/lib/screenSizePerspectiveUtils":"+wMf","esri/views/3d/webgl-engine/lib/ModelContentType":"05NA","esri/views/3d/webgl-engine/shaders/PointRendererPrograms":"116h","esri/views/3d/layers/i3s/LEPCC":"1RVI","esri/views/3d/webgl-engine/lib/doublePrecisionUtils":"1f+t","esri/views/3d/webgl-engine/lib/ProgramRepository":"2A3h","esri/tasks/support/RelationshipQuery":"531e","esri/views/3d/layers/support/layerViewUpdatingProperties":"8Ntk","esri/views/3d/webgl-engine/lib/intersectorUtils":"9DjX","esri/core/requireUtils":"ADZV","esri/views/3d/webgl-engine/lib/GeometryRecord":"Cvn+","esri/core/libs/gl-matrix-2/quat":"EuvN","esri/views/3d/layers/i3s/LoDUtil":"F8B7","esri/views/3d/layers/i3s/PagedNodeIndex":"OA8v","esri/views/3d/layers/LayerView3D":"Ondo","esri/views/3d/support/orientedBoundingBox":"QyYG","esri/tasks/support/AttachmentQuery":"TsGx","esri/views/3d/webgl-engine/shaders/sources/shaderRepository":"VVgn","esri/views/3d/webgl-engine/lib/IdGen":"W0kZ","esri/views/3d/layers/i3s/I3SBinaryReader":"W2ph","esri/views/layers/LayerView":"WsO6","esri/views/3d/webgl-engine/lib/Object3D":"ZJC8","esri/core/libs/gl-matrix-2/quatf32":"fdzS","esri/geometry/support/normalizeUtils":"fw2w","esri/core/libs/gl-matrix-2/factories/quatf32":"gKSc","esri/views/3d/layers/i3s/PointRenderer":"kFFy","esri/views/3d/layers/i3s/I3SUtil":"ku25","esri/views/3d/layers/PointCloudLayerView3D":"lvSe","esri/views/3d/support/dito":"mCA8","esri/views/3d/layers/i3s/PointCloudRendererUtil":"qSbo","esri/views/webgl/renderState":"qbr3","esri/views/3d/webgl-engine/materials/internal/MaterialUtil":"s6rJ","esri/layers/support/PromiseQueue":"tZaU","esri/tasks/support/FeatureSet":"w1v0","esri/views/3d/layers/PointCloudWorker":"wCvz","esri/core/libs/gl-matrix-2/math/quat":"weYu","esri/views/3d/webgl-engine/lib/HighlightUtils":"xsp2","esri/views/3d/webgl-engine/shaders/sources/resolver":"zbgD"})})(),(window.webpackJsonp=window.webpackJsonp||[]).push([[53,91],{"+wMf":function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("wPX3"),t("AzkI")],void 0===(r=function(e,n,t,i){function r(e){return Math.abs(e*e*e)}function o(e,n,t,i){void 0===i&&(i=u);var o=t.parameters,a=t.paddingPixelsOverride;return i.scale=Math.min(o.divisor/(n-o.offset),1),i.factor=r(e),i.minPixelSize=o.minPixelSize,i.paddingPixels=a,i}function a(e,n){return 0===e?n.minPixelSize:n.minPixelSize*(1+2*n.paddingPixels/e)}function l(e,n){return Math.max(i.lerp(e*n.scale,e,n.factor),a(e,n))}function s(e,n,t){var i=o(e,n,t);return i.minPixelSize=0,i.paddingPixels=0,l(1,i)}Object.defineProperty(n,"__esModule",{value:!0}),n.getSettings=function(e){return new c(e,n.defaultDescription)},n.getLabelSettings=function(e){var t=n.defaultDescription.curvatureDependent,i=n.defaultDescription.scaleStart,r=n.defaultDescription.scaleFallOffRange;return new c(e,{curvatureDependent:{min:{curvature:t.min.curvature,tiltAngle:t.min.tiltAngle,scaleFallOffFactor:d.curvatureDependent.min.scaleFallOffFactor},max:{curvature:t.max.curvature,tiltAngle:t.max.tiltAngle,scaleFallOffFactor:d.curvatureDependent.max.scaleFallOffFactor}},scaleStart:i,scaleFallOffRange:r,minPixelSize:d.minPixelSize})},n.perspectiveFactor=r,n.scaleFactor=o,n.applyScaleFactor=l,n.applyScaleFactorVec2=function(e,n,t){void 0===t&&(t=[0,0]);var r=Math.min(Math.max(n.scale,a(e[1],n)/e[1]),1);return t[0]=i.lerp(e[0]*r,e[0],n.factor),t[1]=i.lerp(e[1]*r,e[1],n.factor),t},n.precomputeScale=s,n.precomputeScaleFactor=function(e,n,t,i){return i.scale=s(e,n,t),i.factor=0,i.minPixelSize=t.parameters.minPixelSize,i.paddingPixels=t.paddingPixelsOverride,i},n.applyPrecomputedScaleFactorVec2=function(e,n,t){void 0===t&&(t=[0,0]);var i=Math.min(Math.max(n.scale,a(e[1],n)/e[1]),1);return t[0]=e[0]*i,t[1]=e[1]*i,t},n.scale=function(e,n,t,i){return l(e,o(n,t,i))};var c=function(){function e(e,n,t,i){void 0===t&&(t={camera:{distance:0,fovY:0},divisor:0,offset:0,minPixelSize:0,paddingPixels:0}),this.viewingMode=e,this.description=n,this.parameters=t,this._paddingPixelsOverride=i,"local"===this.viewingMode?(this.coverageCompensation=this.surfaceCoverageCompensationLocal,this.calculateCurvatureDependentParameters=this.calculateCurvatureDependentParametersLocal):(this.coverageCompensation=this.surfaceCoverageCompensationGlobal,this.calculateCurvatureDependentParameters=this.calculateCurvatureDependentParametersGlobal)}return Object.defineProperty(e.prototype,"paddingPixelsOverride",{get:function(){return this._paddingPixelsOverride||this.parameters.paddingPixels},enumerable:!0,configurable:!0}),e.prototype.update=function(e){return!(this.parameters&&this.parameters.camera.fovY===e.fovY&&this.parameters.camera.distance===e.distance||(this.calculateParameters(e,this.parameters),0))},e.prototype.overridePadding=function(n){return n!==this.paddingPixelsOverride?new e(this.viewingMode,this.description,this.parameters,n):this},e.prototype.calculateParameters=function(e,n){var t=this.description,i=t.scaleStart,r=t.scaleFallOffRange,o=t.minPixelSize,a=e.fovY,l=e.distance,s=this.calculateCurvatureDependentParameters(e),c=this.coverageCompensation(e,s),d=s.tiltAngle,u=s.scaleFallOffFactor,f=Math.sin(d)*l,p=.5*Math.PI-d-a*(.5-i*c),v=f/Math.cos(p),h=p+a*r*c,m=(v-u*(f/Math.cos(h)))/(1-u);return n.camera.fovY=e.fovY,n.camera.distance=e.distance,n.offset=m,n.divisor=v-m,n.minPixelSize=o,n},e.prototype.calculateCurvatureDependentParametersLocal=function(e,n){return void 0===n&&(n=f),n.tiltAngle=this.description.curvatureDependent.min.tiltAngle,n.scaleFallOffFactor=this.description.curvatureDependent.min.scaleFallOffFactor,n},e.prototype.calculateCurvatureDependentParametersGlobal=function(e,n){void 0===n&&(n=f);var r=this.description.curvatureDependent,o=1+e.distance/t.earthRadius,a=Math.sqrt(o*o-1),l=[r.min.curvature,r.max.curvature],s=l[0],c=l[1],d=i.clamp((a-s)/(c-s),0,1),u=[r.min,r.max],p=u[0],v=u[1];return n.tiltAngle=i.lerp(p.tiltAngle,v.tiltAngle,d),n.scaleFallOffFactor=i.lerp(p.scaleFallOffFactor,v.scaleFallOffFactor,d),n},e.prototype.surfaceCoverageCompensationLocal=function(e,n){return(e.fovY-n.tiltAngle)/e.fovY},e.prototype.surfaceCoverageCompensationGlobal=function(e,n){var i=t.earthRadius*t.earthRadius,r=n.tiltAngle+.5*Math.PI,o=e.fovY,a=e.distance,l=a*a+i-2*Math.cos(r)*a*t.earthRadius,s=Math.sqrt(l),c=Math.sqrt(l-i);return(Math.acos(c/s)-Math.asin(t.earthRadius/(s/Math.sin(r)))+.5*o)/o},e}();n.defaultDescription={curvatureDependent:{min:{curvature:i.deg2rad(10),tiltAngle:i.deg2rad(12),scaleFallOffFactor:.5},max:{curvature:i.deg2rad(70),tiltAngle:i.deg2rad(40),scaleFallOffFactor:.8}},scaleStart:.3,scaleFallOffRange:.65,minPixelSize:0};var d={curvatureDependent:{min:{scaleFallOffFactor:.7},max:{scaleFallOffFactor:.95}},minPixelSize:14};n.copyParameters=function(e,n){return n.camera.distance=e.camera.distance,n.camera.fovY=e.camera.fovY,n.divisor=e.divisor,n.offset=e.offset,n.minPixelSize=e.minPixelSize,n};var u={scale:0,factor:0,minPixelSize:0,paddingPixels:0},f={tiltAngle:0,scaleFallOffFactor:0}}.apply(null,i))||(e.exports=r)},"05NA":function(e,n,t){var i,r;i=[t.dj.c(e.i),n],void 0===(r=function(e,n){return function(){function e(){}return e.LAYER="layers",e.OBJECT="objects",e.GEOMETRY="geometries",e.MATERIAL="materials",e.TEXTURE="textures",e}()}.apply(null,i))||(e.exports=r)},"116h":function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("zbgD"),t("U+8K")],void 0===(r=function(e,n,t,i){Object.defineProperty(n,"__esModule",{value:!0});var r=function(e){return i.glslifyDefineMap({DEPTH_PASS:e.depthPass,DRAW_SCREEN_SIZE:e.drawScreenSize,SLICE:e.slicePlaneEnabled})};n.program={name:"point-renderer",shaders:function(e){return{vertexShader:r(e)+t.resolveIncludes("pointRenderer/pointRenderer.vert"),fragmentShader:r(e)+t.resolveIncludes("pointRenderer/pointRenderer.frag")}},attributes:{aPosition:0,aColor:1}}}.apply(null,i))||(e.exports=r)},"1RVI":function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("ma1f")],void 0===(r=function(e,n,t){function i(e,n,t){return{identifier:String.fromCharCode.apply(null,new Uint8Array(e,t+d.identifierOffset,d.identifierLength)),version:n.getUint16(t+d.versionOffset,c),checksum:n.getUint32(t+d.checksumOffset,c)}}function r(e,n){return{sizeLo:e.getUint32(n+u.sizeLo,c),sizeHi:e.getUint32(n+u.sizeHi,c),minX:e.getFloat64(n+u.minX,c),minY:e.getFloat64(n+u.minY,c),minZ:e.getFloat64(n+u.minZ,c),maxX:e.getFloat64(n+u.maxX,c),maxY:e.getFloat64(n+u.maxY,c),maxZ:e.getFloat64(n+u.maxZ,c),errorX:e.getFloat64(n+u.errorX,c),errorY:e.getFloat64(n+u.errorY,c),errorZ:e.getFloat64(n+u.errorZ,c),count:e.getUint32(n+u.count,c),reserved:e.getUint32(n+u.reserved,c)}}function o(e,n,t){var i=[];n=a(e,n,i);for(var r=[],o=0;o<i.length;o++){r.length=0,n=a(e,n,r);for(var l=0;l<r.length;l++)t.push(r[l]+i[o])}return n}function a(e,n,i){var r=new DataView(e,n),o=r.getUint8(0),a=31&o,l=!!(32&o),s=(192&o)>>6,d=0;if(0===s)d=r.getUint32(1,c),n+=5;else if(1===s)d=r.getUint16(1,c),n+=3;else{if(2!==s)throw new t("lepcc-decode-error","Bad count type");d=r.getUint8(1),n+=2}if(l)throw new t("lepcc-decode-error","LUT not implemented");for(var u=Math.ceil(d*a/8),f=new Uint8Array(e,n,u),p=0,v=0,h=0,m=-1>>>32-a,g=0;g<d;g++){for(;v<a;)p|=f[h]<<v,v+=8,h+=1;i[g]=p&m,p>>>=a,(v-=a)+a>32&&(p|=f[h-1]>>8-v)}return n+h}function l(e,n){return{sizeLo:e.getUint32(n+f.sizeLo,c),sizeHi:e.getUint32(n+f.sizeHi,c),count:e.getUint32(n+f.count,c),colorMapCount:e.getUint16(n+f.colorMapCount,c),lookupMethod:e.getUint8(n+f.lookupMethod),compressionMethod:e.getUint8(n+f.compressionMethod)}}function s(e,n){return{sizeLo:e.getUint32(n+p.sizeLo,c),sizeHi:e.getUint32(n+p.sizeHi,c),count:e.getUint32(n+p.count,c),scaleFactor:e.getUint16(n+p.scaleFactor,c),bitsPerPoint:e.getUint8(n+p.bitsPerPoint),reserved:e.getUint8(n+p.reserved)}}Object.defineProperty(n,"__esModule",{value:!0});var c=!0,d={identifierOffset:0,identifierLength:10,versionOffset:10,checksumOffset:12,byteCount:16},u={sizeLo:0,sizeHi:4,minX:8,minY:16,minZ:24,maxX:32,maxY:40,maxZ:48,errorX:56,errorY:64,errorZ:72,count:80,reserved:84,byteCount:88};n.decodeXYZ=function(e){var n=new DataView(e,0),a=0,l=i(e,n,a),s=l.identifier,c=l.version;if(a+=d.byteCount,"LEPCC     "!==s)throw new t("lepcc-decode-error","Bad identifier");if(c>1)throw new t("lepcc-decode-error","Unknown version");var f=r(n,a);if(a+=u.byteCount,f.sizeHi*Math.pow(2,32)+f.sizeLo!==e.byteLength)throw new t("lepcc-decode-error","Bad size");var p=new Float64Array(3*f.count),v=[],h=[],m=[],g=[];if(a=o(e,a,v),a=o(e,a,h),a=o(e,a,m),(a=o(e,a,g))!==e.byteLength)throw new t("lepcc-decode-error","Bad length");for(var y=0,x=0,S=0;S<v.length;S++){x+=v[S];for(var b=0,_=0;_<h[S];_++){b+=m[y];var P=g[y];p[3*y]=Math.min(f.maxX,f.minX+2*f.errorX*b),p[3*y+1]=Math.min(f.maxY,f.minY+2*f.errorY*x),p[3*y+2]=Math.min(f.maxZ,f.minZ+2*f.errorZ*P),y++}}return{errorX:f.errorX,errorY:f.errorY,errorZ:f.errorZ,result:p}};var f={sizeLo:0,sizeHi:4,count:8,colorMapCount:12,lookupMethod:14,compressionMethod:15,byteCount:16};n.decodeRGB=function(e){var n=new DataView(e,0),r=0,o=i(e,n,r),a=o.identifier,s=o.version;if(r+=d.byteCount,"ClusterRGB"!==a)throw new t("lepcc-decode-error","Bad identifier");if(s>1)throw new t("lepcc-decode-error","Unknown version");var c=l(n,r);if(r+=f.byteCount,c.sizeHi*Math.pow(2,32)+c.sizeLo!==e.byteLength)throw new t("lepcc-decode-error","Bad size");if((2===c.lookupMethod||1===c.lookupMethod)&&0===c.compressionMethod){if(3*c.colorMapCount+c.count+r!==e.byteLength||c.colorMapCount>256)throw new t("lepcc-decode-error","Bad count");for(var u=new Uint8Array(e,r,3*c.colorMapCount),p=new Uint8Array(e,r+3*c.colorMapCount,c.count),v=new Uint8Array(3*c.count),h=0;h<c.count;h++){var m=p[h];v[3*h]=u[3*m],v[3*h+1]=u[3*m+1],v[3*h+2]=u[3*m+2]}return v}if(0===c.lookupMethod&&0===c.compressionMethod){if(3*c.count+r!==e.byteLength||0!==c.colorMapCount)throw new t("lepcc-decode-error","Bad count");return new Uint8Array(e,r).slice()}if(c.lookupMethod<=2&&1===c.compressionMethod){if(r+3!==e.byteLength||1!==c.colorMapCount)throw new t("lepcc-decode-error","Bad count");var g=n.getUint8(r),y=n.getUint8(r+1),x=n.getUint8(r+2);for(v=new Uint8Array(3*c.count),h=0;h<c.count;h++)v[3*h]=g,v[3*h+1]=y,v[3*h+2]=x;return v}throw new t("lepcc-decode-error","Bad method "+c.lookupMethod+","+c.compressionMethod)};var p={sizeLo:0,sizeHi:4,count:8,scaleFactor:12,bitsPerPoint:14,reserved:15,byteCount:16};n.decodeIntensity=function(e){var n=new DataView(e,0),r=0,o=i(e,n,r),l=o.identifier,c=o.version;if(r+=d.byteCount,"Intensity "!==l)throw new t("lepcc-decode-error","Bad identifier");if(c>1)throw new t("lepcc-decode-error","Unknown version");var u=s(n,r);if(r+=p.byteCount,u.sizeHi*Math.pow(2,32)+u.sizeLo!==e.byteLength)throw new t("lepcc-decode-error","Bad size");var f=new Uint16Array(u.count);if(8===u.bitsPerPoint){if(u.count+r!==e.byteLength)throw new t("lepcc-decode-error","Bad size");for(var v=new Uint8Array(e,r,u.count),h=0;h<u.count;h++)f[h]=v[h]*u.scaleFactor}else if(16===u.bitsPerPoint){if(2*u.count+r!==e.byteLength)throw new t("lepcc-decode-error","Bad size");for(v=new Uint16Array(e,r,u.count),h=0;h<u.count;h++)f[h]=v[h]*u.scaleFactor}else{if(a(e,r,v=[])!==e.byteLength)throw new t("lepcc-decode-error","Bad size");for(h=0;h<u.count;h++)f[h]=v[h]*u.scaleFactor}return f}}.apply(null,i))||(e.exports=r)},"1f+t":function(e,n,t){var i,r;i=[t.dj.c(e.i),n],void 0===(r=function(e,n){function t(e,n,t){for(var i=0;i<t;++i)n[2*i]=e[i],n[2*i+1]=e[i]-n[2*i]}Object.defineProperty(n,"__esModule",{value:!0}),n.encodeDouble=function(e,n){r[0]=e,r[1]=e-r[0],n[0]=r[0],n[1]=r[1]},n.encodeDoubleArray=t,n.decodeDoubleArray=function(e,n,t){for(var i=0;i<t;++i)n[i]=e[2*i]+e[2*i+1]},n.encodeDoubleArraySplit=function(e,n,o,a){for(var l=0;l<a;++l)i[0]=e[l],t(i,r,1),n[l]=r[0],o[l]=r[1]};var i=new Float64Array(1),r=new Float32Array(2)}.apply(null,i))||(e.exports=r)},"2A3h":function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("CIy2"),t("U+8K")],void 0===(r=function(e,n,t,i){return function(){function e(e,n){void 0===n&&(n=""),this._rctx=e,this._shaderPrefix=n,this._programCacheByTemplate=new Map,this._programRefCount=[],this._commonUniforms={model:[],modelNormal:[],lightDirection:[],proj:[],shadowMapDistance:[],viewportPixelSz:[],lightingMainDirection:[]}}return e.prototype.dispose=function(){this._programCacheByTemplate.forEach(function(e){e.programs.forEach(function(e){e.dispose()})}),this._programCacheByTemplate=null,this._programRefCount=null,this._commonUniforms=null,this._rctx=null},e.prototype.getProgram=function(e,n){var t=this;return this._programCacheByTemplate.has(e)||this.addProgramTemplate(e,function(n){return i.createProgram(t._rctx,e,n,t._shaderPrefix)}),this.getProgramTemplateInstance(e,n)},e.prototype.addProgramTemplate=function(e,n){this._programCacheByTemplate.set(e,{constructor:n,programs:new Map})},e.prototype.getProgramTemplateInstance=function(e,n){var t=this._programCacheByTemplate.get(e);if(t){var i=n?JSON.stringify(n):"default";if(!t.programs.has(i)){var r=t.constructor(n);t.programs.set(i,r)}return t.programs.get(i)}return null},e.prototype.getProgramsUsingUniform=function(e){return this._commonUniforms[e]||[]},e.prototype.increaseRefCount=function(e){var n=e.id;this._programRefCount[n]?this._programRefCount[n]++:(this._programRefCount[n]=1,this._findCommonUniforms(e))},e.prototype.decreaseRefCount=function(e){var n=e.id;this._programRefCount[n]>1?this._programRefCount[n]--:(this._forgetCommonUniforms(e),this._programRefCount[n]=0)},e.prototype._findCommonUniforms=function(e){for(var n in this._commonUniforms)e.hasUniform(n)&&(t.assert(-1===this._commonUniforms[n].indexOf(e),"common uniforms of program have already been determined"),this._commonUniforms[n].push(e))},e.prototype._forgetCommonUniforms=function(e){for(var n in this._commonUniforms){var t=this._commonUniforms[n],i=t.indexOf(e);i>-1&&(t[i]=t[t.length-1],t.pop())}},e}()}.apply(null,i))||(e.exports=r)},"531e":function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("9opi"),t("qKT0"),t("TMur"),t("ycL1"),t("rg9i"),t("Vx27")],void 0===(r=function(e,n,t,i,r,o,a,l){return function(e){function n(n){var t=e.call(this,n)||this;return t.gdbVersion=null,t.geometryPrecision=void 0,t.historicMoment=null,t.maxAllowableOffset=void 0,t.objectIds=null,t.outFields=null,t.outSpatialReference=null,t.relationshipId=void 0,t.returnGeometry=!1,t.source=null,t.where=null,t}var o;return t(n,e),o=n,n.prototype._writeHistoricMoment=function(e,n){n.historicMoment=e&&e.getTime()},n.prototype.clone=function(){return new o(a.clone({gdbVersion:this.gdbVersion,geometryPrecision:this.geometryPrecision,historicMoment:this.historicMoment&&this.historicMoment.getTime(),maxAllowableOffset:this.maxAllowableOffset,objectIds:this.objectIds,outFields:this.outFields,outSpatialReference:this.outSpatialReference,relationshipId:this.relationshipId,returnGeometry:this.returnGeometry,source:this.source,where:this.where}))},i([l.property({type:String,json:{write:!0}})],n.prototype,"gdbVersion",void 0),i([l.property({type:Number,json:{write:!0}})],n.prototype,"geometryPrecision",void 0),i([l.property({type:Date})],n.prototype,"historicMoment",void 0),i([l.writer("historicMoment")],n.prototype,"_writeHistoricMoment",null),i([l.property({type:Number,json:{write:!0}})],n.prototype,"maxAllowableOffset",void 0),i([l.property({type:[Number],json:{write:!0}})],n.prototype,"objectIds",void 0),i([l.property({type:[String],json:{write:!0}})],n.prototype,"outFields",void 0),i([l.property({type:r.SpatialReference,json:{read:{source:"outSR"},write:{target:"outSR"}}})],n.prototype,"outSpatialReference",void 0),i([l.property({json:{write:!0}})],n.prototype,"relationshipId",void 0),i([l.property({json:{write:!0}})],n.prototype,"returnGeometry",void 0),i([l.property({json:{write:!0}})],n.prototype,"source",void 0),i([l.property({type:String,json:{read:{source:"definitionExpression"},write:{target:"definitionExpression"}}})],n.prototype,"where",void 0),o=i([l.subclass("esri.tasks.support.RelationshipQuery")],n)}(l.declared(o))}.apply(null,i))||(e.exports=r)},"8Ntk":function(e,n,t){var i,r;i=[t.dj.c(e.i),n],void 0===(r=function(e,n){Object.defineProperty(n,"__esModule",{value:!0}),n.updatingPercentageValue={value:100,readOnly:!0},n.updatingPercentage={dependsOn:["updating","updatingPercentageValue"],readOnly:!0,value:0,get:function(){return this.updating?this.updatingPercentageValue:0}}}.apply(null,i))||(e.exports=r)},"9DjX":function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("jZlN"),t("LxLY"),t("YX1r"),t("51bw"),t("FXVB"),t("1m5D"),t("0LE5"),t("Rdxj"),t("2fXB"),t("O7NG"),t("aWgr"),t("2eYJ"),t("ZJC8")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u,f,p,v){function h(e,n){return i.isNone(e)||null==e.layerUid?null:i.isSome(n.graphicsView)&&e.layerUid===n.graphicsView.mockLayerId?n.graphics:n.map.findLayerByUid(e.layerUid)}function m(e,n,t){if(i.isNone(e))return null;var r=h(e,n);if(i.isNone(r))return null;if(r===n.graphics)return i.isSome(n.graphicsView)?i.expect(n.graphicsView.getGraphicFromGraphicUid(e.graphicUid)):null;var o=n.allLayerViews.find(function(e){return e.layer===r});return o?g(o,e,t):null}function g(e,n,t){return!e||e.suspended?null:i.isSome(t)&&"getGraphicFromStageObject"in e?e.getGraphicFromStageObject(t.obj,t.triangleNr):"getGraphicFromGraphicUid"in e&&null!=n.graphicUid?e.getGraphicFromGraphicUid(n.graphicUid):null}function y(e,n){var t=e.metadata.layerUid;return null!=t?n.map.findLayerByUid(t):null}function x(e,n){var i=n.computeMapPointFromVec3d(e.point),r=new t(i),o=e.metadata.layerUid;if(null!=o){var a=n.map.findLayerByUid(o);r.layer=a,r.sourceLayer=a}return r}Object.defineProperty(n,"__esModule",{value:!0}),n.sliceFilterPredicate=function(e){return function(n,t,i){return s.vec3.lerp(w,n,t,i),!p.extrusionContainsPoint(e,w)}};var S=function(){this.hud=!0,this.selectOpaqueTerrainOnly=!0,this.invisibleTerrain=!1,this.backfacesTerrain=!0,this.storeTerrainResults=!0,this.storeAll=!0};n.EnableIntersectorOptions=S;var b=function(){function e(){this._transform=l.mat4f64.create(),this._transformInverse=new _({value:this._transform},a.mat4.invert,l.mat4f64.create),this._transformInverseTranspose=new _(this._transformInverse,a.mat4.transpose,l.mat4f64.create),this._transformTranspose=new _({value:this._transform},a.mat4.transpose,l.mat4f64.create),this._transformInverseRotation=new _({value:this._transform},r.mat3.normalFromMat4Legacy,o.mat3f64.create)}return e.prototype.invalidateLazyTransforms=function(){this._transformInverse.invalidate(),this._transformInverseTranspose.invalidate(),this._transformTranspose.invalidate(),this._transformInverseRotation.invalidate()},Object.defineProperty(e.prototype,"transform",{get:function(){return this._transform},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"inverse",{get:function(){return this._transformInverse.value},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"inverseTranspose",{get:function(){return this._transformInverseTranspose.value},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"inverseRotation",{get:function(){return this._transformInverseRotation.value},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"transpose",{get:function(){return this._transformTranspose.value},enumerable:!0,configurable:!0}),e.prototype.setTransformMatrix=function(e){a.mat4.copy(this._transform,e)},e.prototype.multiplyTransform=function(e){a.mat4.multiply(this._transform,this._transform,e)},e.prototype.set=function(e){a.mat4.copy(this._transform,e),this.invalidateLazyTransforms()},e.prototype.setAndInvalidateLazyTransforms=function(e,n){this.setTransformMatrix(e),this.multiplyTransform(n),this.invalidateLazyTransforms()},e}();n.IntersectorTransform=b;var _=function(){function e(e,n,t){this.original=e,this.update=n,this.dirty=!0,this.transform=t()}return e.prototype.invalidate=function(){this.dirty=!0},Object.defineProperty(e.prototype,"value",{get:function(){return this.dirty&&(this.update(this.transform,this.original.value),this.dirty=!1),this.transform},enumerable:!0,configurable:!0}),e}(),P=function(){function e(){this.min=new C,this.max=new C,this.hud=new C,this.terrain=new C}return e.prototype.init=function(e){this.min.init(e),this.max.init(e),this.hud.init(e),this.terrain.init(e),this.all=[]},e}();n.IntersectorResults=P;var C=function(){function e(e){this.normal=c.vec3f64.create(),this.transformation=l.mat4f64.create(),this._ray=f.ray.create(),this.init(e)}return Object.defineProperty(e.prototype,"ray",{get:function(){return this._ray},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"hasIntersectionPoint",{get:function(){return null!=this.dist},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"distanceInRenderSpace",{get:function(){if(null!=this.dist)return s.vec3.scale(O,this.ray.direction,this.dist),s.vec3.length(O)},enumerable:!0,configurable:!0}),e.prototype.getIntersectionPoint=function(e){return!!this.hasIntersectionPoint&&(s.vec3.scale(O,this.ray.direction,this.dist),s.vec3.add(e,this.ray.origin,O),!0)},e.prototype.getTransformedNormal=function(e){return s.vec3.copy(E,this.normal),E[3]=0,d.vec4.transformMat4(E,E,this.transformation),s.vec3.copy(e,E),s.vec3.normalize(e,e),e},e.prototype.set=function(e,n,t,i,r,o,l,d,u,f){e instanceof v&&(e={type:"stage",obj:e}),this.dist=t,s.vec3.copy(this.normal,i),a.mat4.copy(this.transformation,r),this.target=e,this.name=n,this.drapedLayerOrder=o,this.center=l?c.vec3f64.clone(l):null,this.geometryId=d,this.triangleNr=u,this.drapedLayerGraphicOrder=f},e.prototype.copyFrom=function(e){f.ray.copy(e._ray,this._ray),this.dist=e.dist,this.target=e.target,this.name=e.name,this.drapedLayerOrder=e.drapedLayerOrder,this.center=e.center?c.vec3f64.clone(e.center):null,this.geometryId=e.geometryId,this.triangleNr=e.triangleNr,this.intersector=e.intersector,this.drapedLayerGraphicOrder=e.drapedLayerGraphicOrder,s.vec3.copy(this.normal,e.normal),a.mat4.copy(this.transformation,e.transformation)},e.prototype.init=function(e){this.dist=void 0,this.target=void 0,this.name=void 0,this.drapedLayerOrder=void 0,this.drapedLayerGraphicOrder=void 0,this.center=null,this.geometryId=null,this.triangleNr=null,this.intersector="Stage",e?f.ray.copy(e,this._ray):this._ray=f.ray.create()},e.prototype.toOwner=function(e){if(!this.target)return null;switch(this.target.type){case"stage":return h(this.target.obj.getMetadata(),e);case"external":switch(this.intersector){case"PointRenderer":return y(this.target,e);case"LodRenderer":case"DrapedRenderer":return h(this.target.metadata,e);case"TerrainRenderer":return e.map&&e.map.ground}}return null},e.prototype.toGraphic=function(e){if(!this.target)return null;switch(this.target.type){case"stage":var n=this.target.obj,t=this.triangleNr;return m(n.getMetadata(),e,{obj:n,triangleNr:t});case"external":switch(this.intersector){case"PointRenderer":return x(this.target,e);case"LodRenderer":case"DrapedRenderer":return m(this.target.metadata,e,null)}}return null},e}();n.IntersectorResult=C,n.TERRAIN_ID="terrain";var w=c.vec3f64.create(),O=c.vec3f64.create(),E=u.vec4f64.create()}.apply(null,i))||(e.exports=r)},ADZV:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("qMld")],void 0===(r=function(e,n,t){Object.defineProperty(n,"__esModule",{value:!0}),n.when=function e(n,i){return Array.isArray(i)?t.create(function(e){n(i,function(){for(var n=[],t=0;t<arguments.length;t++)n[t]=arguments[t];e(n)})}):e(n,[i]).then(function(e){return e[0]})},n.getAbsMid=function(e,n,t){return n.toAbsMid?n.toAbsMid(e):t.id.replace(/\/[^\/]*$/gi,"/")+e}}.apply(null,i))||(e.exports=r)},"Cvn+":function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("W0kZ")],void 0===(r=function(e,n,t){return function(){function e(n,t,i,r,o,a){this.id=e._idGen.gen(n.id),this.geometry=n,this.material=t,this.transformation=i,this.instanceParameters=r,this.origin=o,this.shaderTransformation=a}return e.prototype.getStaticTransformation=function(){return this.transformation},e.prototype.getShaderTransformation=function(){return this.shaderTransformation?this.shaderTransformation(this.transformation):this.transformation},e._idGen=new t,e}()}.apply(null,i))||(e.exports=r)},EuvN:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("weYu")],void 0===(r=function(e,n,t){Object.defineProperty(n,"__esModule",{value:!0}),n.quat=t}.apply(null,i))||(e.exports=r)},F8B7:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("0LE5")],void 0===(r=function(e,n,t){function i(e,n,t){for(var i=e;i>0;){var r=n.indexOf(i);if(r>=0)return r;i=t.getParentId(i)}return n.indexOf(i)}function r(e,n){for(var t=[e.remove[0]],i=[];1===t.length;){var r=t.pop();i.length=0;for(var o=0;o<e.load.length;o++){for(var a=e.load[o],l=n.getParentId(a);l!==r;)a=l,l=n.getParentId(a);var s=t.indexOf(a);s<0&&(s=t.length,t.push(a),i.push([])),i[s].push(e.load[o])}}var c=[];c.push({remove:e.remove,load:t});for(o=0;o<t.length;o++)i[o].length>1?c.push({remove:[t[o]],load:i[o]}):t[o]=i[o][0];return c}Object.defineProperty(n,"__esModule",{value:!0}),n.nodeDiff=function(e,n,t){for(var r=0;r<n.length;r++)l[r]=!1,s[r]=null;for(r=0;r<e.length;r++)o[r]=!1,a[r]=null;for(r=0;r<n.length;r++)(c=i(n[r],e,t))>=0&&(l[r]=!0,null!=a[c]?a[c].push(n[r]):a[c]=[n[r]]);for(r=0;r<e.length;r++){var c;(c=i(e[r],n,t))>=0&&(o[r]=!0,null!=s[c]?s[c].push(e[r]):s[c]=[e[r]])}var d=[];for(r=0;r<e.length;r++)null!=a[r]||o[r]||d.push({load:[],remove:[e[r]]});for(r=0;r<n.length;r++)null!=s[r]||l[r]||d.push({load:[n[r]],remove:[]});for(r=0;r<n.length;r++)null!=s[r]&&(s[r].length>1||s[r][0]!==n[r])&&d.push({load:[n[r]],remove:s[r]});for(r=0;r<e.length;r++)null!=a[r]&&(a[r].length>1||a[r][0]!==e[r])&&d.push({load:a[r],remove:[e[r]]});return d};var o=[!1],a=[null],l=[!1],s=[null];n.sortFrontToBack=function(e,n,i){return e.sort(function(e,r){if(0===e.load.length&&0===r.load.length)return 0;if(0===e.load.length)return-1;if(0===r.load.length)return 1;if(0===e.remove.length&&0===r.remove.length){var o=i.getRenderCenter(e.load[0]),a=i.getRenderCenter(r.load[0]);return t.vec3.dot(o,n)-t.vec3.dot(a,n)}return 0===e.remove.length?-1:0===r.remove.length?1:1===e.load.length&&1===r.load.length?(o=i.getRenderCenter(e.load[0]),a=i.getRenderCenter(r.load[0]),t.vec3.dot(o,n)-t.vec3.dot(a,n)):1===e.load.length?-1:1===r.load.length?1:(o=i.getRenderCenter(e.remove[0]),a=i.getRenderCenter(r.remove[0]),t.vec3.dot(o,n)-t.vec3.dot(a,n))})},n.splitWorkEntries=function(e,n,t){for(var i=0;i<e.length;++i){var o=e[i];if(o.load.length>n&&1===o.remove.length){var a=r(o,t);e[i]=a[0];for(var l=1;l<a.length;l++)e.push(a[l])}}},n.splitWorkEntry=r}.apply(null,i))||(e.exports=r)},OA8v:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("1m5D"),t("EuvN"),t("fdzS"),t("0LE5"),t("Rdxj"),t("WRgd"),t("QyYG"),t("mmEe")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c){function d(e,n,t){var i=e.index;if(i.hasNodes(0,1)){var r=e.queue;r.length=0,r.push(0);var o=e.masks;for(o.length=0,o.push(0);r.length>0;){var a=r.pop(),c=o.pop(),d=i.getNode(a),u=i.getRenderObb(a),f=!0;if(null!=n.clippingBox)if(0==(c&(m=1<<n.frustumPlanes.length))){var v=s.toAaBoundingBox(u,e.tempAabb);l.contains(n.clippingBox,v)?c|=m:l.intersects(n.clippingBox,v)||(f=!1)}for(var h=0;h<n.frustumPlanes.length&&f;h++){var m;if(0==(c&(m=1<<h))){var g=s.intersectPlane(u,n.frustumPlanes[h]);g>0?f=!1:g<0&&(c|=m)}}if(t.predicate(a,d,f)){for(var y=d.firstChild,x=d.childCount,S=!1,b=p(y,i.pageSize),_=p(y+x-1,i.pageSize),P=b;P<=_;P++)if(!i.hasPage(P)){t.pageMiss(a,P),S=!0;break}if(!S)for(h=0;h<x;h++)r.push(y+h),o.push(c)}}}}function u(e,n,t,r){for(var a=new s.ObbArray(e.length),l=0;l<e.length;l++){var d=e[l].obb,u=a.obbs[l];if(s.set(d,u),o.vec3.set(h,d.center[0],d.center[1],d.center[2]+r),!n.isGeographic&&t===c.SphericalECEFSpatialReference){c.computeLinearTransformation(n,h,g,t);var f=2*Math.sqrt(1+g[0]+g[5]+g[10]);y[0]=(g[9]-g[6])/f,y[1]=(g[2]-g[8])/f,y[2]=(g[4]-g[1])/f,y[3]=.25*f,i.quat.conjugate(y,y),i.quat.multiply(u.quaternion,y,u.quaternion)}c.bufferToBuffer(h,n,0,u.center,t,0,1)}return a.obbs}function f(e,n){for(var t=[0];t.length;)for(var i=t.pop(),r=e[p(i,n)].nodes[v(i,n)],o=0;o<r.childCount;o++){var a=r.firstChild+o;null!=e[p(a,n)]&&(e[p(a,n)].parents[v(a,n)]=i,t.push(a))}}function p(e,n){return e/n|0}function v(e,n){return e%n}var h=a.vec3f64.create(),m=function(){function e(e,n,t){this._pages=[],this.pageSize=0,this._nodeSR=null,this._renderSR=null,this._nodeSR=e,this._renderSR=n,this.pageSize=t}return e.prototype.addPage=function(e,n,t){for(void 0===t&&(t=0);this._pages.length<e;)this._pages.push(null);var i=u(n,this._nodeSR,this._renderSR,t);this._pages[e]={nodes:n,renderObbs:i,parents:new Uint32Array(this.pageSize)},f(this._pages,this.pageSize)},e.prototype.hasPage=function(e){return!!this._pages[e]},e.prototype.getNode=function(e){var n=this.pageSize;return this._pages[p(e,n)].nodes[v(e,n)]},e.prototype.getRenderObb=function(e){var n=this.pageSize;return this._pages[p(e,n)].renderObbs[v(e,n)]},e.prototype.getRenderCenter=function(e){return this.getRenderObb(e).center},e.prototype.setRenderObb=function(e,n){var t=this.pageSize;s.set(n,this._pages[p(e,t)].renderObbs[v(e,t)])},e.prototype.getParentId=function(e){var n=this.pageSize;return this._pages[p(e,n)].parents[v(e,n)]},e.prototype.hasNodes=function(e,n){for(var t=p(e,this.pageSize),i=p(e+n-1,this.pageSize),r=t;r<=i;r++)if(null==this._pages[r])return!1;return!0},e.prototype.createVisibilityTraverse=function(){var e={index:this,queue:[],masks:[],tempAabb:l.create()};return function(n,t){return d(e,n,t)}},e}(),g=t.mat4f64.create(),y=r.quatf32.create();return m}.apply(null,i))||(e.exports=r)},Ondo:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("9opi"),t("qKT0"),t("qMld"),t("8MXS"),t("Vx27"),t("niw0"),t("WsO6")],void 0===(r=function(e,n,t,i,r,o,a,l,s){return function(e){function n(){var n=null!==e&&e.apply(this,arguments)||this;return n.slicePlaneEnabled=!1,n.supportsHeightUnitConversion=!1,n}return t(n,e),n.prototype.postscript=function(e){this.inherited(arguments),l.mayHaveHeightModelInfo(this.layer)&&this.addResolvingPromise(this._validateHeightModelInfo())},n.prototype._validateHeightModelInfo=function(){var e=this;return r.create(function(n,t){o.whenFalseOnce(e.view.defaultsFromMap,"isHeightModelInfoSearching",function(){var i=l.rejectLayerError(e.layer,e.view.heightModelInfo,e.supportsHeightUnitConversion);i?t(i):n()})})},i([a.property()],n.prototype,"view",void 0),i([a.property()],n.prototype,"slicePlaneEnabled",void 0),i([a.subclass("esri.views.3d.layers.LayerView3D")],n)}(a.declared(s))}.apply(null,i))||(e.exports=r)},QyYG:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("YX1r"),t("lgZd"),t("EuvN"),t("fdzS"),t("0LE5"),t("vlC2"),t("Rdxj"),t("WRgd"),t("mCA8"),t("aWgr")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u){function f(e,n,t){return{center:s.vec3f64.clone(e),halfSize:l.vec3f32.clone(n),quaternion:o.quatf32.clone(t)}}function p(e,n){var t=u.plane.signedDistance(n,e.center),i=v(e,n);return t>i?1:t<-i?-1:0}function v(e,n){r.quat.conjugate(h,e.quaternion),a.vec3.transformQuat(m,n,h);var t=e.halfSize;return Math.abs(m[0]*t[0])+Math.abs(m[1]*t[1])+Math.abs(m[2]*t[2])}Object.defineProperty(n,"__esModule",{value:!0});var h=o.quatf32.create(),m=l.vec3f32.create(),g=l.vec3f32.create(),y=i.mat3f32.create(),x=function(e){var n=56*e;this.buffer=new ArrayBuffer(n),this.obbs=new Array(e);for(var t=0;t<e;t++)this.obbs[t]={center:s.vec3f64.createView(this.buffer,56*t+0),halfSize:l.vec3f32.createView(this.buffer,56*t+24),quaternion:o.quatf32.createView(this.buffer,56*t+36)}};n.ObbArray=x,n.create=f,n.clone=function(e){return f(e.center,e.halfSize,e.quaternion)},n.set=function(e,n){a.vec3.copy(n.center,e.center),a.vec3.copy(n.halfSize,e.halfSize),r.quat.copy(n.quaternion,e.quaternion)},n.compute=function(e,n){return n||(n=f([0,0,0],[-1,-1,-1],[0,0,0,1])),d.computeOBB(e,n),n},n.intersectPlane=p,n.toAaBoundingBox=function(e,n){n||(n=c.create());var i=t.mat3.fromQuat(y,e.quaternion),r=e.halfSize[0]*Math.abs(i[0])+e.halfSize[1]*Math.abs(i[3])+e.halfSize[2]*Math.abs(i[6]),o=e.halfSize[0]*Math.abs(i[1])+e.halfSize[1]*Math.abs(i[4])+e.halfSize[2]*Math.abs(i[7]),a=e.halfSize[0]*Math.abs(i[2])+e.halfSize[1]*Math.abs(i[5])+e.halfSize[2]*Math.abs(i[8]);return n[0]=e.center[0]-r,n[1]=e.center[1]-o,n[2]=e.center[2]-a,n[3]=e.center[0]+r,n[4]=e.center[1]+o,n[5]=e.center[2]+a,n},n.minimumDistancePlane=function(e,n){return u.plane.signedDistance(n,e.center)-v(e,n)},n.maximumDistancePlane=function(e,n){return u.plane.signedDistance(n,e.center)+v(e,n)},n.isVisible=function(e,n){return p(e,n.planes[0])<=0&&p(e,n.planes[1])<=0&&p(e,n.planes[2])<=0&&p(e,n.planes[3])<=0&&p(e,n.planes[4])<=0&&p(e,n.planes[5])<=0},n.intersectLine=function(e,n,t,i){void 0===i&&(i=0),r.quat.conjugate(h,e.quaternion),a.vec3.subtract(m,n,e.center);for(var o=a.vec3.transformQuat(m,m,h),l=a.vec3.transformQuat(g,t,h),s=-1/0,c=1/0,d=0;d<3;d++)if(Math.abs(l[d])>1e-6){var u=(i+e.halfSize[d]-o[d])/l[d],f=(-i-e.halfSize[d]-o[d])/l[d];s=Math.max(s,Math.min(u,f)),c=Math.min(c,Math.max(u,f))}else if(o[d]>e.halfSize[d]+i||o[d]<-e.halfSize[d]-i)return!1;return s<=c}}.apply(null,i))||(e.exports=r)},TsGx:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("9opi"),t("qKT0"),t("ycL1"),t("rg9i"),t("Vx27")],void 0===(r=function(e,n,t,i,r,o,a){return function(e){function n(n){var t=e.call(this,n)||this;return t.attachmentTypes=null,t.globalIds=null,t.num=null,t.objectIds=null,t.returnMetadata=!1,t.size=null,t.start=null,t.where=null,t}var r;return t(n,e),r=n,n.prototype.writeStart=function(e,n,t){n.resultOffset=this.start,n.resultRecordCount=this.num||10},n.prototype.clone=function(){return new r(o.clone({attachmentTypes:this.attachmentTypes,where:this.where,globalIds:this.globalIds,num:this.num,objectIds:this.objectIds,returnMetadata:this.returnMetadata,size:this.size,start:this.start}))},i([a.property({type:[String],json:{write:!0}})],n.prototype,"attachmentTypes",void 0),i([a.property({type:[Number],json:{write:!0}})],n.prototype,"globalIds",void 0),i([a.property({type:Number,json:{read:{source:"resultRecordCount"}}})],n.prototype,"num",void 0),i([a.property({type:[Number],json:{write:!0}})],n.prototype,"objectIds",void 0),i([a.property({type:Boolean,json:{default:!1,write:!0}})],n.prototype,"returnMetadata",void 0),i([a.property({type:[Number],json:{write:!0}})],n.prototype,"size",void 0),i([a.property({type:Number,json:{read:{source:"resultOffset"}}})],n.prototype,"start",void 0),i([a.writer("start"),a.writer("num")],n.prototype,"writeStart",null),i([a.property({type:String,json:{read:{source:"definitionExpression"},write:{target:"definitionExpression"}}})],n.prototype,"where",void 0),r=i([a.subclass("esri.tasks.support.AttachmentQuery")],n)}(a.declared(r))}.apply(null,i))||(e.exports=r)},VVgn:function(e,n,t){var i,r;i=[t.dj.c(e.i),n],void 0===(r=function(e,n){return{edgeRenderer:{"adjustProjectedPosition.glsl":"uniform vec2 uDepthBias;\nuniform vec2 uViewportDimInv;\n\n// Utility function to check for NaN values\nbool isNaN(float val) {\n  return ( val < 0.0 || 0.0 < val || val == 0.0 ) ? false : true;\n  // important: some nVidias failed to cope with version below.\n  // Probably wrong optimization.\n  /*return ( val <= 0.0 || 0.0 <= val ) ? false : true;*/\n}\n\n// An offset in xy screen space, along the projected normal of the edge\n// This reduces depth fighting when looking at a face from a flat angle\nvec2 calculateProjectedBiasXY(vec4 projPos, vec3 worldNormal) {\n  float offsetXY = uDepthBias.x;\n  float offsetZ  = uDepthBias.y;\n\n  // screen space pixel offset\n  // we multiply by two to account for the fact that NDC go from -1 to 1\n  // we multiply by projPos.w to compensate for the perspective divison that happens later\n  // normalizing over xyz means that the xy influence is reduced the more the normal is pointing\n  // towards the camera\n  vec4 projNormal = uProj * uView * vec4(worldNormal, 0.0);\n\n  return offsetXY * projPos.w * 2.0 * uViewportDimInv * normalize(projNormal.xyz).xy;\n}\n\n// A z-offset, using a depth based heuristic.\nfloat calculateProjectedBiasZ(vec4 projPos) {\n  float offsetZ = uDepthBias.y;\n  return sqrt(projPos.z) * offsetZ;\n}\n\nvec4 adjustProjectedPosition(vec4 projPos, vec3 worldNormal, float lineWidth) {\n  vec2 offsetXY = calculateProjectedBiasXY(projPos, worldNormal);\n\n  // we currently have to do this check because some geometries come with 0 length edge normals.\n  // see https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/12890\n  if (!isNaN(offsetXY.x) && !isNaN(offsetXY.y)) {\n    projPos.xy += offsetXY;\n  }\n\n  projPos.z += calculateProjectedBiasZ(projPos);\n\n  return projPos;\n}\n","edgeRenderer.frag":"#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nvarying vec4 vColor;\nvarying float vRadius;\nvarying vec3 vPosition;\nvarying vec3 vWorldPosition;\nvarying float vLineLengthPixels;\nvarying float vSizeFalloffFactor;\nvarying float vLineIndex;\n\n// At which coverage threshold we discard a fragment completely\n#define COVERAGE_TEST_THRESHOLD 0.01\n\n#include <edgeRenderer/lineOffset.glsl>\n\nvec2 lineWithCapsDistance(float radius, vec2 position, float lineLength) {\n  float lineOffset = calculateLineOffset();\n  float positionX = position.x - lineOffset;\n\n  if (radius < 1.0) {\n    // Handle this specifically for subpixel sizes:\n    // 1. Compute correct coverage (note coverage is computed by\n    //    0.5 - dist, so we make sure that that will lead to correct\n    //    subpixel coverage\n    // 2. Ignore rounded caps\n    float coverageX = clamp(min(radius, positionX + 0.5) - max(-radius, positionX - 0.5), 0.0, 1.0);\n    float coverageY = clamp(min(lineLength, position.y + 0.5) - max(0.0, position.y - 0.5), 0.0, 1.0);\n\n    float coverage = min(coverageX, coverageY);\n\n    return vec2(0.5 - coverage, 0.0);\n  }\n  else {\n    // Between -radius -> 0 for start cap, 0 for line, 0 -> radius\n    float positionOnCap = position.y - clamp(position.y, 0.0, lineLength);\n\n    vec2 lineToPosition = vec2(positionX, positionOnCap);\n    return vec2(length(lineToPosition) - radius, positionOnCap / radius);\n  }\n}\n\nvoid main() {\n\n  float radius = vRadius * calculateLinePressure();\n\n  vec2 distance = lineWithCapsDistance(radius, vPosition.xy, vLineLengthPixels);\n  float coverage = clamp(0.5 - distance.x, 0.0, 1.0);\n\n#ifdef ANTIALIASING\n\n  const float coverageLimit = COVERAGE_TEST_THRESHOLD;\n\n#else /* ANTIALIASING */\n\n  // Use subpixel coverage computation when lines get subpixel widths\n  // so we still render them appropriately. Otherwise discard anything\n  // that is not fully within the line\n  float coverageLimit = radius <= 0.5 ? COVERAGE_TEST_THRESHOLD : 0.75;\n\n#endif /* ANTIALIASING */\n\n  if (coverage < coverageLimit) {\n    discard;\n  }\n\n  discardBySlice(vWorldPosition);\n\n  float alpha = vColor.a * coverage;\n\n  gl_FragColor = vec4(vColor.rgb, alpha);\n}\n","edgeRenderer.vert":"#include <util/vsPrecision.glsl>\n\n// Transformations\nuniform mat4 uProj;\nuniform mat4 uView;\nuniform mat4 uModel;\nuniform vec3 uCameraPosition;\n\n// Line configuration\n\n// Conversion constants\nuniform vec2 uPixelToNDC;\nuniform vec2 uNDCToPixel;\nuniform float uPixelRatio;\n\n// Inputs\nattribute vec3 aPosition0;\nattribute vec3 aPosition1;\nattribute float aVariantOffset;\nattribute float aVariantStroke;\nattribute float aVariantExtension;\n\n#ifdef SILHOUETTE\n\nattribute vec3 aNormalA;\nattribute vec3 aNormalB;\n\n#else /* SILHOUETTE */\n\nattribute vec3 aNormal;\n\n#endif /* SILHOUETTE */\n\nattribute vec2 aSideness;\nattribute vec2 aPackedAttributes;\n\nstruct UnpackedAttributes {\nvec2 sideness;\nvec2 sidenessNorm;\nfloat lineWidthPixels;\nfloat extensionLengthPixels;\n\n#if (MODE == MODE_UBER)\n\nfloat type;\n\n#endif\n};\n\n// Output required to compute color\nvarying vec4 vColor;\n\n// Output required to compute distance to line/caps\nvarying vec3 vPosition;\nvarying vec3 vWorldPosition;\nvarying float vRadius;\nvarying float vLineLengthPixels;\nvarying float vSizeFalloffFactor;\n\n#include <edgeRenderer/adjustProjectedPosition.glsl>\n#include <edgeRenderer/styleOutputs.glsl>\n#include <edgeRenderer/lineAmplitude.glsl>\n#include <edgeRenderer/util.glsl>\n\nvec4 calculateGeometricOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n  vec2 sideness = unpackedAttributes.sideness;\n  vec2 sidenessNorm = unpackedAttributes.sidenessNorm;\n\n  vWorldPosition = mix(worldPosV0, worldPosV1, sidenessNorm.y).xyz;\n\n  vec4 viewPos = mix(viewPosV0, viewPosV1, sidenessNorm.y);\n  vec4 projPosV0 = uProj * viewPosV0;\n  vec4 projPosV1 = uProj * viewPosV1;\n  vec4 projPos = uProj * viewPos;\n\n  vec3 screenSpaceLineNDC = (projPosV1.xyz / projPosV1.w - projPosV0.xyz / projPosV0.w);\n  vec2 screenSpaceLinePixels = screenSpaceLineNDC.xy * uNDCToPixel;\n  float lineLengthPixels = length(screenSpaceLinePixels);\n\n  float dzPerPixel = screenSpaceLineNDC.z / lineLengthPixels;\n  vec2 screenSpaceDirection = screenSpaceLinePixels / lineLengthPixels;\n  vec2 perpendicularScreenSpaceDirection = vec2(screenSpaceDirection.y, -screenSpaceDirection.x) * sideness.x;\n\n  float falloffFactor = distanceBasedPerspectiveFactor(-viewPos.z) * uPixelRatio;\n  float lineWidthPixels = unpackedAttributes.lineWidthPixels * falloffFactor;\n\n  float extensionLengthPixels = calculateExtensionLength(unpackedAttributes.extensionLengthPixels, lineLengthPixels) * falloffFactor;\n  float lineAmplitudePixels = calculateLineAmplitude(unpackedAttributes) * uPixelRatio;\n\n  vSizeFalloffFactor = falloffFactor;\n\n  float lineWidthAndAmplitudePixels = lineWidthPixels + lineAmplitudePixels + lineAmplitudePixels;\n  float extendedLineLengthPixels = lineLengthPixels + extensionLengthPixels + extensionLengthPixels;\n\n#ifdef ANTIALIASING\n\n  const float aaPaddingPixels = 1.0;\n\n  // Line size with padding\n  float halfAAPaddedLineWidthAndAmplitudePixels = lineWidthAndAmplitudePixels * 0.5 + aaPaddingPixels;\n  float aaPaddedRoundedCapSizePixels = lineWidthPixels * 0.5 + aaPaddingPixels;\n\n  // Line length with padding\n  float aaPaddedLineLengthPixels = extendedLineLengthPixels + aaPaddingPixels + aaPaddingPixels;\n  float halfAAPaddedLineLengthPixels = aaPaddedLineLengthPixels * 0.5;\n\n#else /* ANTIALIASING */\n\n  // Even if there is no AA, we still want to do proper <1px rendering,\n  // so we effectively clamp the pixel sizes to minimum of 1px and compute\n  // coverage in the fragment shader\n  float halfAAPaddedLineWidthAndAmplitudePixels = max(lineWidthAndAmplitudePixels, 1.0) * 0.5;\n  float aaPaddedRoundedCapSizePixels = max(lineWidthPixels, 1.0) * 0.5;\n\n  float halfAAPaddedLineLengthPixels = max(extendedLineLengthPixels, 1.0) * 0.5;\n\n#endif /* ANTIALIASING */\n\n  // Half line width in NDC including padding for anti aliasing\n  vec2 halfAAPaddedLineWidthAndAmplitudeNDC = halfAAPaddedLineWidthAndAmplitudePixels * uPixelToNDC;\n  vec2 aaPaddedRoundedCapSizeNDC = aaPaddedRoundedCapSizePixels * uPixelToNDC;\n  vec2 extensionLengthNDC = extensionLengthPixels * uPixelToNDC;\n\n  // Compute screen space position of vertex, offsetting for line size and end caps\n  vec2 ndcOffset = (\n      screenSpaceDirection * sideness.y * (aaPaddedRoundedCapSizeNDC + extensionLengthNDC)\n    + perpendicularScreenSpaceDirection * halfAAPaddedLineWidthAndAmplitudeNDC\n  );\n\n  projPos.xy += ndcOffset * projPos.w;\n  projPos.z += (dzPerPixel * (aaPaddedRoundedCapSizePixels + extensionLengthPixels)) * sideness.y * projPos.w;\n\n  projPos = adjustProjectedPosition(projPos, worldNormal, 1.0 + max((lineWidthAndAmplitudePixels - 1.0) * 0.5, 0.0));\n\n  // Line length with end caps\n  float aaPaddedLineWithCapsLengthPixels = extendedLineLengthPixels + aaPaddedRoundedCapSizePixels + aaPaddedRoundedCapSizePixels;\n\n  float pixelPositionAlongLine = aaPaddedLineWithCapsLengthPixels * sidenessNorm.y - aaPaddedRoundedCapSizePixels;\n\n  // Position in pixels with origin at first vertex of line segment\n  vPosition = vec3(\n    halfAAPaddedLineWidthAndAmplitudePixels * sideness.x,\n    pixelPositionAlongLine,\n    pixelPositionAlongLine / extendedLineLengthPixels\n  );\n\n  // The line width radius in pixels\n  vRadius = lineWidthPixels * 0.5;\n  vLineLengthPixels = extendedLineLengthPixels;\n\n#ifdef SILHOUETTE\n\n  gl_Position = isSilhouetteEdge(viewPosV0, aNormalA, aNormalB) ? projPos : vec4(10.0, 10.0, 10.0, 1.0);\n\n#else /* SILHOUETTE */\n\n  gl_Position = projPos;\n\n#endif /* SILHOUETTE */\n\n#if (MODE == MODE_UBER)\n\n  if (unpackedAttributes.type <= 0.0 && lineLengthPixels <= 3.0) {\n    gl_Position = vec4(10.0, 10.0, 10.0, 1.0);\n  }\n\n#elif (MODE == MODE_SKETCH)\n\n  if (lineLengthPixels <= 3.0) {\n    gl_Position = vec4(10.0, 10.0, 10.0, 1.0);\n  }\n\n#endif\n\n  return projPos;\n}\n\n#if (MODE == MODE_UBER)\n\nUnpackedAttributes unpackAttributes(ComponentData component) {\n\n  vec2 sidenessNorm = aSideness;\n  vec2 sideness = sidenessNorm * 2.0 - 1.0;\n\n  float fType = component.type;\n  float extensionLengthPixels = component.extensionLength;\n  float lineWidth = component.lineWidth;\n\n  if (fType <= 0.0) {\n    extensionLengthPixels *= aVariantExtension * 2.0 - 1.0;\n  }\n\n  return UnpackedAttributes(sideness, sidenessNorm, lineWidth, extensionLengthPixels, fType);\n}\n\n#else /* (MODE == MODE_UBER) */\n\nUnpackedAttributes unpackAttributes(ComponentData component) {\n  vec2 sidenessNorm = aSideness;\n  vec2 sideness = sidenessNorm * 2.0 - 1.0;\n  float extensionLengthPixels = component.extensionLength;\n\n#if (MODE == MODE_SKETCH)\n\n  extensionLengthPixels *= aVariantExtension * 2.0 - 1.0;\n\n#endif\n\n  float lineWidth = component.lineWidth;\n\n  return UnpackedAttributes(sideness, sidenessNorm, lineWidth, extensionLengthPixels);\n}\n\n#endif /* (MODE == MODE_UBER) */\n\nvoid main() {\n  ComponentData component = readComponentData();\n  UnpackedAttributes unpackedAttributes = unpackAttributes(component);\n\n  vec4 worldPosV0 = uModel * vec4(aPosition0, 1.0);\n  vec4 worldPosV1 = uModel * vec4(aPosition1, 1.0);\n\n  vec4 viewPosV0 = uView * worldPosV0;\n  vec4 viewPosV1 = uView * worldPosV1;\n\n#ifdef SILHOUETTE\n\n  vec3 worldNormal = silhouetteWorldNormal(aNormalA, aNormalB);\n\n#else /* SILHOUETTE */\n\n  vec3 worldNormal = modelToWorldNormal(aNormal);\n\n#endif /* SILHOUETTE */\n\n  // General geometric computation for all types of edges\n  vec4 projPos = calculateGeometricOutputs(viewPosV0, viewPosV1, worldPosV0, worldPosV1, worldNormal, unpackedAttributes);\n\n  // Component color\n  vColor = component.color;\n\n  // Specific computation for different edge styles\n  calculateStyleOutputs(viewPosV0, viewPosV1, worldPosV0, worldPosV1, projPos, worldNormal, unpackedAttributes);\n}\n","lineAmplitude.glsl":"// Solid\n\n#if (MODE == MODE_UBER || MODE == MODE_SOLID)\n\n  float calculateLineAmplitudeSolid() {\n    return 0.0;\n  }\n\n#endif\n\n#if (MODE == MODE_SOLID)\n\n  float calculateLineAmplitude(UnpackedAttributes unpackedAttributes) {\n    return calculateLineAmplitudeSolid();\n  }\n\n#endif\n\n// Sketch\n\n#if (MODE == MODE_UBER || MODE == MODE_SKETCH)\n\n  uniform float uStrokesAmplitude;\n\n  float calculateLineAmplitudeSketch() {\n    return uStrokesAmplitude;\n  }\n\n#endif\n\n#if (MODE == MODE_SKETCH)\n\n  float calculateLineAmplitude(UnpackedAttributes unpackedAttributes) {\n    return calculateLineAmplitudeSketch();\n  }\n\n#endif\n\n// Uber\n\n#if (MODE == MODE_UBER)\n\n  float calculateLineAmplitude(UnpackedAttributes unpackedAttributes) {\n    float type = unpackedAttributes.type;\n\n    if (type <= 0.0) {\n      return calculateLineAmplitudeSketch();\n    }\n    else {\n      return calculateLineAmplitudeSolid();\n    }\n  }\n\n#endif\n","lineOffset.glsl":"#include <util/encoding.glsl>\n\n// Sketch\n\n#if (MODE == MODE_UBER || MODE == MODE_SKETCH)\n\n  uniform sampler2D uStrokesTexture;\n  uniform float uStrokesNormalizationScale;\n\n  varying vec2 vStrokeUV;\n\n  float calculateLineOffsetSketch() {\n    float offsetNorm = rgba2float(texture2D(uStrokesTexture, vStrokeUV));\n    return (offsetNorm - 0.5) * uStrokesNormalizationScale;\n  }\n\n  float calculateLinePressureSketch() {\n    return rgba2float(texture2D(uStrokesTexture, vStrokeUV + vec2(0.0, 0.5)));\n  }\n\n#endif\n\n#if (MODE == MODE_SKETCH)\n\n  float calculateLineOffset() {\n    return calculateLineOffsetSketch();\n  }\n\n  float calculateLinePressure() {\n    return calculateLinePressureSketch();\n  }\n\n#endif\n\n// Solid\n\n#if (MODE == MODE_UBER || MODE == MODE_SOLID)\n\n  float calculateLineOffsetSolid() {\n    return 0.0;\n  }\n\n  float calculateLinePressureSolid() {\n    return 1.0;\n  }\n\n#endif\n\n#if (MODE == MODE_SOLID)\n\n  float calculateLineOffset() {\n    return calculateLineOffsetSolid();\n  }\n\n  float calculateLinePressure() {\n    return calculateLinePressureSolid();\n  }\n\n#endif\n\n// Uber\n\n#if (MODE == MODE_UBER)\n  varying float vType;\n\n  float calculateLineOffset() {\n    if (vType <= 0.0) {\n      return calculateLineOffsetSketch();\n    }\n    else {\n      return calculateLineOffsetSolid();\n    }\n  }\n\n  float calculateLinePressure() {\n    if (vType <= 0.0) {\n      return calculateLinePressureSketch();\n    }\n    else {\n      return calculateLinePressureSolid();\n    }\n  }\n#endif\n","styleOutputs.glsl":"#if (MODE == MODE_UBER || MODE == MODE_SKETCH)\n\n  uniform vec2 uStrokesTextureScale;\n  uniform float uStrokesLog2Resolution;\n  uniform float uStrokeVariants;\n\n  varying vec2 vStrokeUV;\n  varying float vLineIndex;\n\n  void calculateStyleOutputsSketch(float lineLength, UnpackedAttributes unpackedAttributes) {\n    vec2 sidenessNorm = unpackedAttributes.sidenessNorm;\n\n    float lineIndex = clamp(ceil(log2(lineLength)), 0.0, uStrokesLog2Resolution);\n\n    vStrokeUV = vec2(exp2(lineIndex) * sidenessNorm.y, lineIndex * uStrokeVariants + aVariantStroke + 0.5) * uStrokesTextureScale;\n    vStrokeUV.x += aVariantOffset;\n\n    vLineIndex = lineIndex;\n  }\n#endif\n\n#if (MODE == MODE_SOLID)\n  void calculateStyleOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec4 projPos, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n  }\n#elif (MODE == MODE_SKETCH)\n  void calculateStyleOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec4 projPos, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n    calculateStyleOutputsSketch(vLineLengthPixels, unpackedAttributes);\n  }\n#elif (MODE == MODE_UBER)\n  varying float vType;\n\n  void calculateStyleOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec4 projPos, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n    vType = unpackedAttributes.type;\n\n    if (unpackedAttributes.type <= 0.0) {\n      calculateStyleOutputsSketch(vLineLengthPixels, unpackedAttributes);\n    }\n  }\n#endif\n","util.glsl":"uniform float uDistanceFalloffFactor;\n\nfloat distanceBasedPerspectiveFactor(float distance) {\n  return clamp(sqrt(uDistanceFalloffFactor / distance), 0.0, 1.0);\n}\n\nuniform sampler2D uComponentDataTex;\nuniform vec2 uComponentDataTexInvDim;\n\nattribute float aComponentIndex;\n\n#define COMPONENT_COLOR_FIELD_OFFSET 0.0\n#define COMPONENT_OTHER_FIELDS_OFFSET 1.0\n#define COMPONENT_FIELD_COUNT 2.0\n\n#define LINE_WIDTH_FRACTION_FACTOR 8.0\n#define EXTENSION_LENGTH_OFFSET 128.0\n\n#define COMPONENT_TEX_WIDTH 4096.0\n\nvec2 componentTextureCoords(float componentIndex, float fieldOffset) {\n  float fieldIndex = COMPONENT_FIELD_COUNT * componentIndex + fieldOffset;\n\n  float rowIndex = floor(fieldIndex / COMPONENT_TEX_WIDTH);\n  float colIndex = mod(fieldIndex, COMPONENT_TEX_WIDTH);\n\n  vec2 linearIndex = vec2(\n    (colIndex + 0.5) / COMPONENT_TEX_WIDTH,\n    (rowIndex + 0.5) * uComponentDataTexInvDim.y\n  );\n\n  return linearIndex;\n}\n\nstruct ComponentData {\n  vec4 color;\n  float lineWidth;\n  float extensionLength;\n  float type;\n};\n\nComponentData readComponentData() {\n  vec2 colorIndex = componentTextureCoords(aComponentIndex, COMPONENT_COLOR_FIELD_OFFSET);\n  vec2 otherIndex = componentTextureCoords(aComponentIndex, COMPONENT_OTHER_FIELDS_OFFSET);\n\n  vec4 colorValue = texture2D(uComponentDataTex, colorIndex);\n  vec4 otherValue = texture2D(uComponentDataTex, otherIndex);\n\n  return ComponentData(\n    vec4(colorValue.rgb, colorValue.a * otherValue.w), // otherValue.w stores separate opacity\n    otherValue.x * (255.0 / LINE_WIDTH_FRACTION_FACTOR),\n    otherValue.y * 255.0 - EXTENSION_LENGTH_OFFSET,\n    -(otherValue.z * 255.0) + 0.5 // SOLID (=0/255) needs to be > 0.0, SKETCHY (=1/255) needs to be <= 0;\n  );\n}\n\nvec3 modelToWorldNormal(vec3 normal) {\n  return (uModel * vec4(normal, 0.0)).xyz;\n}\n\nvec3 silhouetteWorldNormal(vec3 normalA, vec3 normalB) {\n  return modelToWorldNormal(normalize(normalA + normalB));\n}\n\n// Fall-off extension length for shorter strokes, starting from strokes that are 256 size,\n// fall-off exponentially\nfloat calculateExtensionLength(float extensionLength, float lineLength) {\n  return extensionLength / (log2(max(1.0, 256.0 / lineLength)) * 0.2 + 1.0);\n}\n\n#ifdef SILHOUETTE\n\n// #uniforms: uView, uModel\nbool isSilhouetteEdge(vec4 viewPos, vec3 normalA, vec3 normalB) {\n  // transform the two face normals\n  vec3 viewNormalA = (uView * uModel * vec4(normalA, 0.0)).xyz;\n  vec3 viewNormalB = (uView * uModel * vec4(normalB, 0.0)).xyz;\n\n  // compute the direction from the edge to the camera\n  vec3 viewDir = -viewPos.xyz;\n\n  // check which of the two faces are visible\n  // display the edge if exactly one of the two is visible\n  float faceAVisible = dot(viewDir, viewNormalA); // positive if visible\n  float faceBVisible = dot(viewDir, viewNormalB); // positive if visible\n\n  // 1 if exactly one face visible, 0 otherwise\n  return faceAVisible * faceBVisible < 0.0;\n}\n\n#endif /* SILHOUETTE */\n"},environment:{"realisticAtmosphere.frag":"#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/color.glsl>\n\n// Light\nuniform vec3 v3LightDir;      // The direction vector to the light source\nuniform vec3 v3InvWavelength; // 1 / pow(wavelength, 4) for the red, green, and blue channels\nuniform vec3 v3InvWavelengthScaled; //v3InvWavelength * fKr4PI + fKm4PI\n\n// Atmosphere\nconst float fKrESun = 0.075;        // Kr * ESun = 0.005 * 15.0\nconst float fKmESun = 0.015;        // Km * ESun = 0.005 * 15\n\n// Radii\nuniform vec4 v4Radii; // (fInnerRadius, fInnerRadius^2, fOuterRadius, fOuterRadius^2)\n\n// The inner (planetary) radius\n#define fInnerRadius v4Radii[0]\n// fInnerRadius^2\n#define fInnerRadius2 v4Radii[1]\n// The outer (atmosphere) radius\n#define fOuterRadius v4Radii[2]\n// fOuterRadius^2\n#define fOuterRadius2 v4Radii[3]\n\n// Atmosphere parameters:\n// fScale:                    1.0 / (fOuterRadius - fInnerRadius)\n// fScaleDepth:               The scale depth (i.e. the altitude at which the atmosphere's average density is found)\n// fScaleOverScaleDepth:      fScale / fScaleDepth\n// fOneOverScaleDepth:        1.0 / fScaleDepth\n\n// fScaleDepthBlue:           The scale depth (i.e. the altitude at which the atmosphere's average density is found)\n// fScaleOverScaleDepthBlue:  fScale / fScaleDepthBlue\n// fOneOverScaleDepthBlue;    1.0 / fScaleDepthBlue\n\nuniform vec4 v4AtmosParams1; // (fScale, fScaleDepth, fScaleOverScaleDepth, fOneOverScaleDepth)\nuniform vec4 v4AtmosParams2; // (g, fScaleDepthBlue, fScaleOverScaleDepthBlue, fOneOverScaleDepthBlue)\n\n#define fScale v4AtmosParams1.x\n// fScaleDepth, fScaleDepthBlue\n#define v2ScaleDepth vec2(v4AtmosParams1.y,v4AtmosParams2.y)\n// fScaleOverScaleDepth, fScaleOverScaleDepthBlue\n#define v2ScaleOverScaleDepth vec2(v4AtmosParams1.z,v4AtmosParams2.z)\n// fOneOverScaleDepth, fOneOverScaleDepthBlue\n#define v2OneOverScaleDepth vec2(v4AtmosParams1.w,v4AtmosParams2.w)\n\n#ifndef HAZE\nuniform vec4 v4AtmosParams3; // (g2, fMiePhaseCoefficients, fLowerAlphaBlendBound, fOneOverOuterRadiusMinusAlphaBlendBound)\nuniform float fInnerFadeDistance;\nuniform float fAltitudeFade;\n\n#define fg v4AtmosParams2.x\n#define fg2 v4AtmosParams3.x\n#define fMiePhaseCoefficients v4AtmosParams3.y\n#define fLowerAlphaBlendBound v4AtmosParams3.z\n#define fOneOverOuterRadiusMinusAlphaBlendBound v4AtmosParams3.w\n#endif\n\n// Camera\nuniform vec3 v3CameraPos;     // The camera's current position\nuniform vec2 nearFar;\n\nuniform vec4 v4SphereComp;              // (fCameraHeight, fCameraHeight2, fC, fCSur)\n// The camera's current height\n#define fCameraHeight v4SphereComp[0]\n// fCameraHeight^2\n#define fCameraHeight2 v4SphereComp[1]\n// fCameraHeight2 - fOuterRadius2; // C = ||o-c||^2 - r^2\n#define fC v4SphereComp[2]\n// fCameraHeight2 - (fInnerRadius2 - 63756370000.0); // C = ||o-c||^2 - r^2\n#define fCSur v4SphereComp[3]\n\n// Camera HDR\n#ifdef HAZE\nconst float fExposure = 1.5;\n#else\nconst float fExposure = 2.0;\n#endif\n\n#ifdef HAZE\n// Depth texture\nuniform sampler2D tDepth;\n#endif\n\n// Testing variables\nuniform float showTest;\n\n// Varyings\nvarying vec3 v3EyeDir;\nvarying vec3 v3WorldRay;\nvarying vec2 vtc;\n\n// Loop constants for integral approximation\nconst float fSamples = 5.0;\nconst int maxSamples = 5;\n\n#ifdef HAZE\n  const float fOneOverGamma = 1.0;//Gamma = 1.0\n#else\n  const float fOneOverGamma = 0.454545; // Gamma = 2.2\n#endif\n\nconst vec3 v3OneOverGamma = vec3(fOneOverGamma);\n\n// ToneMapping operators\nvec3 expTM(vec3 inputColor,float exposure){\n    return pow(1.0 - exp(inputColor * -exposure), v3OneOverGamma);\n}\n\n#ifndef HAZE\nvec3 reinhardTM(vec3 inputColor, float exposure){\n  vec3 intermediate = inputColor *exposure;\n  intermediate /= (1.0+intermediate);\n  return pow(intermediate, v3OneOverGamma);\n}\n#endif\n\n// Approximation for inner integral based on a radii ratio of 10.25:10\nfloat scale(float fCos){\n  float x = 1.0 - fCos;\n  return exp(-0.00287 + x*(0.459 + x*(3.83 + x*(-6.80 + x*5.25))));\n}\n\nvoid main() {\n  vec3 cameraPosition = v3CameraPos;\n\n  // Debug variables\n  vec3 test = vec3(0.0,0.0,0.0);\n\n  // Obtain ray from Camera\n  vec3 worldSpaceRay = normalize(v3WorldRay);\n\n  // Compute Atmosphere intersection; i.e. ray/sphere intersection\n  float B = 2.0 * dot(cameraPosition, worldSpaceRay); // B = 2(l * (o-c))\n  float det = B*B - 4.0 * fC; // det = B^2 - 4.0* C\n\n  // idealized sphere intersection to discard early some pixels\n  float detSur = B*B - 4.0 * fCSur; // det = B^2 - 4.0* C\n\n  // the minimal sample start position:\n  // at the camera by default, on the earth radius surface if the camera is underground.\n  float fMinRayStart = 0.0;\n#ifndef HAZE\n  // When the ray intersects the earth surface, fade the sky to a simple light direction\n  // based color. This is used to make sure we have a white background in underground\n  // mode (at noon).\n  float fSurfaceBlend = 0.0;\n  vec4 surfaceColor = vec4(0.0);\n  if (detSur >= 0.0) {\n    float nearSurfaceT = max(0.0, 0.5 *(-B - sqrt(detSur)));\n    float farSurfaceT = max(0.0, 0.5 *(-B + sqrt(detSur)));\n\n    if (nearSurfaceT == 0.0) {\n      fMinRayStart = farSurfaceT;\n    }\n\n    // Compute lighting at the point where the ray enters the earth surface\n    // Lighting computation is copied from the terrain shader.\n    vec3 vPos = cameraPosition + worldSpaceRay * nearSurfaceT;\n    float fLightAngle = dot(v3LightDir, normalize(vPos));\n    float fBrightness = max(0.0, (smoothstep(-1.0, 0.8, 2.0 * fLightAngle)));\n\n    // Make the surface transparent based on altitude\n    surfaceColor = vec4(fBrightness, fBrightness, fBrightness, 1.0 - fAltitudeFade);\n\n    // Fade based on the distance the ray travels below the earth surface\n    float fRelDist = (farSurfaceT - nearSurfaceT) / fInnerFadeDistance;\n\n    // early exit\n    if (fRelDist > 1.0) {\n      gl_FragColor = surfaceColor;\n      return;\n    }\n\n    fSurfaceBlend = smoothstep(0.0, 1.0, fRelDist * fRelDist);\n  }\n#endif\n\n  // Inside Atmosphere\n  if (det >= 0.0) {\n#ifdef HAZE\n    // only use red channel from depth texture.\n    // see 'Issues' at https://www.khronos.org/registry/webgl/extensions/WEBGL_depth_texture\n    float depthSample = texture2D(tDepth, vtc).r;\n\n    float zNear = nearFar[0];\n    float zFar = nearFar[1];\n\n    // http://web.archive.org/web/20130416194336/http://olivers.posterous.com/linear-depth-in-glsl-for-real\n    float zNorm = 2.0 * depthSample - 1.0;\n    float linDepth = 2.0 * zNear * zFar /\n      (zFar + zNear - zNorm * (zFar - zNear));\n\n    float rayEndT;\n    float altitudeAlpha = 1.0;\n\n    // find intersections with ground, but only between the near and far\n    // clipping planes.\n    if (depthSample < 1.0 && depthSample > 0.0) {\n      vec3 cameraSpaceRay = normalize(v3EyeDir);\n      cameraSpaceRay /= cameraSpaceRay.z;\n      cameraSpaceRay *= linDepth;\n\n      float cameraSpaceRayLength = length(cameraSpaceRay);\n\n      vec3 v3World = cameraPosition + worldSpaceRay * cameraSpaceRayLength;\n      float v3WorldRadius2 = dot(v3World, v3World);\n\n      // Handle tall structures:\n      // https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/5450\n      float transitionStart = fInnerRadius + 20000.0;\n      float transitionHeight = 25000.0;\n      float transitionEnd = transitionStart + transitionHeight;\n\n      float edge0 = transitionStart * transitionStart;\n      float edge1 = transitionEnd * transitionEnd;\n\n      altitudeAlpha = 1.0 - clamp((v3WorldRadius2 - edge0) / (edge1 - edge0), 0.0, 1.0);\n      rayEndT = cameraSpaceRayLength;\n\n      if (altitudeAlpha > 0.0 && detSur > 0.0) {\n        float nearSurfaceT = 0.5 *(-B - sqrt(detSur));\n        float interp = clamp(((fCameraHeight - fInnerRadius) - 2000000.0) / 6000000.0, 0.0, 1.0);\n        rayEndT = mix(cameraSpaceRayLength, nearSurfaceT, interp);\n      }\n    }\n#endif\n\n    float rayStartT = 0.5 *(-B - sqrt(det)); //near intersection with atmosphere\n#ifdef HAZE\n    float nearT = abs(rayStartT);\n    float farT = abs(rayEndT);\n#else\n    float rayEndT = 0.5 *(-B + sqrt(det)); //far intersection with atmosphere\n\n#endif\n\n    float fDistance; // calculate its scattering offset\n    // Calculate the ray's starting position\n    if (rayStartT < fMinRayStart)\n    { // ray starts from camera or inner radius sphere to far\n      rayStartT = fMinRayStart;\n#ifndef HAZE\n      // clamp to value at inner radius altitude\n      fDistance = fScale * min(0.0, fInnerRadius - fCameraHeight);\n#endif\n    }\n#ifndef HAZE\n    else\n    { // outside atmosphere\n      fDistance = -1.0;\n    }\n#endif\n\n    // Initialize the scattering loop variables\n    vec3 v3Start = cameraPosition + worldSpaceRay * rayStartT;\n\n#ifdef HAZE\n    vec3 v3End = cameraPosition + worldSpaceRay * rayEndT;\n\n    float fEndLength = length(v3End);\n    float fAltitudeEnd = fEndLength - fInnerRadius;\n    float fAltitudeStart = length(v3Start) - fInnerRadius;\n\n    // for camera positions below altitude 0, invert the altitudes, to achieve\n    // a similar haze as above ground. Note that there is a small but visible change\n    // when the camera passes altitude 0.\n    if (fAltitudeStart < 0.0) {\n      fAltitudeStart = -fAltitudeStart;\n      fAltitudeEnd = -fAltitudeEnd;\n    }\n\n    // computed for the original end point to get consistent light angles after possible inversions\n    float fLightAngle = dot(v3LightDir, v3End) / fEndLength;\n\n    if (nearT > farT)\n    {\n      if (fAltitudeStart < fAltitudeEnd)\n      {\n        // Switch positive slopes for flipped rays\n        v3End = cameraPosition + worldSpaceRay * rayStartT;\n        v3Start = cameraPosition + worldSpaceRay * rayEndT;\n        worldSpaceRay *= -1.0;\n        float fTmp = fAltitudeStart;\n        fAltitudeStart = fAltitudeEnd;\n        fAltitudeEnd = fTmp;\n      }\n      else if (fAltitudeStart == fAltitudeEnd)\n      { // create minuscule fake slope for integration if the slope is zero\n        fAltitudeStart += 1.0; //BUGFIX, if the height of camera and ground is equal the equation breaks, add fake meter to camera height to get\n        // slope for the camera function\n      }\n    }\n\n    // Calculate its scattering offset\n    // Assumes camera constrains of WSV 3.8\n    float fCameraDepth;\n    float fCameraDepthBlue;\n    if (fAltitudeStart > fOuterRadius - fInnerRadius)\n    { // outside atmosphere\n      fDistance = fInnerRadius - fOuterRadius;\n    } else\n    {\n      fDistance = fAltitudeEnd - fAltitudeStart;\n    }\n\n#endif\n    vec2 v2OpticalStartDepth = exp(fDistance * v2OneOverScaleDepth);\n\n    float fRayLength = rayEndT - rayStartT;\n    float fSampleLength = fRayLength / fSamples;\n    float fScaledLength = fSampleLength * fScale;\n    vec3 v3SampleRay = worldSpaceRay * fSampleLength;\n    vec3 v3SamplePoint = v3Start + v3SampleRay * 0.5;\n\n#ifdef HAZE\n    float fCameraAngle = dot(-worldSpaceRay, v3End) / length(v3End);\n    float fScaleCameraAngle = scale(fCameraAngle);\n    vec2 v2CameraOffset = fScaleCameraAngle*v2OpticalStartDepth;\n\n    float scaledValues = scale(fLightAngle) + fScaleCameraAngle;\n    vec2 v2ScaledValuesDepth = scaledValues * v2ScaleDepth;\n#else\n    float fCameraAngle = dot(worldSpaceRay, v3Start / length(v3Start));\n    float angleMultiplier = fCameraAngle>0.0?fCameraAngle:0.0;\n\n    float fScaleCameraAngle = scale(fCameraAngle);\n    vec2 v2CameraOffset = fScaleCameraAngle*v2OpticalStartDepth * v2ScaleDepth;\n#endif\n\n    // Loop variables\n    vec3 v3FrontColor = vec3(0.0, 0.0, 0.0);\n    vec3 v3FrontColorBlue = vec3(0.0, 0.0, 0.0);\n    vec3 v3Attenuate= vec3(0.0, 0.0, 0.0);\n    vec3 v3AttenuateBlue = vec3(0.0, 0.0, 0.0);\n\n    // Now loop through the sample rays\n    for(int i=0; i<maxSamples; i++) {\n      float fHeight = length(v3SamplePoint);\n      float fAltitude = abs(fHeight - fInnerRadius);\n\n      vec2 v2Depth = exp(-fAltitude * v2ScaleOverScaleDepth);\n#ifdef HAZE\n      vec2 v2Scatter = v2Depth*v2ScaledValuesDepth-v2CameraOffset;\n#else\n      float fLightAngle = dot(v3LightDir, v3SamplePoint) / fHeight;\n      float fCameraAngle = dot(worldSpaceRay, v3SamplePoint) / fHeight;\n      float fTempScaledValues = scale(fLightAngle) - scale(fCameraAngle);\n      vec2 v2Scatter = v2CameraOffset + fTempScaledValues*v2Depth* v2ScaleDepth;\n#endif\n      v3Attenuate = exp(-v2Scatter.x * v3InvWavelengthScaled);\n      v3AttenuateBlue = exp(-v2Scatter.y * v3InvWavelengthScaled);\n\n      v3FrontColor += v3Attenuate * v2Depth.x;\n      v3FrontColorBlue += v3AttenuateBlue * v2Depth.y;\n\n      v3SamplePoint += v3SampleRay;\n    }\n\n    // Phase computation\n    // clamp to avoid numerical instability at fCos == -1.0 (and close values) to display fake sun\n    float fCos = clamp(dot(v3LightDir, -worldSpaceRay ),-0.9999999,1.0);\n    float fOnePlusCos2 = fCos*fCos + 1.0;\n#ifdef HAZE\n    // Finally, scale the Rayleigh colors and set up the varying variables for the pixel shader\n    vec3 colorCoefficients = (fScaledLength* 0.75 * fOnePlusCos2)*(fKrESun*v3InvWavelength+fKmESun);\n\n    // Scaled Length is only applied afterwards to save multiplications\n    vec3 v3Color = colorCoefficients *v3FrontColor;\n    vec3 v3ColorBlue = colorCoefficients *v3FrontColorBlue;\n#else\n    vec3 v3RayleighCoefficients = (fScaledLength*0.75 * fOnePlusCos2*fKrESun)*v3InvWavelength;\n    float fMieCoefficients = fScaledLength*fKmESun * fMiePhaseCoefficients * fOnePlusCos2 / pow(1.0 + fg2 - 2.0*fg*fCos, 1.5);\n\n    // Calculate the attenuation factor for the ground\n    vec3 v3Color = v3RayleighCoefficients * v3FrontColor + fMieCoefficients * v3FrontColor;\n    vec3 v3ColorBlue = v3RayleighCoefficients * v3FrontColorBlue + fMieCoefficients * v3FrontColorBlue;\n#endif\n\n    // HDR to LDR conversion\n    vec3 ldrBlue = expTM(v3ColorBlue,2.0*fExposure);\n    vec3 ldrRed = expTM(v3Color,fExposure);\n\n    // mix reddish and blueish atmosphere\n    vec3 LDR = mix(ldrBlue,ldrRed,0.2);\n#ifdef HAZE\n    LDR *= (1.0-fCameraAngle);\n    vec3 hsv = rgb2hsv(LDR);\n    hsv.y = clamp(hsv.y*1.5,0.0,1.0); // boost haze saturation by 50%\n    LDR = hsv2rgb(hsv);\n    vec3 finalColor = LDR;\n    // when rendering we specify the blend functions such that\n    // newDestColor = oldDestColor*(1.0-finalColor) + finalColor\n#else\n    // reinhard tonemapper for looking upwards\n    vec3 ldrReinhard = reinhardTM(v3Color,fExposure);\n    LDR += angleMultiplier*ldrReinhard;\n\n    // height dependent parameter to smooth out reddish atmosphere\n    float side = (rayEndT+rayStartT)*0.5;\n    float atmoHeight = sqrt(fCameraHeight2 - side*side);\n    float h2 = clamp(1.0-(atmoHeight-fLowerAlphaBlendBound)/(fOuterRadius-fLowerAlphaBlendBound),0.0,1.0);\n\n    vec3 finalColor = LDR*h2;\n    vec3 hsv = rgb2hsv(finalColor);\n    hsv.y = clamp(hsv.y*1.5,0.0,1.0); // boost sky saturation by 50%\n    finalColor = hsv2rgb(hsv);\n#endif\n\n#ifndef HAZE\n    float atmosStrength = clamp((length(ldrRed)-0.05)*1.05,0.0,1.0);\n    gl_FragColor = vec4(finalColor, atmosStrength*clamp(1.0-(atmoHeight-fInnerRadius)/(fOuterRadius-fInnerRadius),0.0,1.0));\n    if (fSurfaceBlend > 0.0) {\n      gl_FragColor = mix(gl_FragColor, surfaceColor, fSurfaceBlend);\n    }\n#else\n    gl_FragColor = vec4(finalColor, 1.0) * altitudeAlpha;\n#endif\n\n    // Debug variable overlay\n    if(showTest>0.0){\n      gl_FragColor = vec4(test,1.0);\n    }\n  } else { // Outside Atmosphere\n    gl_FragColor = vec4(0.0);\n  }\n}\n","realisticAtmosphere.vert":"#include <util/vsPrecision.glsl>\n\n// Camera\nuniform vec2 halfSizeNearPlane;\nuniform vec3 v3CameraUp;\nuniform vec3 v3CameraRight;\nuniform vec3 v3CameraDir;\nuniform vec2 v2CameraCenterOffset;\n\n// Attributes\nattribute vec3 position;\nattribute vec2 uv0;\n\n// Varyings\nvarying vec3 v3WorldRay;\nvarying vec2 vtc;\n\n#ifdef HAZE\nvarying vec3 v3EyeDir;\n#endif\n\nvoid main(void) {\n  vec3 v3Pos = position;\n  vtc = uv0;\n  vec2 rayvtc = uv0 - v2CameraCenterOffset;\n\n#ifdef HAZE\n  v3EyeDir = vec3((2.0*halfSizeNearPlane *rayvtc)-halfSizeNearPlane,-1.0);\n#else\n  vec3 v3EyeDir = vec3((2.0*halfSizeNearPlane *rayvtc)-halfSizeNearPlane,-1.0);\n#endif\n  v3WorldRay = v3EyeDir.z*v3CameraDir + v3EyeDir.y*v3CameraUp + v3EyeDir.x*v3CameraRight;\n  gl_Position = vec4(v3Pos, 1.0);\n}\n","simpleAtmosphere.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\n\nvarying vec2 vtc;\nvarying float falloff;\n\n#ifndef PANORAMIC\nuniform float altitudeFade;\nvarying float innerFactor;\n#endif\n\nvoid main() {\n  vec4 texColor = texture2D(tex, vtc);\n\n#ifdef PANORAMIC\n  gl_FragColor = texColor * falloff;\n#else\n  vec4 atmosphereColor = texColor * falloff;\n  vec4 innerColor = vec4(texColor.rgb * falloff, 1.0 - altitudeFade);\n  gl_FragColor = mix(atmosphereColor, innerColor, smoothstep(0.0, 1.0, innerFactor));\n#endif\n}\n","simpleAtmosphere.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\n\n#ifndef PANORAMIC\nconst float TWICEPI = 2.0*3.14159265;\nconst float ATMOSPHERE_RIM_SEGMENTS = 128.0;\n\nuniform vec3 silCircleCenter;\nuniform vec3 silCircleV1;\nuniform vec3 silCircleV2;\nuniform vec2 texV;\n\nuniform float innerScale;  // scale for inner rim\nvarying float innerFactor; // 0: outer atmosphere, 1: inner atmosphere\n#endif\n\nuniform vec3 lightDirection;\n\nattribute vec3 position;\nvarying vec2 vtc;\nvarying float falloff;\n\nvoid main(void) {\n\n#ifdef PANORAMIC\n\n  vec3 pos = position;\n  float ndotl = lightDirection.z;\n  vtc = vec2(0.0, position.z+0.05);\n\n#else\n\n  innerFactor = clamp(-position.z, 0.0, 1.0);\n  float scale = position.y * (1.0 + innerFactor * innerScale);\n  float phi = position.x * (TWICEPI / ATMOSPHERE_RIM_SEGMENTS) + 1.0;\n  vec3 pos =  (silCircleCenter + sin(phi) * silCircleV1 + cos(phi) * silCircleV2) * scale;\n  float ndotl = dot(normalize(position.y > 0.0 ? pos: silCircleCenter), lightDirection);\n\n  vtc.x = position.x / ATMOSPHERE_RIM_SEGMENTS;\n  vtc.y = texV.x * (1.0 - position.z) + texV.y * position.z;\n\n#endif\n\n  falloff = max(0.0, smoothstep(-1.0, 0.8, 2.0 * ndotl));\n\n  gl_Position = proj * view * vec4(pos, 1.0);\n  gl_Position.z = gl_Position.w; // project atmosphere onto the far plane\n}\n","simpleAtmosphereFade.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec4 color;\n\nvoid main() {\n  gl_FragColor = color;\n}\n","simpleAtmosphereFade.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\n\nuniform vec3 lightDirection;\nuniform vec3 cameraPosition;\n\nuniform float undergroundFadeAlpha;\n\nvarying vec4 color;\n\nvoid main(void) {\n  float ndotl = dot(normalize(cameraPosition), lightDirection);\n  float lighting = max(0.0, smoothstep(-1.0, 0.8, 2.0 * ndotl));\n\n  color = vec4(vec3(lighting), undergroundFadeAlpha);\n\n  gl_Position = vec4(position.xy, 1.0, 1.0); // on the far plane\n}\n","stars.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec4 vcolor;\nvarying float vsize;\n\nvoid main() {\n  float cap = 0.7;\n  float scale = 1.0/cap;\n  float helper = clamp(length(abs(gl_PointCoord-vec2(0.5))),0.0,cap);\n  float alpha = clamp((cap-helper)*scale,0.0,1.0);\n  float intensity = alpha*alpha*alpha;\n  if (vsize < 3.0)\n    intensity *= 0.5;\n  gl_FragColor = vec4(1.0,1.0,1.0,intensity);\n  gl_FragColor.xyz *= vcolor.xyz;\n}\n","stars.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\nuniform vec4 viewport;\nuniform float pixelRatio;\n\nattribute vec3 position;\nattribute vec4 color;\nattribute float size;\n\nvarying vec4 vcolor;\nvarying float vsize;\n\nvoid main(void) {\n  vec4 posProj = proj * view * model*vec4(position*1.0e25,1.0);//move infinitely far away\n  gl_Position = alignToPixelCenter(posProj, viewport.zw); //pixel align position\n  gl_Position.z = gl_Position.w; // project atmosphere onto the far plane\n  vcolor = color / 1.2;\n  vsize = size * 5.0 * pixelRatio;\n  gl_PointSize = vsize;\n}\n"},materials:{checkerBoard:{"checkerBoard.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n\nuniform vec2 size;\nuniform vec4 color1;\nuniform vec4 color2;\n\nvarying vec2 vUV;\n\nvoid main() {\n  vec2 uvScaled = vUV / (2.0 * size);\n\n  vec2 uv = fract(uvScaled - 0.25);\n  vec2 ab = clamp((abs(uv - 0.5) - 0.25) / fwidth(uvScaled), -0.5, 0.5);\n  float fade = smoothstep(0.25, 0.5, max(fwidth(uvScaled.x), fwidth(uvScaled.y)));\n  float t = mix(abs(ab.x + ab.y), 0.5, fade);\n\n  gl_FragColor = mix(color2, color1, t);\n}\n","checkerBoard.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vUV = uv0;\n  gl_Position = proj * view * vec4((model * vec4(position, 1.0)).xyz, 1.0);\n}\n"},color:{"color.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nuniform vec4 eColor;\n#ifdef VERTEX_COLORS\nvarying vec4 vColor;\n#endif\n\nvarying vec3 vpos;\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef VERTEX_COLORS\n  gl_FragColor = vColor * eColor;\n#else\n  gl_FragColor = eColor;\n#endif\n\n  gl_FragColor = highlightSlice(gl_FragColor, vpos);\n}\n","color.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\n#ifdef VERTEX_COLORS\nattribute vec4 color;\n\nvarying vec4 vColor;\n#endif\n\nvarying vec3 vpos;\n\nvoid main(void) {\n#ifdef VERTEX_COLORS\n  vColor = color * 0.003921568627451; // = 1/255;\n#endif\n  vpos = (model * vec4(position, 1.0)).xyz;\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n}\n"},defaultMaterial:{"colorMixMode.glsl":"#include <util/color.glsl>\n\n/*\n * The color mix modes are encoded in the symbol color as follows:\n *  - Fully transparent symbols are represented with alpha 0 for\n *    all color mix modes (except ignore).\n *  - color mix mode ignore is encoded as multiply with white\n *  - the other 3 color mix modes (tint, replace, multiply) are\n *    equally distributed on the remaining 255 alpha values, which\n *    gives us 85 possible alpha values\n *\n * alpha             0 : fully transparent\n * alpha in [  1 -  85]: tint\n * alpha in [ 86 - 170]: replace\n * alpha in [171 - 255]: multiply\n * \n */\nvec4 decodeSymbolColor(vec4 symbolColor, out int colorMixMode) {\n  float symbolAlpha = 0.0;\n\n  const float maxTint = 85.0;\n  const float maxReplace = 170.0;\n  const float scaleAlpha = 3.0;\n\n  if (symbolColor.a > maxReplace) {\n    colorMixMode = 1;  // multiply\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxReplace);\n  } else if (symbolColor.a > maxTint) {\n    colorMixMode = 3; // replace\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxTint);\n  } else if (symbolColor.a > 0.0) {\n    colorMixMode = 0; // tint\n    symbolAlpha = scaleAlpha * symbolColor.a;\n  } else {\n    colorMixMode = 1; // fully transparent -> multiply\n    symbolAlpha = 0.0;\n  }\n\n  return vec4(symbolColor.r, symbolColor.g, symbolColor.b, symbolAlpha);\n}\n\nvec3 mixExternalColor(vec3 internalColor, vec3 textureColor, vec3 externalColor, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  vec3 internalMixed = internalColor * textureColor;\n  vec3 allMixed = internalMixed * externalColor;\n\n  if (mode == 1 /* multiply */) {\n    return allMixed;\n  }\n  else if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalColor;\n  }\n  else {\n    // tint (or something invalid)\n    vec3 hsvIn = rgb2hsv(internalMixed);\n    vec3 hsvTint = rgb2hsv(externalColor);\n    vec3 hsvOut = vec3(hsvTint.x, hsvTint.y, hsvIn.z * hsvTint.z);\n    return hsv2rgb(hsvOut);\n  }\n}\n\nfloat mixExternalOpacity(float internalOpacity, float textureOpacity, float externalOpacity, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  float internalMixed = internalOpacity * textureOpacity;\n  float allMixed = internalMixed * externalOpacity;\n\n  if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalOpacity;\n  }\n  else {\n    // multiply or tint (or something invalid)\n    return allMixed;\n  }\n}\n","colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/sceneLighting.glsl>\n\n#ifdef TEXTURING\n#include <materials/defaultMaterial/texturingInputs.glsl>\n#endif\n\n#define FRAGMENT_SHADER\n#include <materials/defaultMaterial/vertexTangents.glsl>\n#include <materials/defaultMaterial/textureNormals.glsl>\n\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\n// material parameters\n//////////////////////////////////////////\nuniform vec3 ambient;\nuniform vec3 diffuse;\nuniform vec3 specular;\nuniform float opacity;\nuniform float layerOpacity;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#else\nuniform int colorMixMode;\n#endif\n\n#ifdef RECEIVE_SHADOWS\nuniform sampler2D depthTex;\nuniform int shadowMapNum;\nuniform vec4 shadowMapDistance;\nuniform mat4 shadowMapMatrix[4];\nuniform float depthHalfPixelSz;\n#endif\n\n#ifdef RECEIVE_SSAO\nuniform sampler2D ssaoTex;\nuniform vec4 viewportPixelSz;\n#endif\n\nvarying vec3 vpos;\n\n#if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n  varying vec3 vnormal;\n#endif\n\n#if defined(VERTEXCOLORS)\nvarying vec4 vcolor;\n#endif\nvarying vec4 vcolorExt;\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#include <util/shadow.glsl>\n#endif\n\n#ifdef TREE_RENDERING\n  uniform mat4 view;\n#endif\n\n#ifdef TEXTURING\n#include <materials/defaultMaterial/texturing.glsl>\n#endif\n\n#include <materials/defaultMaterial/colorMixMode.glsl>\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  vec4 texColor = textureLookup(tex, vtc);\n\n  #if defined(TEXTURE_ALPHA_PREMULTIPLIED)\n    texColor.rgb /= texColor.a;\n  #endif\n\n  discardOrAdjustTextureAlpha(texColor);\n#else /* TEXTURING */\n  vec4 texColor = vec4(1.0);\n#endif /* TEXTURING */\n\n  vec3 viewDir = vpos - camPos;\n\n  // compute normal\n  // TODO: this is not in sync with the normal pass\n#ifdef GROUND_NORMAL_SHADING\n  #if VIEWING_MODE == VIEWING_MODE_GLOBAL\n    vec3 normal = normalize(vpos + localOrigin);\n  #else\n    vec3 normal = vec3(0.0, 0.0, 1.0);\n  #endif\n#else\n  #if (NORMALS == NORMALS_SCREEN_DERIVATIVE)\n    vec3 normal = normalize(cross(dFdx(vpos),dFdy(vpos)));\n  #else\n    #ifdef DOUBLESIDED\n      vec3 normal = dot(vnormal, viewDir)>0.0 ? -vnormal : vnormal;\n    #elif defined(WINDINGORDERDOUBLESIDED)\n      vec3 normal = gl_FrontFacing ? vnormal : -vnormal;\n    #else\n      vec3 normal = vnormal;\n    #endif\n    normal = normalize(normal);\n  #endif\n#endif\n\n  // compute ssao\n#ifdef RECEIVE_SSAO\n  float ssao = texture2D(ssaoTex, (gl_FragCoord.xy - viewportPixelSz.xy) * viewportPixelSz.zw).a;\n  ssao = viewportPixelSz.z < 0.0 ? 1.0 : ssao;\n#else\n  float ssao = 1.0;\n#endif\n\n  // At global scale we create some additional ambient light based on the main light to simulate global illumination\n  float additionalAmbientScale;\n  vec3 additionalLight = sceneLightingAdditionalLightGlobal(vpos + localOrigin, ssao, additionalAmbientScale);\n\n  // compute shadowing\n  float shadow = 0.0;\n#ifdef RECEIVE_SHADOWS\n  shadow = evalShadow(vpos, linearDepth, depthTex, shadowMapNum, shadowMapDistance, shadowMapMatrix, depthHalfPixelSz);\n#elif VIEWING_MODE == VIEWING_MODE_GLOBAL\n  // at global scale (and in global scenes) we fall back to this approximation\n  // to shadow objects on the dark side of the earth\n  shadow = lightingGlobalFactor * (1.0 - additionalAmbientScale);\n#endif\n\n  vec3 matColor = max(ambient, diffuse); // combine the old material parameters into a single one\n#if defined(VERTEXCOLORS)\n  // Internal colors: varying vcolor + uniform ambient/diffuse, external colors: varying vcolorExt\n  vec3 albedo_ = mixExternalColor(vcolor.rgb * matColor, texColor.rgb, vcolorExt.rgb, int(colorMixMode));\n  float opacity_ = layerOpacity * mixExternalOpacity(vcolor.a * opacity, texColor.a, vcolorExt.a, int(colorMixMode));\n#else\n  // Internal colors: uniform ambient/diffuse, external colors: varying vcolorExt\n  vec3 albedo_ = mixExternalColor(matColor, texColor.rgb, vcolorExt.rgb, int(colorMixMode));\n  float opacity_ = layerOpacity * mixExternalOpacity(opacity, texColor.a, vcolorExt.a, int(colorMixMode));\n#endif\n  albedo_+= 0.25 * specular; // don't completely ignore specular for now\n\n\n  #if defined(TEXTURE_NORMALS)\n    mat3 tangentSpace = computeTangentSpace(normal);\n    vec3 shadingNormal = computeTextureNormal(tangentSpace);\n  #else\n    vec3 shadingNormal = normal;\n  #endif\n\n  #ifdef TREE_RENDERING\n    // make sure we use unflipped normal\n    shadingNormal = normalize(vnormal);\n\n    // make tree 20% brighter\n    albedo_ *= 1.2;\n\n    // view forward vector in global coordinates\n    vec3 viewForward = - vec3(view[0][2], view[1][2], view[2][2]);\n\n    // factor indicating how aligned the lighting direction and view axis are\n    float alignmentLightView = clamp(dot(-viewForward, lightingMainDirection), 0.0, 1.0);\n\n    // we approximate the tree crown transmittance based on view direction and tree crown normal\n    float transmittance = 1.0 - clamp(dot(-viewForward, shadingNormal), 0.0, 1.0);\n\n    float treeRadialFalloff = vcolor.r;\n    float backLightFactor = 0.5 * treeRadialFalloff * alignmentLightView * transmittance * (1.0 - shadow);\n    additionalLight += backLightFactor * lightingMainIntensity;\n  #endif\n\n  vec3 shadedColor = evaluateSceneLighting(shadingNormal, albedo_, shadow, 1.0 - ssao, additionalLight);\n  gl_FragColor = highlightSlice(vec4(shadedColor, opacity_), vpos);\n}\n","colorPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\n#define VERTEX_SHADER\n#include <materials/defaultMaterial/vertexTangents.glsl>\n\n#ifdef INSTANCEDCOLOR\nattribute vec4 instanceColor;\n#endif\nattribute vec3 position;\n\n#if (NORMALS == NORMALS_COMPRESSED)\n  attribute vec2 normalCompressed;\n  varying vec3 vnormal;\n#elif (NORMALS == NORMALS_DEFAULT)\n  attribute vec3 normal;\n  varying vec3 vnormal;\n#endif\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\n    attribute vec2 uv0;\n    varying vec2 vtc;\n  #ifdef TEXTURE_ATLAS\n    attribute vec4 region;\n    varying vec4 regionV;\n  #endif\n#endif\n\n#ifdef COMPONENTCOLORS\n#include <materials/defaultMaterial/componentColors.glsl>\n#endif\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\n#ifdef VERTEXCOLORS\nattribute vec4 color;\n#endif\n\n#ifdef SYMBOLVERTEXCOLORS\nattribute vec4 symbolColor;\n#endif\n\n#if defined(VERTEXCOLORS)\nvarying vec4 vcolor;\n#endif\n\n// Workaround for https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/13452\n// We pass the externalColor uniform from VS to FS through the vcolorExt varying because\n// there is a driver bug for Intel Integrated Graphics which led to rendering artifacts\n// since the introduction of https://devtopia.esri.com/WebGIS/arcgis-js-api/pull/12673\n// This should be further cleaned up later with through the following issue:\n// https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/12763\nuniform vec4 externalColor;\nvarying vec4 vcolorExt;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#endif\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_SIZE) || defined(VV_COLOR)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/colorMixMode.glsl>\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/constants.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n#include <materials/defaultMaterial/localNormal.glsl>\n\nvoid main() {\n\n#ifdef VERTEXCOLORS\n  vcolor = color * 0.003921568627451; // = 1/255\n#endif\n\n  vcolorExt = externalColor;\n\n#ifdef INSTANCEDCOLOR\n  vcolorExt *= instanceColor;\n#endif\n\n#ifdef VV_COLOR\n  vcolorExt *= vvGetColor(instanceFeatureAttribute, vvColorValues, vvColorColors);\n#endif\n\n#ifdef SYMBOLVERTEXCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(symbolColor, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n#ifdef COMPONENTCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(readComponentColor() * 255.0, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n  if (vcolorExt.a < SYMBOL_ALPHA_CUTOFF) {\n    // Discard this vertex\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n  }\n  else {\n    vpos = calculateVPos();\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize(modelNormal * localNormal().xyz);\n  #endif\n\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n  #ifdef IOS_SAFARI_FIX\n    originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n  #endif\n  vpos -= originDelta;\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = model * localCenter().xyz + originDelta;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize((modelNormal * localNormal()).xyz);\n  #endif\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = (model * localCenter()).xyz;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n    #if defined(VERTEX_TANGENTS)\n      transformVertexTangent(mat3(modelNormal));\n    #endif\n\n    gl_Position = proj * view * vec4(vpos, 1.0);\n  }\n\n#ifdef RECEIVE_SHADOWS\n  // Shadowmap's cascading index used to be based on '1.0 / gl_FragCoord.w'\n  // (i.e. the perspective interpolation of 'gl_Position.w'). Precision\n  // issues on iPad/iPhone with the 'w' component require the depth to be\n  // passed as varying to properly drive the cascading shadow map index.\n  linearDepth = gl_Position.w;\n#endif\n\n\n#ifdef TEXTURING\n  #ifndef FLIPV\n    vtc = uv0;\n  #else\n    vtc = vec2(uv0.x, 1.0-uv0.y);\n  #endif\n  #ifdef TEXTURE_ATLAS\n    regionV = region;\n  #endif\n#endif /* TEXTURING */\n\n}\n","commonFunctions.glsl":"#include <materials/defaultMaterial/localPosition.glsl>\n#include <util/doublePrecision.glsl>\n\nvec3 calculateVPos() {\n#ifdef INSTANCED_DOUBLE_PRECISION\n  return model * localPosition().xyz;\n#else\n  return (model * localPosition()).xyz;\n#endif\n}\n\n#ifdef VERTICAL_OFFSET\n#ifdef SCREEN_SIZE_PERSPECTIVE\n#include <util/screenSizePerspective.glsl>\n#endif\n\nvec3 calculateVerticalOffset(vec3 worldPos, vec3 localOrigin) {\n  float viewDistance = length((view * vec4(worldPos, 1.0)).xyz);\n  float verticalOffsetOffsetDistance = verticalOffset.x * viewDistance;\n\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec3 worldNormal = normalize(worldPos + localOrigin);\n#else\n  vec3 worldNormal = vec3(0.0, 0.0, 1.0);\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  float cosAngle = dot(worldNormal, normalize(worldPos - camPos));\n\n  float verticalOffsetScreenHeight = screenSizePerspectiveScaleFloat(verticalOffset.x, abs(cosAngle), viewDistance, screenSizePerspectiveAlignment);\n#else\n  float verticalOffsetScreenHeight = verticalOffset.x;\n#endif\n\n  // Screen sized offset in world space, used for example for line callouts\n  float worldOffset = clamp(verticalOffsetScreenHeight * verticalOffset.y * viewDistance, verticalOffset.z, verticalOffset.w);\n\n  return worldNormal * worldOffset;\n}\n#endif\n","commonInputs.glsl":"uniform mat4 proj;\nuniform mat4 view;\n#ifdef INSTANCED_DOUBLE_PRECISION\nuniform vec3 viewOriginHi;\nuniform vec3 viewOriginLo;\n#endif\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\n#ifdef INSTANCED\n#ifdef INSTANCED_DOUBLE_PRECISION\nattribute vec3 modelOriginHi;\nattribute vec3 modelOriginLo;\nattribute mat3 model;\nattribute mat3 modelNormal;\n#else /* INSTANCED_DOUBLE_PRECISION */\nattribute mat4 model;\nattribute mat4 modelNormal;\n#endif /* INSTANCED_DOUBLE_PRECISION */\n#else /* INSTANCED */\nuniform mat4 model;\nuniform mat4 modelNormal;\n#endif /* INSTANCED */\n\n#ifdef VERTICAL_OFFSET\n// [ verticalOffsetPerDistance, minWorldLength, maxWorldLength ]\nuniform vec4 verticalOffset;\n#ifdef SCREEN_SIZE_PERSPECTIVE\nuniform vec4 screenSizePerspectiveAlignment;\n#endif\n#endif\n","componentColors.glsl":"\nuniform sampler2D uComponentColorTex;\nuniform vec2 uComponentColorTexInvDim;\n\nattribute float componentIndex;\n\nvec4 readComponentColor() {\n  float normalizedIndex = (componentIndex + 0.5) * uComponentColorTexInvDim.x;\n  vec2 indexCoord = vec2(\n    mod(normalizedIndex, 1.0),\n    (floor(normalizedIndex) + 0.5) * uComponentColorTexInvDim.y\n  );\n  vec4 componentColor = texture2D(uComponentColorTex, indexCoord);\n  // NB: we clear the least significant bit of the blue channel as this contains\n  // the castShadows flag\n  return vec4( componentColor.r, componentColor.g, componentColor.b - mod(componentColor.b*255.0, 2.0)/255.0, componentColor.a);\n}\n\n// returns 1.0 if shadowCasting is enabled and 0.0 otherwise\n// this is found by reading the least significant bit of the\n// componentColors blue color channel which contains the castShadows flag\nbool readComponentCastShadowsFlag(){\n  float normalizedIndex = (componentIndex + 0.5) * uComponentColorTexInvDim.x;\n  vec2 indexCoord = vec2(\n    mod(normalizedIndex, 1.0),\n    (floor(normalizedIndex) + 0.5) * uComponentColorTexInvDim.y\n  );\n  if( mod(texture2D(uComponentColorTex, indexCoord).b*255.0, 2.0) < 1.0 )\n      return false;\n  return true;\n}\n","constants.glsl":"#define SYMBOL_ALPHA_CUTOFF 0.001\n","depthPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/depth.glsl>\n#include <util/slice.glsl>\n\nvarying float depth;\nvarying vec3 vpos;\n\n#if defined(TEXTURING)\n  #include <materials/defaultMaterial/texturingInputs.glsl>\n  #include <materials/defaultMaterial/texturing.glsl>\n#endif\n\n\nvoid main() {\n  discardBySlice(vpos);\n\n  #if defined(TEXTURING)\n    vec4 texColor = textureLookup(tex, vtc);\n    discardOrAdjustTextureAlpha(texColor);\n  #endif\n\n  #ifndef BIAS_SHADOWMAP\n    gl_FragColor = float2rgba(depth);\n  #else\n    gl_FragColor = float2rgba(calcFragDepth(depth));\n  #endif\n}\n","depthPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\nuniform vec2 nearFar;\nattribute vec3 position;\n\nvarying float depth;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_CUSTOM_MODEL_MATRIX)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n\n#if defined(COMPONENTCOLORS)\n#include <materials/defaultMaterial/componentColors.glsl>\n#endif\n\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n\n\n#if defined(COMPONENTCOLORS)\n  if( !readComponentCastShadowsFlag() ){\n    // discard vertex so that it doesnt show up in depth buffer\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n  }else\n  {\n#endif\n\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n#ifdef IOS_SAFARI_FIX\n  originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n#endif\n  vpos -= originDelta;\n\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = model * localCenter().xyz + originDelta;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = (model * localCenter()).xyz;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n  vec4 eye = view * vec4(vpos, 1.0);\n\n  gl_Position = proj * eye;\n  depth = (-eye.z - nearFar[0]) / (nearFar[1] - nearFar[0]) ;\n\n#if defined(COMPONENTCOLORS)\n  } // if readComponentCastShadowsFlag==true\n#endif\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","highlightPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/highlight.glsl>\n\nvarying vec3 vpos;\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\n#if defined(TEXTURING)\n  #include <materials/defaultMaterial/texturingInputs.glsl>\n  #include <materials/defaultMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n  #if defined(TEXTURING)\n    vec4 texColor = textureLookup(tex, vtc);\n    discardOrAdjustTextureAlpha(texColor);\n  #endif\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","highlightPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\nattribute vec3 position;\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_CUSTOM_MODEL_MATRIX)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n#ifdef IOS_SAFARI_FIX\n  originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n#endif\n  vpos -= originDelta;\n\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = model * localCenter().xyz + originDelta;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = (model * localCenter()).xyz;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","localCenter.glsl":"#ifdef VV_CUSTOM_MODEL_MATRIX\n# ifdef VERTICAL_OFFSET\nvec4 localCenter() { return vvTransformPosition(vec3(0.0), instanceFeatureAttribute); }\n# endif\n#else\n# ifdef VERTICAL_OFFSET\nvec4 localCenter() { return vec4(vec3(0.0), 1.0); }\n# endif\n#endif\n","localNormal.glsl":"#include <util/normalEncoding.glsl>\n\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  # if (NORMALS == NORMALS_COMPRESSED)\n    vec4 localNormal() { return vvTransformNormal(decodeNormal(normalCompressed), instanceFeatureAttribute); }\n  # elif (NORMALS == NORMALS_DEFAULT)\n    vec4 localNormal() { return vvTransformNormal(normal, instanceFeatureAttribute); }\n  # endif\n#else\n  # if (NORMALS == NORMALS_COMPRESSED)\n    vec4 localNormal() { return vec4(decodeNormal(normalCompressed), 1.0); }\n  # elif (NORMALS == NORMALS_DEFAULT)\n    vec4 localNormal() { return vec4(normal, 1.0); }\n  # endif\n#endif\n","localPosition.glsl":"#ifdef VV_CUSTOM_MODEL_MATRIX\nvec4 localPosition() { return vvTransformPosition(position, instanceFeatureAttribute); }\n#else\nvec4 localPosition() { return vec4(position, 1.0); }\n#endif\n","normalPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\n#if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n  varying vec3 vnormal;\n#endif\n\nvarying vec3 vpos;\n\n#if defined(TEXTURING)\n  #include <materials/defaultMaterial/texturingInputs.glsl>\n  #include <materials/defaultMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n  #if defined(TEXTURING)\n    vec4 texColor = textureLookup(tex, vtc);\n    discardOrAdjustTextureAlpha(texColor);\n  #endif\n\n#if (NORMALS == NORMALS_SCREEN_DERIVATIVE)\n  vec3 normal = normalize(cross(dFdx(vpos),dFdy(vpos)));\n#else\n  vec3 normal = normalize(vnormal);\n  if (gl_FrontFacing == false) normal = -normal;\n#endif\n\n  #ifndef ALPHA_ZERO\n    gl_FragColor = vec4(vec3(.5) + .5 * normal, 1.0);\n  #else\n    gl_FragColor = vec4(vec3(.5) + .5 * normal, 0.0);\n  #endif\n}\n","normalPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\nuniform mat4 viewNormal;\nattribute vec3 position;\n\n#if (NORMALS == NORMALS_COMPRESSED)\n  attribute vec2 normalCompressed;\n  varying vec3 vnormal;\n#elif (NORMALS == NORMALS_DEFAULT)\n  attribute vec3 normal;\n  varying vec3 vnormal;\n#endif\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n\nvarying vec3 vpos;\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_CUSTOM_MODEL_MATRIX)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n#include <materials/defaultMaterial/localNormal.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize((viewNormal * vec4(modelNormal * localNormal().xyz, 1.0)).xyz);\n  #endif\n\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n\n  #ifdef IOS_SAFARI_FIX\n    originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n  #endif\n  vpos -= originDelta;\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = model * localCenter().xyz + originDelta;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize((viewNormal * modelNormal * localNormal()).xyz);\n  #endif\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = (model * localCenter()).xyz;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","textureNormals.glsl":"#if defined(TEXTURE_NORMALS)\n  uniform sampler2D texNormal;\n\n  vec3 computeTextureNormal(mat3 tangentSpace) {\n    vec3 rawNormal = texture2D(texNormal, vtc).rgb * 2.0 - 1.0;\n    return tangentSpace * rawNormal;\n  }\n#endif","texturing.glsl":'float calcMipMapLevel(const vec2 ddx, const vec2 ddy) {\n  // from:\n  //   - OpenGLES Common Profile Specification Version 2.0.25, Section 3.7.7 - Texture Minification\n  //   - https://www.opengl.org/discussion_boards/showthread.php/171485-Texture-LOD-calculation-(useful-for-atlasing)\n  //   - http://www.linedef.com/virtual-texture-demo.html\n  float deltaMaxSqr = max(dot(ddx, ddx), dot(ddy, ddy));\n  return max(0.0, 0.5 * log2(deltaMaxSqr));\n}\n\nvec4 textureAtlasLookup(sampler2D tex, vec2 uv, vec4 region, vec2 texSize) {\n  //[umin, vmin, umax, vmax]\n  vec2 atlasScale = region.zw - region.xy;\n  vec2 uvAtlas = fract(uv) * atlasScale + region.xy;\n\n  vec4 texColor;\n\n  // calculate derivative of continuous texture coordinate\n  // to avoid mipmapping artifacts caused by manual wrapping in shader\n  vec2 dUVdx = dFdx(uv) * atlasScale;\n  vec2 dUVdy = dFdy(uv) * atlasScale;\n\n#ifdef GL_EXT_shader_texture_lod\n  return texture2DGradEXT(tex, uvAtlas, dUVdx, dUVdy);\n#else\n  // use bias to compensate for difference in automatic vs desired mipmap level\n  vec2 dUVdxAuto = dFdx(uvAtlas);\n  vec2 dUVdyAuto = dFdy(uvAtlas);\n  float mipMapLevel = calcMipMapLevel(dUVdx * texSize, dUVdy * texSize);\n  float autoMipMapLevel = calcMipMapLevel(dUVdxAuto * texSize, dUVdyAuto * texSize);\n\n  return texture2D(tex, uvAtlas, mipMapLevel - autoMipMapLevel);\n#endif\n}\n\nvec4 textureLookup(sampler2D tex, vec2 uv) {\n#ifdef TEXTURE_ATLAS\n  return textureAtlasLookup(tex, uv, regionV, texSize);\n#else\n  return texture2D(tex, uv);\n#endif\n}\n\n/**\n * Based on the texture alpha mode:\n * - discards fragments if necessary\n * - adjusts read texture alpha if necessary\n */\nvoid discardOrAdjustTextureAlpha(inout vec4 texColor) {\n  // if the texture alpha mode is set to "mask"\n  // the resulting alpha is either 0.0 (discard) or 1.0\n  #if defined(TEXTURE_ALPHA_MODE_MASK)\n    if (texColor.a < textureAlphaCutoff) {\n      discard;\n    } else {\n      texColor.a = 1.0;\n    }\n  // if the texture alpha mode is set to "maskBlend"\n  // the resulting alpha is either 0.0 (discard) or untouched for further use in blending\n  #elif defined(TEXTURE_ALPHA_MODE_MASK_BLEND)\n    if (texColor.a < textureAlphaCutoff) {\n      discard;\n    }\n  // if the texture alpha mode is set to "opaque"\n  // the resulting alpha is always 1.0\n  #elif defined(TEXTURE_ALPHA_MODE_OPAQUE)\n    texColor.a = 1.0;\n  // for "blend" we don\'t need to do anyting\n  #else // defined(TEXTURE_ALPHA_MODE_BLEND)\n\n  #endif\n}\n\n\n\n',"texturingInputs.glsl":"#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\n\n#if defined(TEXTURE_ALPHA_MODE_MASK) || defined(TEXTURE_ALPHA_MODE_MASK_BLEND)\nuniform float textureAlphaCutoff;\n#endif\n\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n\n#endif\n\n#if defined(TEXTURING) || defined(TEXTURE_COORDINATES)\nvarying vec2 vtc;\n#endif\n","vertexTangents.glsl":"#if defined(VERTEX_SHADER)\n\n  #if defined(VERTEX_TANGENTS)\n    attribute vec4 aTangent;\n    varying vec4 vTangent;\n\n    void transformVertexTangent(mat3 modelTransformForNormals) {\n      vTangent.xyz = modelTransformForNormals * aTangent.xyz;\n      vTangent.w = aTangent.w;\n    }\n  #endif // VERTEX_TANGENTS\n\n#elif defined(FRAGMENT_SHADER)\n\n  #if defined(VERTEX_TANGENTS)\n    varying vec4 vTangent;\n\n    #if defined(WINDINGORDERDOUBLESIDED)\n      mat3 computeTangentSpace(vec3 normal) {\n        float tangentHeadedness = gl_FrontFacing ? vTangent.w : -vTangent.w;\n        vec3 tangent = normalize(gl_FrontFacing ? vTangent.xyz : -vTangent.xyz);\n        vec3 bitangent = cross(normal, tangent) * tangentHeadedness;\n        return mat3(tangent, bitangent, normal);\n      }\n    #else // WINDINGORDERDOUBLESIDED\n      mat3 computeTangentSpace(vec3 normal) {\n        float tangentHeadedness = vTangent.w;\n        vec3 tangent = normalize(vTangent.xyz);\n        vec3 bitangent = cross(normal, tangent) * tangentHeadedness;\n        return mat3(tangent, bitangent, normal);\n      }\n    #endif // WINDINGORDERDOUBLESIDED\n  #endif // VERTEX_TANGENTS\n\n#endif // VERTEX_SHADER\n"},hud:{"colorPass.frag":"#include <materials/hud/hudHeader.glsl>\n\nvoid main() {\n#include <materials/hud/hudMain.glsl>\n}\n","highlightPass.frag":"#include <materials/hud/hudHeader.glsl>\n#include <util/highlight.glsl>\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\nvoid main() {\n#include <materials/hud/hudMain.glsl>\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\n  // Instead of deciding on a per-pixel basis if the highlight is occluded,\n  // do it for all highlight pixel based on the centroid occlusion. This\n  // is a temporary solution for:\n  // https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/9645\n  if (voccluded == 1.0) {\n    gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);\n  } else {\n    gl_FragColor = vec4(1.0, 0.0, 1.0, 1.0);\n  }\n#else\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n#endif\n}\n","hud.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n#include <util/hud.glsl>\n#include <util/visualVariables.glsl>\n#include <util/slice.glsl>\n\nuniform vec2 screenOffset;\nuniform vec2 anchorPos;\n\n// textureCoordinateScaleFactor can be used when there is a uniform texture scaling per material.\n// This is used in the case where we enforce a POT texture (for mipmaps) and the effective\n// texture is only in a subregion of the full POT texture.\nuniform vec2 textureCoordinateScaleFactor;\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\nuniform vec4 screenSizePerspective;\n#endif\n\n#ifdef DEBUG_DRAW_BORDER\nvarying vec3 debugBorderCoords;\n#endif\n\nattribute vec2 uv0;\nattribute vec4 color;\nattribute vec2 size;\nattribute vec4 auxpos2;\n\nvarying vec4 vcolor;\n\nvarying vec2 vtc;\nvarying vec2 vsize;\n\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\nvarying float voccluded;\n#endif\n\nvoid main(void) {\n  ProjectHUDAux projectAux;\n  vec4 posProj = projectPositionHUD(projectAux);\n\n  if (rejectBySlice(projectAux.posModel)) {\n    // Project outside of clip plane\n    gl_Position = vec4(1e038, 1e038, 1e038, 1.0);\n    return;\n  }\n\n  vec2 inputSize;\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n  inputSize = screenSizePerspectiveScaleVec2(size, projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspective);\n\n  vec2 screenOffsetScaled = screenSizePerspectiveScaleVec2(screenOffset, projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);\n\n#else\n\n  inputSize = size;\n\n  vec2 screenOffsetScaled = screenOffset;\n#endif\n\n#ifdef VV_SIZE\n  // only use width (.xx) for proportional scaling\n  // (if no width was defined in vv, width\n  //  will be a copy of height vv)\n  inputSize *= vvGetScale(auxpos2).xx;\n#endif\n\n  vec2 combinedSize = inputSize * pixelRatio;\n  vec4 quadOffset = vec4(0.0);\n\n#if defined(OCCL_TEST) || defined(BINARY_HIGHLIGHT_OCCLUSION)\n  bool visible = testVisibilityHUD(posProj);\n#endif\n\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\nvoccluded = visible ? 0.0 : 1.0;\n#endif\n\n#ifdef OCCL_TEST\n  if (visible) {\n#endif\n    // UV goes from 0 to 1.99999, where the integer part is used\n    // for the normalized vertex coordinates, and the fractional\n    // part is used for texture sampling\n    vec2 uv01 = floor(uv0);\n    vec2 uv = uv0 - uv01;\n\n    // Displace icon based on anchor position (normalized for size) and\n    // absolute screen offset. anchorPos is [-0.5, 0.5]\n    quadOffset.xy = ((uv01 - anchorPos) * 2.0 * combinedSize + screenOffsetScaled) / viewport.zw * posProj.w;\n\n#ifdef SIGNED_DISTANCE_FIELD\n\n    // SDF primitives might be scaled so that the SDF texture resolution does\n    // not match the resolution of the canvas, but we still want to render\n    // outline-only ('cross' and 'x') primitives cleanly. Aligning to a screen\n    // pixel border at the geometry center achieves this, since SDF textures\n    // always have power of 2 dimensions.\n    posProj = alignToPixelOrigin(posProj, viewport.zw) + quadOffset;\n#else\n    posProj += quadOffset;\n\n    // Aligning vertex positions to the nearest (using 'floor') screen pixel\n    // border renders textures with pixel-perfect results. If the texture\n    // resolution does not match the canvas resolution then aligning is\n    // redundant.\n    if (inputSize.x == size.x) {\n      posProj = alignToPixelOrigin(posProj, viewport.zw);\n    }\n#endif\n\n    gl_Position = posProj;\n\n    vtc = uv * textureCoordinateScaleFactor;\n\n#ifdef DEBUG_DRAW_BORDER\n    debugBorderCoords = vec3(uv01, 1.0 / combinedSize);\n#endif\n\n    vsize = inputSize;\n#ifdef OCCL_TEST\n  } else {\n    vtc = vec2(.0);\n\n#ifdef DEBUG_DRAW_BORDER\n    debugBorderCoords = vec3(0.0);\n#endif\n\n  }\n#endif\n\n  gl_Position = posProj;\n\n#ifdef VV_COLOR\n  vcolor = vvGetColor(auxpos2, vvColorValues, vvColorColors);\n#else\n  vcolor = color / 255.0;\n#endif\n}\n","hudHeader.glsl":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/color.glsl>\n\nuniform sampler2D tex;\nuniform vec4 overrideColor;\nuniform vec4 outlineColor;\nuniform float outlineSize;\n\nvarying vec4 vcolor;\n\nvarying vec2 vtc;\nvarying vec2 vsize;\n\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\nvarying float voccluded;\n#endif\n\n#ifdef DEBUG_DRAW_BORDER\nvarying vec3 debugBorderCoords;\n#endif\n","hudMain.glsl":"#ifdef SIGNED_DISTANCE_FIELD\n  vec4 color = vec4(0.0, 0.0, 0.0, 0.0);\n  vec4 fillPixelColor = overrideColor * vcolor;\n\n  // Attempt to sample texel centers to avoid that thin cross outlines\n  // disappear with large symbol sizes.\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/7058#issuecomment-603041\n  const float txSize = 128.0;\n  const float texelSize = 1.0 / txSize;\n  // Calculate how much we have to add/subtract to/from each texel to reach the size of an onscreen pixel\n  vec2 scaleFactor = (vsize - txSize) * texelSize;\n  vec2 samplePos = vtc + (vec2(1.0, -1.0) * texelSize) * scaleFactor;\n\n  // Get distance and map it into [-0.5, 0.5]\n  float d = rgba2float(texture2D(tex, samplePos)) - 0.5;\n\n  // Distance in output units (i.e. pixels)\n  float dist = d * vsize.x;\n\n  // Create smooth transition from the icon into its outline\n  fillPixelColor.a *= clamp(0.5 - dist, 0.0, 1.0);\n\n  if (outlineSize > 0.25) {\n    vec4 outlinePixelColor = outlineColor;\n    float clampedOutlineSize = min(outlineSize, 0.5*vsize.x);\n\n    // Create smooth transition around outline\n    outlinePixelColor.a *= clamp(0.5 - (abs(dist) - 0.5*clampedOutlineSize), 0.0, 1.0);\n\n    // perform un-premultiplied over operator (see https://en.wikipedia.org/wiki/Alpha_compositing#Description)\n    float compositeAlpha = outlinePixelColor.a + fillPixelColor.a * (1.0 - outlinePixelColor.a);\n    vec3 compositeColor = vec3(outlinePixelColor) * outlinePixelColor.a +\n      vec3(fillPixelColor) * fillPixelColor.a * (1.0 - outlinePixelColor.a);\n\n    gl_FragColor = vec4(compositeColor, compositeAlpha);\n  }\n  else {\n    gl_FragColor = premultiplyAlpha(fillPixelColor);\n  }\n\n  // visualize SDF:\n  // gl_FragColor = vec4(clamp(-dist/vsize.x*2.0, 0.0, 1.0), clamp(dist/vsize.x*2.0, 0.0, 1.0), 0.0, 1.0);\n#else\n\n  // HUDMaterial is rendered with a blending mode that assumes a pre-multiplied\n  // fragment color. Input textures should already be pre-multiplied and so\n  // don't require adjustment, but the override and vertex colors must be\n  // modulated by their alpha values.\n\n  gl_FragColor = texture2D(tex, vtc, -0.5) * premultiplyAlpha(overrideColor * vcolor);\n\n#endif\n\n#ifdef DEBUG_DRAW_BORDER\n   float isBorder = float(any(lessThan(debugBorderCoords.xy, vec2(debugBorderCoords.z))) || any(greaterThan(debugBorderCoords.xy, vec2(1.0 - debugBorderCoords.z))));\n   gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 1.0, 1.0), isBorder);\n#endif\n\n  if (gl_FragColor.a < 0.1) {\n    discard;\n  }\n","occlusionTest.frag":"#include <util/fsPrecision.glsl>\n\nuniform vec4 color;\n\nvoid main() {\n  gl_FragColor = color;\n}\n","occlusionTest.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n#include <util/hud.glsl>\n#include <util/slice.glsl>\n\nvoid main(void) {\n  vec4 posProjCenter;\n\n  // Check for special value of position (0, 0, 0) which is used by the Renderer when graphics\n  // are removed before the VBO is recompacted. If this is the case, then we just project outside\n  // of clip space.\n  if (dot(position, position) > 0.0) {\n    // Render single point to center of the pixel to avoid subpixel filtering to affect\n    // the marker color\n    ProjectHUDAux projectAux;\n    vec4 posProj = projectPositionHUD(projectAux);\n    posProjCenter = alignToPixelCenter(posProj, viewport.zw);\n\n    vec3 vpos = projectAux.posModel;\n    if (rejectBySlice(vpos)) {\n      // Project out of clip space\n      posProjCenter = vec4(1e038, 1e038, 1e038, 1.0);\n    }\n  }\n  else {\n    // Project out of clip space\n    posProjCenter = vec4(1e038, 1e038, 1e038, 1.0);\n  }\n\n  gl_Position = posProjCenter;\n  gl_PointSize = 1.0;\n}\n"},lineCallout:{"lineCallout.frag":"#include <util/fsPrecision.glsl>\n\nuniform vec4 color;\nuniform vec4 borderColor;\n\nvarying vec4 coverageSampling;\nvarying vec2 lineSizes;\n\nvoid main() {\n  // Mix between line and border coverage offsets depending on whether we need\n  // a border (based on the sidedness).\n  vec2 coverage = min(1.0 - clamp(abs(coverageSampling.xy) - coverageSampling.zw, 0.0, 1.0), lineSizes);\n\n  // Mix between border and line color based on the line coverage (conceptually the line\n  // blends on top of the border background).\n  //\n  // Anti-alias by blending final result using the full (including optional border) coverage\n  // and the color alpha\n  float borderAlpha = color.a * borderColor.a * coverage.y;\n  float colorAlpha = color.a * coverage.x;\n\n  float finalAlpha = mix(borderAlpha, 1.0, colorAlpha);\n\n#ifdef DEPTH_HUD\n\n  if (finalAlpha < 0.01) {\n    discard;\n  }\n\n#else\n\n  // Compute the finalRgb, but keep it pre-multiplied (for unpre-multiplied you\n  // need to divide by finalAlpha). We avoid the division here by setting the\n  // appropriate blending function in the material.\n  vec3 finalRgb = mix(borderColor.rgb * borderAlpha, color.rgb, colorAlpha);\n\n  gl_FragColor = vec4(finalRgb, finalAlpha);\n\n#endif\n\n}\n","lineCallout.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n#include <util/hud.glsl>\n#include <util/slice.glsl>\n\nattribute vec2 uv0;\n\nuniform float lineSize;\nuniform vec2 pixelToNDC;\nuniform float borderSize;\nuniform vec2 screenOffset;\n\nvarying vec4 coverageSampling;\nvarying vec2 lineSizes;\n\nvoid main(void) {\n\n  ProjectHUDAux projectAux;\n  vec4 endPoint = projectPositionHUD(projectAux);\n\n  vec3 vpos = projectAux.posModel;\n  if (rejectBySlice(vpos)) {\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n    return;\n  }\n\n#ifdef OCCL_TEST\n  if (!testVisibilityHUD(endPoint)) {\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n    return;\n  }\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  vec4 perspectiveFactor = screenSizePerspectiveScaleFactor(projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);\n  vec2 screenOffsetScaled = applyScreenSizePerspectiveScaleFactorVec2(screenOffset, perspectiveFactor);\n#else\n  vec2 screenOffsetScaled = screenOffset;\n#endif\n\n  // Add view dependent polygon offset to get exact same original starting point. This is mostly\n  // used to get the correct depth value\n  vec3 posView = (view * (model * vec4(position, 1.0))).xyz;\n  applyHUDViewDependentPolygonOffset(auxpos1.w, projectAux.absCosAngle, posView);\n\n  vec4 startPoint = proj * vec4(posView, 1.0);\n\n  // Apply screen offset to both start and end point\n  vec2 screenOffsetNorm = screenOffsetScaled * 2.0 / viewport.zw;\n\n  startPoint.xy += screenOffsetNorm * startPoint.w;\n  endPoint.xy += screenOffsetNorm * endPoint.w;\n\n  // Align start and end to pixel origin\n  vec4 startAligned = alignToPixelOrigin(startPoint, viewport.zw);\n  vec4 endAligned = alignToPixelOrigin(endPoint, viewport.zw);\n\n#ifdef DEPTH_HUD\n\n#ifdef DEPTH_HUD_ALIGN_START\n  endAligned = vec4(endAligned.xy / endAligned.w * startAligned.w, startAligned.zw);\n#else\n  startAligned = vec4(startAligned.xy / startAligned.w * endAligned.w, endAligned.zw);\n#endif\n\n#endif\n\n  vec4 projectedPosition = mix(startAligned, endAligned, uv0.y);\n\n  // The direction of the line in screen space\n  vec2 screenSpaceDirection = normalize(endAligned.xy / endAligned.w - startAligned.xy / startAligned.w);\n  vec2 perpendicularScreenSpaceDirection = vec2(screenSpaceDirection.y, -screenSpaceDirection.x);\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n  float lineSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(lineSize, perspectiveFactor);\n  float borderSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(borderSize, perspectiveFactor);\n\n#else\n\n  float lineSizeScaled = lineSize;\n  float borderSizeScaled = borderSize;\n\n#endif\n\n  float halfPixelSize = lineSizeScaled * 0.5;\n  // Calculate a pixel offset from the edge of the pixel, s.t. we keep the line aligned\n  // to pixels if it has a full pixel size. Since pixel aligned biases to the bottom-left,\n  // we bias the size to the right (for odd sizes) to balance out the bias. Grow sub-pixel\n  // sizes towards the left or right s.t. there is a smooth transition (e.g. from 2 to 3 px).\n  float halfWholePixelSize = floor(lineSizeScaled) * 0.5;\n  float halfPixelSizeInt = floor(halfWholePixelSize);\n\n  // Sub-pixel offset if we need to grow sub-pixels to the left\n  float subpixelOffset = -fract(lineSizeScaled) * float(halfWholePixelSize > 0.0);\n\n  // Pixel offset aligning to whole pixels and adding subpixel offset if needed\n  float pixelOffset = -halfPixelSizeInt + subpixelOffset;\n\n  // Compute full ndc offset, adding 1px padding for doing anti-aliasing and the border size\n  float padding = 1.0 + borderSizeScaled;\n  vec2 ndcOffset = (pixelOffset - padding + uv0.x * (lineSizeScaled + padding + padding)) * pixelToNDC;\n\n  // Offset x/y from the center of the line in screen space\n  projectedPosition.xy += perpendicularScreenSpaceDirection * ndcOffset * projectedPosition.w;\n\n  // Compute a coverage varying which we can use in the fragment shader to determine\n  // how much a pixel is actually covered by the line (i.e. to anti alias the line).\n  // This works by computing two coordinates that can be linearly interpolated and then\n  // subtracted to find out how far away from the line edge we are.\n  float edgeDirection = (uv0.x * 2.0 - 1.0);\n\n  float halfBorderSize = 0.5 * borderSizeScaled;\n  float halfPixelSizeAndBorder = halfPixelSize + halfBorderSize;\n  float outerEdgeCoverageSampler = edgeDirection * (halfPixelSizeAndBorder + halfBorderSize + 1.0);\n\n  float isOneSided = float(lineSizeScaled < 2.0 && borderSize < 2.0);\n\n  coverageSampling = vec4(\n    // Edge coordinate\n    outerEdgeCoverageSampler,\n\n    // Border edge coordinate\n    outerEdgeCoverageSampler - halfPixelSizeAndBorder * isOneSided,\n\n    // Line offset\n    halfPixelSize - 0.5,\n\n    // Border offset\n    halfBorderSize - 0.5 + halfPixelSizeAndBorder * (1.0 - isOneSided)\n  );\n\n  lineSizes = vec2(lineSizeScaled, borderSizeScaled);\n\n  gl_Position = projectedPosition;\n}\n"},measurementArrow:{"measurementArrow.frag":"#include <util/fsPrecision.glsl>\n\nuniform float outlineSize;\nuniform vec4 outlineColor;\nuniform float stripeLength;\nuniform vec4 stripeEvenColor;\nuniform vec4 stripeOddColor;\n\nvarying vec2 vtc;\nvarying float vlength;\nvarying float vradius;\n\n#define INV_SQRT2 (1.0 / sqrt(2.0))\n\nvec4 arrowColor(vec2 tc, float len) {\n  float d = INV_SQRT2 * (tc.x - abs(tc.y));\n  d = min(d, INV_SQRT2 * (len - tc.x - abs(tc.y)));\n  d = min(d, 1.0 - abs(tc.y));\n\n  if (d < 0.0) {\n    return vec4(0.0);\n  } else if (d < outlineSize) {\n    return outlineColor;\n  } else {\n    return fract(0.5 / stripeLength * tc.x * vradius) >= 0.5 ? stripeOddColor : stripeEvenColor;\n  }\n}\n\nvoid main(void) {\n  vec2 ntc = vec2(vtc.x / vradius, vtc.y);\n  vec4 color = arrowColor(ntc, vlength / vradius);\n  if (color.a == 0.0) {\n    discard;\n  }\n  gl_FragColor = color;\n}\n","measurementArrow.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nuniform float width;\n\nattribute vec3 position;\nattribute vec3 normal;\nattribute vec2 uv0;\nattribute float auxpos1;\n\nvarying vec2 vtc;\nvarying float vlength;\nvarying float vradius;\n\nvoid main(void) {\n  vec3 bitangent = normal;\n\n  vtc = uv0;\n  vlength = auxpos1;\n  vradius = 0.5 * width;\n\n  vec4 pos = view * vec4((model * vec4(position + vradius * bitangent * uv0.y, 1.0)).xyz, 1.0);\n  gl_Position = proj * pos;\n}\n"},nativeLine:{"colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nuniform vec4 constantColor;\n\nvarying vec3 vpos;\n\n#ifdef VERTEXCOLORS\nvarying vec4 vcolor;\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n#ifdef VERTEXCOLORS\n  gl_FragColor = highlightSlice(vcolor, vpos);\n#else\n  gl_FragColor = highlightSlice(constantColor, vpos);\n#endif\n}\n","highlightPass.frag":"#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/highlight.glsl>\n\nvarying vec3 vpos;\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\nvoid main() {\n  discardBySlice(vpos);\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","nativeLine.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\n\n#ifdef VERTEXCOLORS\nattribute vec4 color;\n#endif\n\n\nvarying vec3 vpos;\n\n#ifdef VERTEXCOLORS\nvarying vec4 vcolor;\n#endif\n\n\nvoid main(void) {\n  vpos = (model * vec4(position, 1.0)).xyz;\n  #ifdef VERTEXCOLORS\n    vcolor = color * 0.003921568627451; // = 1/255\n  #endif\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n}\n"},pathMaterial:{"colorMixMode.glsl":"#include <util/color.glsl>\n\n/*\n * The color mix modes are encoded in the symbol color as follows:\n *  - Fully transparent symbols are represented with alpha 0 for\n *    all color mix modes (except ignore).\n *  - color mix mode ignore is encoded as multiply with white\n *  - the other 3 color mix modes (tint, replace, multiply) are\n *    equally distributed on the remaining 255 alpha values, which\n *    gives us 85 possible alpha values\n *\n * alpha             0 : fully transparent\n * alpha in [  1 -  85]: tint\n * alpha in [ 86 - 170]: replace\n * alpha in [171 - 255]: multiply\n */\nvec4 decodeSymbolColor(vec4 symbolColor, out int colorMixMode) {\n  float symbolAlpha = 0.0;\n\n  const float maxTint = 85.0;\n  const float maxReplace = 170.0;\n  const float scaleAlpha = 3.0;\n\n  if (symbolColor.a == 0.0) {\n    colorMixMode = 1; // fully transparent -> multiply\n    symbolAlpha = 0.0;\n  }\n  else if (symbolColor.a <= maxTint) {\n    colorMixMode = 0; // tint\n    symbolAlpha = scaleAlpha * symbolColor.a;\n  }\n  else if (symbolColor.a <= maxReplace) {\n    colorMixMode = 3; // replace\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxTint);\n  }\n  else {\n    colorMixMode = 1;  // multiply\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxReplace);\n  }\n\n  return vec4(symbolColor.rgb, symbolAlpha);\n}\n\nvec3 mixExternalColor(vec3 internalColor, vec3 textureColor, vec3 externalColor, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  vec3 internalMixed = internalColor * textureColor;\n  vec3 allMixed = internalMixed * externalColor;\n\n  if (mode == 1 /* multiply */) {\n    return allMixed;\n  }\n  else if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalColor;\n  }\n  else {\n    // tint (or something invalid)\n    vec3 hsvIn = rgb2hsv(internalMixed);\n    vec3 hsvTint = rgb2hsv(externalColor);\n    vec3 hsvOut = vec3(hsvTint.x, hsvTint.y, hsvIn.z * hsvTint.z);\n    return hsv2rgb(hsvOut);\n  }\n}\n\nfloat mixExternalOpacity(float internalOpacity, float textureOpacity, float externalOpacity, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  float internalMixed = internalOpacity * textureOpacity;\n  float allMixed = internalMixed * externalOpacity;\n\n  if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalOpacity;\n  }\n  else {\n    // multiply or tint (or something invalid)\n    return allMixed;\n  }\n}\n","colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/sceneLighting.glsl>\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\n// material parameters\n//////////////////////////////////////////\nuniform vec3 ambient;\nuniform vec3 diffuse;\nuniform vec3 specular;\nuniform float opacity;\nuniform float layerOpacity;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#else\nuniform int colorMixMode;\n#endif\n\n#ifdef RECEIVE_SHADOWS\nuniform sampler2D depthTex;\nuniform int shadowMapNum;\nuniform vec4 shadowMapDistance;\nuniform mat4 shadowMapMatrix[4];\nuniform float depthHalfPixelSz;\n#endif\n\n#ifdef RECEIVE_SSAO\nuniform sampler2D ssaoTex;\nuniform vec4 viewportPixelSz;\n#endif\n\nvarying vec3 vpos;\nvarying vec3 vnormal;\n// the vertex color variable will contain vvColor and/or vvOpacity or 1,1,1,1\nvarying vec4 vcolor; \nvarying vec4 vcolorExt;\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#include <util/shadow.glsl>\n#endif\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\n#include <materials/pathMaterial/colorMixMode.glsl>\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  vec4 texColor = textureLookup(tex, vtc);\n  if (texColor.a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#else /* TEXTURING */\n  vec4 texColor = vec4(1.0);\n#endif /* TEXTURING */\n\n  vec3 viewDir = vpos - camPos;\n\n  // compute normal\n  // TODO: this is not in sync with the normal pass\n#ifdef GROUND_NORMAL_SHADING\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec3 normal = normalize(vpos + localOrigin);\n#else\n  vec3 normal = vec3(0.0, 0.0, 1.0);\n#endif\n#else\n#ifdef DOUBLESIDED\n  vec3 normal = dot(vnormal, viewDir)>0.0 ? -vnormal : vnormal;\n#elif defined(WINDINGORDERDOUBLESIDED)\n  vec3 normal = gl_FrontFacing ? vnormal : -vnormal;\n#else\n  vec3 normal = vnormal;\n#endif\n  normal = normalize(normal);\n#endif\n\n  // compute ssao\n#ifdef RECEIVE_SSAO\n  float ssao = texture2D(ssaoTex, (gl_FragCoord.xy - viewportPixelSz.xy) * viewportPixelSz.zw).a;\n  ssao = viewportPixelSz.z < 0.0 ? 1.0 : ssao;\n#else\n  float ssao = 1.0;\n#endif\n\n  // At global scale we create some additional ambient light based on the main light to simulate global illumination\n  float additionalAmbientScale;\n  vec3 additionalLight = sceneLightingAdditionalLightGlobal(vpos + localOrigin, ssao, additionalAmbientScale);\n\n  // compute shadowing\n  float shadow = 0.0;\n#ifdef RECEIVE_SHADOWS\n  shadow = evalShadow(vpos, linearDepth, depthTex, shadowMapNum, shadowMapDistance, shadowMapMatrix, depthHalfPixelSz);\n#elif VIEWING_MODE == VIEWING_MODE_GLOBAL\n  // at global scale (and in global scenes) we fall back to this approximation\n  // to shadow objects on the dark side of the earth\n  shadow = lightingGlobalFactor * (1.0 - additionalAmbientScale);\n#endif\n\n  vec3 matColor = max(ambient, diffuse); // combine the old material parameters into a single one\n\n  vec3 albedo_ = mixExternalColor(vcolor.rgb * matColor, texColor.rgb, vcolorExt.rgb, int(colorMixMode));\n  float opacity_ = layerOpacity * mixExternalOpacity(vcolor.a * opacity, texColor.a, vcolorExt.a, int(colorMixMode));\n  albedo_+= 0.25 * specular; // don't completely ignore specular for now\n\n#ifdef TRANSPARENCY_DISCARD\n  if (opacity_ < 0.001) {\n    discard;\n  }\n#endif\n\n  vec3 shadedColor = evaluateSceneLighting(normal, albedo_, shadow, 1.0 - ssao, additionalLight);\n  gl_FragColor = vec4(shadedColor, opacity_);\n  gl_FragColor = highlightSlice(gl_FragColor, vpos);\n}\n","colorPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n#ifdef COMPRESSED_NORMALS\nattribute vec2 normalCompressed;\n#else\nattribute vec3 normal;\n#endif\nvarying vec3 vpos;\nvarying vec3 vnormal;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#ifdef COMPONENTCOLORS\nuniform sampler2D uComponentColorTex;\nuniform vec2 uComponentColorTexInvDim;\n\nattribute float componentIndex;\n\nvec4 readComponentColor() {\n  float normalizedIndex = (componentIndex + 0.5) * uComponentColorTexInvDim.x;\n  vec2 indexCoord = vec2(\n    mod(normalizedIndex, 1.0),\n    (floor(normalizedIndex) + 0.5) * uComponentColorTexInvDim.y\n  );\n  return texture2D(uComponentColorTex, indexCoord);\n}\n#endif\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\n#ifdef SYMBOLVERTEXCOLORS\nattribute vec4 symbolColor;\n#endif\n\n// Workaround for https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/13452\n// We pass the externalColor uniform from VS to FS through the vcolorExt varying because\n// there is a driver bug for Intel Integrated Graphics which led to rendering artifacts\n// since the introduction of https://devtopia.esri.com/WebGIS/arcgis-js-api/pull/12673\n// This should be further cleaned up later with through the following issue:\n// https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/12763\nuniform vec4 externalColor;\n// the vertex color variable will contain vvColor and/or vvOpacity or 1,1,1,1\nvarying vec4 vcolor;\nvarying vec4 vcolorExt;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#endif\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE) || defined(VV_COLOR) || defined(VV_OPACITY)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n#include <materials/pathMaterial/localNormal.glsl>\n#include <materials/pathMaterial/colorMixMode.glsl>\n\nvoid main() {\n  vpos = calculateVPos();\n\n  vnormal = normalize((modelNormal * localNormal()).xyz);\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef RECEIVE_SHADOWS\n  // Shadowmap's cascading index used to be based on '1.0 / gl_FragCoord.w'\n  // (i.e. the perspective interpolation of 'gl_Position.w'). Precision\n  // issues on iPad/iPhone with the 'w' component require the depth to be\n  // passed as varying to properly drive the cascading shadow map index.\n  linearDepth = gl_Position.w;\n#endif\n\n  vcolorExt = externalColor;\n\n  vcolor = vec4(1.0, 1.0, 1.0, 1.0);\n#ifdef VV_COLOR\n  vcolor = vvGetColor(auxpos2, vvColorValues, vvColorColors);\n#endif\n#ifdef VV_OPACITY\n  // there might be opacity values in vvColor but according to the logic in graphicUtils.mixinColorAndOpacity,\n  // this value will be overridden by vvOpacity so we do the same here\n  vcolor.a = vvGetOpacity(auxpos2, vvOpacityValues, vvOpacityOpacities);\n#endif\n\n\n#ifdef SYMBOLVERTEXCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(symbolColor, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n#ifdef COMPONENTCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(readComponentColor() * 255.0, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n#ifdef TEXTURING\n  // the v coordinate is stored in auxpos1.w\n#ifndef FLIPV\n  vtc = vec2(uv0.x, auxpos1.w);\n#else\n  vtc = vec2(uv0.x, 1.0-auxpos1.w);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","commonFunctions.glsl":"#include <materials/pathMaterial/localPosition.glsl>\n#include <util/doublePrecision.glsl>\n\nvec3 calculateVPos() {\n  return (model * localPosition()).xyz;\n}","commonInputs.glsl":"uniform mat4 proj;\nuniform mat4 view;\n\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\nuniform mat4 model;\nuniform mat4 modelNormal;\n\nuniform float size;\n\n// ---------------------------------------------- ++","depthPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/depth.glsl>\n#include <util/slice.glsl>\n\nvarying float depth;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  if (textureLookup(tex, vtc).a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#endif\n\n#ifndef BIAS_SHADOWMAP\n  gl_FragColor = float2rgba(depth);\n#else\n  gl_FragColor = float2rgba(calcFragDepth(depth));\n#endif\n}\n","depthPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nuniform vec2 nearFar;\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n\nvarying float depth;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n  vec4 eye = view * vec4(vpos, 1.0);\n\n  gl_Position = proj * eye;\n  depth = (-eye.z - nearFar[0]) / (nearFar[1] - nearFar[0]) ;\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","highlightPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/highlight.glsl>\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  if (textureLookup(tex, vtc).a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#endif\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","highlightPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","localNormal.glsl":"#include <util/normalEncoding.glsl>\n\n# ifdef COMPRESSED_NORMALS\nvec4 localNormal() { return vec4(decodeNormal(normalCompressed), 1.0); }\n# else\nvec4 localNormal() { return vec4(normal, 1.0); }\n# endif\n","localPosition.glsl":"#ifdef VV_SIZE\nvec4 localPosition() {\n    vec3 sizeScale = vvGetScale(auxpos2);\n    vec3 positionOffset = auxpos1.xyz*sizeScale;\n    return vec4( position+positionOffset, 1.0 );\n}\n#else\nvec4 localPosition() {\n    vec3 sizeScale = vec3(size);\n    vec3 positionOffset = auxpos1.xyz*sizeScale;\n    return vec4(position+positionOffset, 1.0);\n}\n#endif\n","normalPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  if (textureLookup(tex, vtc).a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#endif\n\n  vec3 normal = normalize(vnormal);\n  if (gl_FrontFacing == false) normal = -normal;\n\n#ifndef ALPHA_ZERO\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 1.0);\n#else\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 0.0);\n#endif\n}\n","normalPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nuniform mat4 viewNormal;\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n#ifdef COMPRESSED_NORMALS\nattribute vec2 normalCompressed;\n#else\nattribute vec3 normal;\n#endif\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n#include <materials/pathMaterial/localNormal.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n  vnormal = normalize((viewNormal * modelNormal * localNormal()).xyz);\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","texturing.glsl":"float calcMipMapLevel(const vec2 ddx, const vec2 ddy) {\n  // from:\n  //   - OpenGLES Common Profile Specification Version 2.0.25, Section 3.7.7 - Texture Minification\n  //   - https://www.opengl.org/discussion_boards/showthread.php/171485-Texture-LOD-calculation-(useful-for-atlasing)\n  //   - http://www.linedef.com/virtual-texture-demo.html\n  float deltaMaxSqr = max(dot(ddx, ddx), dot(ddy, ddy));\n  return max(0.0, 0.5 * log2(deltaMaxSqr));\n}\n\nvec4 textureAtlasLookup(sampler2D tex, vec2 uv, vec4 region, vec2 texSize) {\n  //[umin, vmin, umax, vmax]\n  vec2 atlasScale = region.zw - region.xy;\n  vec2 uvAtlas = fract(uv) * atlasScale + region.xy;\n\n  // calculate derivative of continuous texture coordinate\n  // to avoid mipmapping artifacts caused by manual wrapping in shader\n  vec2 dUVdx = dFdx(uv) * atlasScale;\n  vec2 dUVdy = dFdy(uv) * atlasScale;\n\n#ifdef GL_EXT_shader_texture_lod\n  return texture2DGradEXT(tex, uvAtlas, dUVdx, dUVdy);\n#else\n  // use bias to compensate for difference in automatic vs desired mipmap level\n  vec2 dUVdxAuto = dFdx(uvAtlas);\n  vec2 dUVdyAuto = dFdy(uvAtlas);\n  float mipMapLevel = calcMipMapLevel(dUVdx * texSize, dUVdy * texSize);\n  float autoMipMapLevel = calcMipMapLevel(dUVdxAuto * texSize, dUVdyAuto * texSize);\n\n  return texture2D(tex, uvAtlas, mipMapLevel - autoMipMapLevel);\n#endif\n}\n\nvec4 textureLookup(sampler2D tex, vec2 uv) {\n#ifdef TEXTURE_ATLAS\n  return textureAtlasLookup(tex, uv, regionV, texSize);\n#else\n  return texture2D(tex, uv);\n#endif\n}\n\n","visualVariables.glsl":"\n#if defined(VV_SIZE)\n  uniform vec3 vvSizeMinSize;\n  uniform vec3 vvSizeMaxSize;\n  uniform vec3 vvSizeOffset;\n  uniform vec3 vvSizeFactor;\n\n  vec3 vvGetScale(vec4 featureAttribute) {\n    // the 0.5 factor comes from the fact that the generated profiles have radius of 1\n    // but the old implementation of the Graphics3DPathSymbolLayer actually had a profile radius of 0.5\n    // for constant size values the 0.5 is applied in Graphcis3DPathSymbolLayer when setting material parms\n    // we might want to change the path geometry generation so that it produces profile radius of 0.5 too\n    return clamp(vvSizeOffset + featureAttribute.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize)*0.5;\n  }\n#endif\n\n#ifdef VV_COLOR\n  #define VV_COLOR_N 8\n  uniform float vvColorValues[VV_COLOR_N];\n  uniform vec4 vvColorColors[VV_COLOR_N];\n\n  vec4 vvGetColor(vec4 featureAttribute, float values[VV_COLOR_N], vec4 colors[VV_COLOR_N]) {\n    float value = featureAttribute.y;\n    if (value <= values[0]) {\n      return colors[0];\n    }\n\n    for (int i = 1; i < VV_COLOR_N; ++i) {\n      if (values[i] >= value) {\n        float f = (value - values[i-1]) / (values[i] - values[i-1]);\n        return mix(colors[i-1], colors[i], f);\n      }\n    }\n\n    return colors[VV_COLOR_N - 1];\n  }\n#endif\n\n\n#ifdef VV_OPACITY\n  #define VV_OPACITY_N 8\n  uniform float vvOpacityValues[VV_OPACITY_N];\n  uniform float vvOpacityOpacities[VV_OPACITY_N];\n\n  float vvGetOpacity(vec4 featureAttribute, float values[VV_OPACITY_N], float opacities[VV_OPACITY_N]) {\n    float value = featureAttribute.z;\n    if (value <= values[0]) {\n      return opacities[0];\n    }\n\n    for (int i = 1; i < VV_OPACITY_N; ++i) {\n      if (values[i] >= value) {\n        float f = (value - values[i-1]) / (values[i] - values[i-1]);\n        return mix(opacities[i-1], opacities[i], f);\n      }\n    }\n\n    return opacities[VV_OPACITY_N - 1];\n  }\n#endif\n\n"},ribbonLine:{"colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nuniform vec4 eColor;\nvarying vec4 vColor;\nvarying vec2 vtc;\nvarying vec3 vpos;\n\n#ifdef STIPPLE\nuniform float stippleLengthDoubleInv;\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef STIPPLE\n  if (fract(vtc.x * stippleLengthDoubleInv) > 0.5) {\n    discard;\n  }\n#endif\n\n  gl_FragColor = highlightSlice(eColor * vColor, vpos);\n}\n","highlightPass.frag":"#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nvarying vec2 vtc;\nvarying vec3 vpos;\n\n#ifdef STIPPLE\nuniform float stippleLengthDoubleInv;\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef STIPPLE\n  if (fract(vtc.x * stippleLengthDoubleInv) > 0.5) {\n    discard;\n  }\n#endif\n\n  gl_FragColor = vec4(1.0, 1.0, 1.0, 1.0);\n}\n","ribbonLine.vert":'#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nuniform float extLineWidth;\nuniform float nearPlane;\nuniform float pixelRatio;\n\nattribute vec3 position;\nattribute vec2 uv0;\nattribute vec4 color;\n\nvarying vec2 vtc;\nvarying vec4 vColor;\nvarying vec3 vpos;\n\nattribute float size;\n\n#ifndef WALL\nuniform float miterLimit;\nattribute vec3 auxpos1;\nattribute vec3 auxpos2;\n#endif\n\n#ifdef SCREENSCALE\nuniform vec2 screenSize;\n\nvec4 toScreenCoords(vec3 vertex) {\n  vec4 vClipSpace = proj * view * vec4((model * vec4(vertex, 1.0)).xyz, 1.0);\n  vClipSpace.xy *= screenSize;\n  return vClipSpace/abs(vClipSpace.w);\n}\n\n#define VECTYPE vec2\n#define ZEROVEC vec2(0.0, 0.0)\n#define PERPENDICULAR(v) vec2(v.y, -v.x);\n#define ISOUTSIDE (left.x * right.y - left.y * right.x)*uv0.y > 0.0\n\n#else //ifdef SCREENSCALE\n\n#define VECTYPE vec3\n#define ZEROVEC vec3(0.0, 0.0, 0.0)\n// these macros are only valid for "strip" type lines:\n#define PERPENDICULAR(v) cross(up/*vec3(0.0, 1.0, 0.0)*/, v)\n#define ISOUTSIDE dot(cross(left, right), up/*vec3(0.0, 1.0, 0.0)*/)*uv0.y < 0.0\n\n#endif //ifdef SCREENSCALE\n\nfloat interp(float ncp, vec4 a, vec4 b) {\n  return (-ncp - a.z) / (b.z - a.z);\n}\n\n#ifdef SCREENSCALE\n\nvoid clipAndTransform(inout vec4 pos, inout vec4 prev, inout vec4 next) {\n  float vnp = nearPlane*0.99;\n\n  //We have four vertices per point on the line. Start and end vertices\n  //are treated differently --\x3e d > 0, d < 0\n  float d = abs(uv0.y) - 1.1;\n\n  //current pos behind ncp --\x3e we need to clip\n  if(pos.z > -nearPlane) {\n    if (d < 0.0) {\n      //previous in front of ncp\n      if(prev.z < -nearPlane) {\n        pos = mix(prev, pos, interp(vnp, prev, pos));\n        next = pos;\n      } else {\n        pos = vec4(0.0, 0.0, 0.0, 1.0);\n      }\n    }\n    //next in front of ncp\n    if(d > 0.0) {\n      if(next.z < -nearPlane) {\n        pos = mix(pos, next, interp(vnp, pos, next));\n        prev = pos;\n      } else {\n        pos = vec4(0.0, 0.0, 0.0, 1.0);\n      }\n    }\n  } else {\n    //current position visible\n    //previous behind ncp\n    if (prev.z > -nearPlane) {\n      prev = mix(pos, prev, interp(vnp, pos, prev));\n    }\n    //next behind ncp\n    if (next.z > -nearPlane) {\n      next = mix(next, pos, interp(vnp, next, pos));\n    }\n  }\n\n  pos= proj * pos;\n  pos.xy *= screenSize;\n  pos /= pos.w;\n\n  next = proj * next;\n  next.xy *= screenSize;\n  next /= next.w;\n\n  prev = proj * prev;\n  prev.xy *= screenSize;\n  prev /= prev.w;\n}\n\n#endif // SCREENSCALE\n\nvoid main(void) {\n  vpos = (model * vec4(position, 1.0)).xyz;\n\n#ifdef SCREENSCALE\n// Check for special value of uv0.y which is used by the Renderer when graphics\n// are removed before the VBO is recompacted. If this is the case, then we just\n// project outside of clip space.\nif (uv0.y == 0.0) {\n  // Project out of clip space\n  gl_Position = vec4(1e038, 1e038, 1e038, 1.0);\n}\nelse {\n#endif\n\nfloat lineWidth = (extLineWidth + size) * pixelRatio;\n\n#ifdef SCREENSCALE\n\n#if 0\n  vec4 pos = toScreenCoords(position.xyz);\n  vec2 left = (pos - toScreenCoords(auxpos1)).xy;\n  vec2 right = (toScreenCoords(auxpos2) - pos).xy;\n#else\n  vec4 pos  = view * vec4((model * vec4(position.xyz, 1.0)).xyz, 1.0);\n  vec4 prev = view * vec4((model * vec4(auxpos1.xyz, 1.0)).xyz, 1.0);\n  vec4 next = view * vec4((model * vec4(auxpos2.xyz, 1.0)).xyz, 1.0);\n\n  clipAndTransform(pos, prev, next);\n\n  vec2 left = (pos - prev).xy;\n  vec2 right = (next - pos).xy;\n#endif\n\n#else // ifdef SCREENSCALE\n  vec4 pos = vec4(position, 1.0);\n#ifndef WALL\n  vec3 left = position.xyz - auxpos1;\n  vec3 right = auxpos2 - position.xyz;\n  vec3 up = normalize(position.xyz);\n#endif // ifndef WALL\n#endif // ifdef SCREENSCALE\n\n#ifdef WALL\n  float displacementLen = lineWidth;\n  vec3 displacementDir = normalize(position.xyz);//vec3(0.0, 1.0, 0.0);\n#else // ifdef WALL\n\n  float leftLen = length(left);\n  left = (leftLen > 0.001) ? left/leftLen : ZEROVEC;\n\n  float rightLen = length(right);\n  right = (rightLen > 0.001) ? right/rightLen : ZEROVEC;\n\n  // determine if vertex is on the "outside or "inside" of the join\n  bool isOutside = ISOUTSIDE;\n\n  // compute miter join position first\n  float displacementLen = lineWidth;\n  VECTYPE displacementDir = normalize(left + right);\n  displacementDir = PERPENDICULAR(displacementDir);\n  if (leftLen > 0.001 && rightLen > 0.001) {\n    float nDotSeg = dot(displacementDir, left);\n    displacementLen /= length(nDotSeg*left - displacementDir);\n\n    // limit displacement of inner vertices\n    if (!isOutside) {\n      displacementLen = min(displacementLen, min(leftLen, rightLen)/abs(nDotSeg));\n    }\n  }\n\n  if (isOutside && (displacementLen > miterLimit*lineWidth)) {\n    // convert to bevel join if miterLimit is exceeded\n    if (leftLen < 0.001) {\n      displacementDir = right;\n    }\n    else if (rightLen < 0.001) {\n      displacementDir = left;\n    }\n    else {\n      displacementDir = (abs(uv0.y) - 1.1 < 0.0) ? left : right;\n    }\n    displacementDir = normalize(displacementDir);\n    displacementDir = PERPENDICULAR(displacementDir);\n    displacementLen = lineWidth;\n  }\n\n#endif // ifdef WALL\n\n#ifdef SCREENSCALE\n  pos.xy += displacementDir * floor(uv0.y + 0.5) * displacementLen;\n  pos.xy /= screenSize;\n#else\n  pos.xyz += displacementDir * floor(uv0.y + 0.5) * displacementLen;\n  pos = proj * view * model * pos;\n#endif\n\n  vtc = uv0;\n  vColor = color * 0.003921568627451; // = 1/255\n  gl_Position = pos;\n\n#ifdef SCREENSCALE\n  }\n#endif\n}\n'},slicePlane:{"slicePlane.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n\nuniform vec4 backgroundColor;\nuniform vec4 gridColor;\nuniform float ratio;\nuniform float gridWidth;\n\nvarying vec2 vUV;\n\nvoid main() {\n  const float LINE_WIDTH = 1.0;\n\n  vec2 uvScaled = vUV * gridWidth;\n  vec2 gridUV = (fract(uvScaled + 0.5) - 0.5) / (LINE_WIDTH * fwidth(uvScaled));\n  vec2 grid = (1.0 - step(0.5, gridUV)) * step(-0.5, gridUV);\n\n  // mask aliasing along edges\n  grid.x *= step(0.5, uvScaled.x) * step(uvScaled.x, gridWidth - 0.5);\n  grid.y *= step(0.5, uvScaled.y) * step(uvScaled.y, gridWidth - 0.5);\n\n  float gridFade = max(grid.x, grid.y);\n\n  float gridAlpha = gridColor.a * gridFade;\n\n  // premultiply alpha in output\n  gl_FragColor =\n    vec4(backgroundColor.rgb * backgroundColor.a, backgroundColor.a) * (1.0 - gridAlpha) +\n    vec4(gridColor.rgb, 1.0) * gridAlpha;\n}\n","slicePlane.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vUV = uv0;\n  gl_Position = proj * view * vec4((model * vec4(position, 1.0)).xyz, 1.0);\n}\n"}},misc:{"blendLayers.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec2 uv;\n\nuniform sampler2D tex;\nuniform float opacity;\n\nvoid main() {\n  vec4 color = texture2D(tex, uv);\n\n  // Note: output in pre-multiplied alpha for correct alpha compositing\n  gl_FragColor = vec4(color.xyz, 1.0) * color.a * opacity;\n}\n","blendLayers.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nuniform float scale;\nuniform vec2 offset;\n\nvarying vec2 uv;\n\nvoid main(void) {\n  gl_Position = vec4(position, 1.0);\n  uv = uv0 * scale + offset;;\n}\n","texOnly.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\nuniform vec4 color;\nvarying vec2 vtc;\n\nvoid main() {\n  vec4 texColor = texture2D(tex, vtc);\n  gl_FragColor = texColor * color;\n}\n","texOnly.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec2 vtc;\n\nvoid main(void) {\n  gl_Position = vec4(position, 1.0);\n  vtc = uv0;\n}\n"},pointRenderer:{"pointRenderer.frag":"#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n\n#ifdef DEPTH_PASS\nvarying float depth;\n#else\nvarying vec3 vColor;\n#endif\n\nvoid main(void) {\n  vec2 vOffset = gl_PointCoord - vec2(0.5, 0.5);\n  float r2 = dot(vOffset, vOffset);\n\n  if (r2 > 0.25) {\n    discard;\n  }\n\n#ifdef DEPTH_PASS\n  gl_FragColor = float2rgba(depth);\n#else\n  gl_FragColor = vec4(vColor, 1.0);\n#endif\n}\n","pointRenderer.vert":"#include <util/slice.glsl>\n#include <util/vsPrecision.glsl>\n\nattribute vec3 aPosition;\nattribute vec3 aColor;\n\nuniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\nuniform vec2 uScreenMinMaxSize;\nuniform vec2 uPointScale;\nuniform vec3 uClipMin;\nuniform vec3 uClipMax;\n\n#ifdef DEPTH_PASS\nuniform vec2 nearFar;\n\nvarying float depth;\n#else\nvarying vec3 vColor;\n#endif\n\nvoid main(void) {\n\n  // Move clipped points outside of clipspace\n  if (aPosition.x < uClipMin.x || aPosition.y < uClipMin.y || aPosition.z < uClipMin.z ||\n      aPosition.x > uClipMax.x || aPosition.y > uClipMax.y || aPosition.z > uClipMax.z) {\n    gl_Position = vec4(0.0,0.0,0.0,2.0);\n    gl_PointSize = 0.0;\n    return;\n  }\n\n  if (rejectBySlice(aPosition)) {\n    gl_Position = vec4(0.0,0.0,0.0,2.0);\n    gl_PointSize = 0.0;\n    return;\n  }\n\n  // Position in camera space\n  vec4 camera = uModelViewMatrix * vec4(aPosition, 1.0);\n\n  float pointSize = uPointScale.x;\n  vec4 position = uProjectionMatrix * camera;\n\n  // Calculate Size\n#ifdef DRAW_SCREEN_SIZE\n    float clampedScreenSize = pointSize;\n#else\n    float pointRadius = 0.5 * pointSize;\n    vec4 cameraOffset = camera + vec4(0.0, pointRadius, 0.0, 0.0);\n    vec4 positionOffset = uProjectionMatrix * cameraOffset;\n    float radius = abs(positionOffset.y - position.y);\n\n    float viewHeight = uPointScale.y;\n\n    // screen diameter = (2 * r / w) * (h / 2)\n    float screenPointSize = (radius / position.w) * viewHeight;\n    float clampedScreenSize = clamp(screenPointSize, uScreenMinMaxSize.x, uScreenMinMaxSize.y);\n\n    // Shift towards camera, to move rendered point out of terrain i.e. to\n    // the camera-facing end of the virtual point when considering it as a\n    // 3D sphere.\n    camera.xyz -= normalize(camera.xyz) * pointRadius * clampedScreenSize / screenPointSize;\n    position = uProjectionMatrix * camera;\n#endif\n\n  gl_PointSize = clampedScreenSize;\n  gl_Position = position;\n\n#ifdef DEPTH_PASS\n  depth = (-camera.z - nearFar[0]) / (nearFar[1] - nearFar[0]);\n#else\n  vColor = aColor;\n#endif\n}\n"},renderer:{highlight:{"apply.frag":"#include <util/fsPrecision.glsl>\n\n// ===============================================================================\n// Merging blurred outlines with source image, advanced version\n\n// Defines:\n// GRID_OPTIMIZATION (set or !set)\n// GRID_DEBUG (set or !set)\n// ===============================================================================\n\nuniform sampler2D tex;\nuniform sampler2D origin;\n\nuniform vec4 color;\nuniform float outlineSize;\nuniform float blurSize;\nuniform vec4 opacities; // [outline, outlineOccluded, fill, fillOccluded]\n\nvarying vec2 uv;\n\nvoid main() {\n  #if defined(GRID_OPTIMIZATION) && defined(GRID_DEBUG)\n    gl_FragColor = vec4(uv, 0.0, 1.0);\n  #else\n    // Read the highlight intensity from the blurred highlight image\n    vec4 blurredHighlightValue = texture2D(tex, uv);\n    float highlightIntensity = blurredHighlightValue.a;\n\n    // Discard all pixels which are not affected by highlight\n    if (highlightIntensity == 0.0) {\n      discard;\n    }\n\n    vec4 origin_color = texture2D(origin, uv);\n\n    float outlineIntensity;\n    float fillIntensity;\n\n    // if occluded\n    if (blurredHighlightValue.g > blurredHighlightValue.b) {\n      outlineIntensity = color.w * opacities[1];\n      fillIntensity = color.w * opacities[3];\n    }\n    // if unoccluded\n    else {\n      outlineIntensity = color.w * opacities[0];\n      fillIntensity = color.w * opacities[2];\n    }\n\n    float inner = 1.0 - outlineSize / 9.0;\n    float outer = 1.0 - (outlineSize + blurSize) / 9.0;\n\n    float outlineFactor = smoothstep(outer, inner, highlightIntensity);\n    //float fillFactor = smoothstep(0.6, 0.72, highlightIntensity);\n    float fillFactor = any(notEqual(origin_color, vec4(0.0, 0.0, 0.0, 0.0))) ? 1.0 : 0.0;\n    float intensity = outlineIntensity * outlineFactor * (1.0 - fillFactor) + fillIntensity * fillFactor;\n\n    // Blending equation: gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);\n    // I.e., color should not be premultiplied with alpha\n    gl_FragColor = vec4(color.xyz, intensity);\n  #endif\n}\n","apply.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nvarying vec2 uv;\n\n#ifdef GRID_OPTIMIZATION\n  attribute vec2 uv0;\n  uniform sampler2D coverageTex;\n#endif\n\nvoid main() {\n  #ifdef GRID_OPTIMIZATION\n    #ifdef GRID_DEBUG\n      vec4 cov = texture2D(coverageTex, uv0);\n      // if no highlight pixel set in this block,\n      // or all pixels set, hide block\n      if (cov.r == 0.0 || cov.g == 1.0 || cov.b == 1.0) {\n        gl_Position = vec4(0.0);\n        return;\n      }\n      gl_Position = vec4(position, .0, 1.0);\n      uv = uv0;\n      return;\n    #else\n      vec4 cov = texture2D(coverageTex, uv0);\n      // if no highlight pixel set in this block, hide block\n      if (cov.r == 0.0) {\n        gl_Position = vec4(0.0);\n        return;\n      }\n    #endif\n  #endif\n\n  gl_Position = vec4(position, .0, 1.0);\n  uv = position.xy * .5 + vec2(.5);\n}\n","blur.frag":"#include <util/fsPrecision.glsl>\n\n// ===============================================================================\n// Gaussian blur with linear sampling. Supports different number of samples, but\n// only 5 samples have proper weights. Uses linear texture interpolation to reduce\n// the number of samples taken.\n\n// Defines:\n// GRID_OPTIMIZATION (set or !set)\n// GAUSSIAN_SAMPLES (3,5,7)\n\n// This technique requires linear filtering on source texture\n// http://rastergrid.com/blog/2010/09/efficient-gaussian-blur-with-linear-sampling/\n// ===============================================================================\n\nuniform sampler2D tex;\n\n#ifdef GRID_OPTIMIZATION\n  uniform vec2 blurSize;\n  varying vec3 blurCoordinate;\n#else\n  varying vec2 blurCoordinates[GAUSSIAN_SAMPLES];\n#endif\n\nvoid main() {\n  #ifdef GRID_OPTIMIZATION\n    vec2 uv = blurCoordinate.xy;\n    vec4 center = texture2D(tex, uv);\n\n    // do not blur if no pixel or all pixels in neighborhood are set\n    if (blurCoordinate.z == 1.0) {\n      gl_FragColor = center;\n    }\n    else {\n      vec4 sum = vec4(0.0);\n\n      #if GAUSSIAN_SAMPLES == 3\n        // not proper gaussian weights\n        sum += center * 0.204164;\n        sum += texture2D(tex, uv + blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv - blurSize * 1.407333) * 0.304005;\n      #elif GAUSSIAN_SAMPLES == 5\n        sum += center * 0.204164;\n        sum += texture2D(tex, uv + blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv - blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv + blurSize * 3.294215) * 0.093913;\n        sum += texture2D(tex, uv - blurSize * 3.294215) * 0.093913;\n      #elif GAUSSIAN_SAMPLES == 7\n        // not proper gaussian weights\n        sum += center * 0.204164;\n        sum += texture2D(tex, uv + blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv - blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv + blurSize * 3.294215) * 0.093913;\n        sum += texture2D(tex, uv - blurSize * 3.294215) * 0.093913;\n        sum += texture2D(tex, uv + blurSize * 5.1) * 0.03;\n        sum += texture2D(tex, uv - blurSize * 5.1) * 0.03;\n      #elif GAUSSIAN_SAMPLES == 9\n        // not proper gaussian weights\n        sum += center * 0.154164;\n        sum += texture2D(tex, uv + blurSize * 1.5) * 0.204005;\n        sum += texture2D(tex, uv - blurSize * 1.5) * 0.204005;\n        sum += texture2D(tex, uv + blurSize * 3.5) * 0.123913;\n        sum += texture2D(tex, uv - blurSize * 3.5) * 0.123913;\n        sum += texture2D(tex, uv + blurSize * 5.5) * 0.123913;\n        sum += texture2D(tex, uv - blurSize * 5.5) * 0.123913;\n        sum += texture2D(tex, uv + blurSize * 7.5) * 0.05;\n        sum += texture2D(tex, uv - blurSize * 7.5) * 0.05;\n      #endif\n\n      gl_FragColor = sum;\n    }\n  #else\n    vec4 sum = vec4(0.0);\n\n    #if GAUSSIAN_SAMPLES == 3\n      // not proper gaussian weights\n      sum += texture2D(tex, blurCoordinates[0]) * 0.204164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.304005;\n    #elif GAUSSIAN_SAMPLES == 5\n      sum += texture2D(tex, blurCoordinates[0]) * 0.204164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[3]) * 0.093913;\n      sum += texture2D(tex, blurCoordinates[4]) * 0.093913;\n    #elif GAUSSIAN_SAMPLES == 7\n      // not proper gaussian weights\n      sum += texture2D(tex, blurCoordinates[0]) * 0.204164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[3]) * 0.093913;\n      sum += texture2D(tex, blurCoordinates[4]) * 0.093913;\n      sum += texture2D(tex, blurCoordinates[5]) * 0.03;\n      sum += texture2D(tex, blurCoordinates[6]) * 0.03;\n    #elif GAUSSIAN_SAMPLES == 9\n      // not proper gaussian weights\n      sum += texture2D(tex, blurCoordinates[0]) * 0.154164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.204005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.204005;\n      sum += texture2D(tex, blurCoordinates[3]) * 0.123913;\n      sum += texture2D(tex, blurCoordinates[4]) * 0.123913;\n      sum += texture2D(tex, blurCoordinates[5]) * 0.09;\n      sum += texture2D(tex, blurCoordinates[6]) * 0.09;\n      sum += texture2D(tex, blurCoordinates[7]) * 0.05;\n      sum += texture2D(tex, blurCoordinates[8]) * 0.05;\n    #endif\n\n    gl_FragColor = sum;\n  #endif\n}\n","blur.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nattribute vec2 uv0;\n\n#ifdef GRID_OPTIMIZATION\n  uniform sampler2D coverageTex;\n  varying vec3 blurCoordinate;\n#else\n  uniform vec2 blurSize;\n  varying vec2 blurCoordinates[GAUSSIAN_SAMPLES];\n#endif\n\nvoid main() {\n  gl_Position = vec4(position, 0.0, 1.0);\n\n  #ifdef GRID_OPTIMIZATION\n    // sample the coverage texture at the block center\n    // and if no coverage detected, create degenerate triangle\n    vec4 cov = texture2D(coverageTex, uv0);\n    if (cov.r == 0.0) {\n      gl_Position = vec4(0.0);\n    }\n\n    // create texture coordinate for blur center\n    // encode information about fully inside block in z coordinate\n    blurCoordinate = vec3(gl_Position.xy * .5 + vec2(.5), max(cov.g, cov.b));\n  #else\n    vec2 uv = position.xy * .5 + vec2(.5);\n\n    #if GAUSSIAN_SAMPLES == 3\n      // not proper gaussian weights\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n    #elif GAUSSIAN_SAMPLES == 5\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n      blurCoordinates[3] = uv + blurSize * 3.294215;\n      blurCoordinates[4] = uv - blurSize * 3.294215;\n    #elif GAUSSIAN_SAMPLES == 7\n      // not proper gaussian weights\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n      blurCoordinates[3] = uv + blurSize * 3.294215;\n      blurCoordinates[4] = uv - blurSize * 3.294215;\n      blurCoordinates[5] = uv + blurSize * 5.1;\n      blurCoordinates[6] = uv - blurSize * 5.1;\n    #elif GAUSSIAN_SAMPLES == 9\n      // not proper gaussian weights\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n      blurCoordinates[3] = uv + blurSize * 3.294215;\n      blurCoordinates[4] = uv - blurSize * 3.294215;\n      blurCoordinates[5] = uv + blurSize * 5.1;\n      blurCoordinates[6] = uv - blurSize * 5.1;\n      blurCoordinates[7] = uv + blurSize * 7.1;\n      blurCoordinates[8] = uv - blurSize * 7.1;\n    #endif\n  #endif\n}\n","downsample.frag":"#include <util/fsPrecision.glsl>\n\n// ===============================================================================\n// Smartly downsamples a texture, halfing its resolution. This allows for a square\n// screen region to check if none, any or all pixels were set.\n\n// The red channel is always ceiled after interpolating the 4 merged pixels.\n// This allows to evaluate:\n// any(pixels.red != 0.0) as red == 1.0\n// none(pixels.red != 0.0) as red == 0.0\n\n// The green and blue channels are set to floor(max(green, blue)).\n// This allows to evaluate:\n// all(pixels.green || pixels.blue) as green == 1.0\n// ===============================================================================\n\nuniform sampler2D tex;\nuniform vec2 invFramebufferDim;\n\nvoid main() {\n  vec2 coord = gl_FragCoord.xy * invFramebufferDim;\n  vec4 value = texture2D(tex, coord);\n  float mx = floor(max(value.g, value.b));\n  gl_FragColor = vec4(ceil(value.r), mx, mx, 1.0);\n}\n","downsample.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\n\nvoid main() {\n  gl_Position = vec4(vec2(1.0) - position * 2.0, .0, 1.0);\n}\n"},laserLine:{"laserLine.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/depth.glsl>\n\n//--------------------------------------------------------------------------\n// Uniforms\n//--------------------------------------------------------------------------\n\nuniform sampler2D depthMap;\n\nuniform vec2 nearFar;\nuniform vec4 projInfo;\nuniform vec2 zScale;\nuniform float maxPixelDistance;\n\n// focus plane in camera space\nuniform vec4 focusPlane;\n\n// focus sphere in camera space\nuniform vec4 focusSphere;\n\n// segment plane in camera space\nuniform vec4 segmentPlane;\n\n// line segment\nuniform vec3 segmentStart;\nuniform vec3 segmentEnd;\n\n// styling\nuniform vec3 glowColor;\nuniform float glowWidth;\nuniform vec3 innerColor;\nuniform float innerWidth;\nuniform float globalAlpha;\n\n//--------------------------------------------------------------------------\n// Inputs\n//--------------------------------------------------------------------------\n\nvarying vec2 uv;\n\n//--------------------------------------------------------------------------\n// Defines\n//--------------------------------------------------------------------------\n\n#define INFINITY 100000.0\n\n// reconstruct position in view space\nvec3 reconstructPosition(vec2 fragCoord, float depth) {\n  return vec3((fragCoord * projInfo.xy + projInfo.zw) * (zScale.x * depth + zScale.y), depth);\n}\n\nfloat planeDistancePixels(vec4 plane, vec3 pos) {\n  // compute distance to plane\n  float dist = dot(plane.xyz, pos) + plane.w;\n  // compute derivative of distance function with respect to pixels\n  float width = fwidth(dist);\n  // normalize distance by the derivative to get a measurement with respect to pixels\n  // the clamping is used to prevent excessive artifacts along depth discontinuities\n  dist /= min(width, maxPixelDistance);\n  return abs(dist);\n}\n\nfloat sphereDistancePixels(vec4 sphere, vec3 pos) {\n  // compute distance to sphere\n  float dist = distance(sphere.xyz, pos) - sphere.w;\n  // compute derivative of distance function with respect to pixels\n  float width = fwidth(dist);\n  // normalize distance by the derivative to get a measurement with respect to pixels\n  // the clamping is used to prevent excessive artifacts along depth discontinuities\n  dist /= min(width, maxPixelDistance);\n  return abs(dist);\n}\n\nvec4 blendPremultiplied(vec4 source, vec4 dest) {\n  float oneMinusSourceAlpha = 1.0 - source.a;\n\n  return vec4(\n    source.rgb + dest.rgb * oneMinusSourceAlpha,\n    source.a + dest.a * oneMinusSourceAlpha\n  );\n}\n\nvec4 premultipliedColor(vec3 rgb, float alpha) {\n  return vec4(rgb * alpha, alpha);\n}\n\n// computes laser line color based on distance in pixels\nvec4 laserLineProfile(float dist) {\n  if (dist > glowWidth) {\n    return vec4(0.0);\n  }\n\n  float innerAlpha = (1.0 - smoothstep(0.0, innerWidth, dist));\n  float glowAlpha = pow(max(0.0, 1.0 - dist / glowWidth), 8.0);\n\n  return blendPremultiplied(\n    premultipliedColor(innerColor, innerAlpha),\n    premultipliedColor(glowColor, glowAlpha)\n  );\n}\n\nvoid main() {\n  // do not draw laserline on background\n  float depth = linearDepth(depthMap, uv, nearFar);\n  if (-depth == nearFar[0]) {\n    discard;\n  }\n\n  // reconstruct position in view space\n  vec3 pos = reconstructPosition(gl_FragCoord.xy, depth);\n\n  // empirical hack to fade out laser line in problematic areas:\n  // the derivatives to normalize the distance function are valid inside smooth surfaces,\n  // but break down at depth discontinuities (e.g. edges). We fade out the laser lines in\n  // areas where depth valus have large variations in order to avoid this problem.\n  float ddepth = fwidth(depth);\n  float depthDiscontinuityAlpha = 1.0 - smoothstep(0.0, 0.01, -ddepth / depth);\n\n  // reconstruct normal using derivatives\n  vec3 normal = normalize(cross(dFdx(pos), dFdy(pos)));\n\n  // distance to focus plane\n  float focusPlaneDistance = planeDistancePixels(focusPlane, pos);\n\n  // distance to focus sphere\n  float focusSphereDistance = sphereDistancePixels(focusSphere, pos);\n\n  // distance to segment plane\n  float segmentDistance = INFINITY;\n  float segmentLength = length(segmentEnd - segmentStart);\n  vec3 segmentDir = (segmentEnd - segmentStart) / segmentLength;\n  float t = dot(segmentDir, pos - segmentStart);\n\n  if (segmentLength > 0.0 && t >= 0.0 && t <= segmentLength) {\n    segmentDistance = planeDistancePixels(segmentPlane, pos);\n  }\n\n  // evaluate color profile for both planes and the sphere\n  vec4 focusPlaneColor = laserLineProfile(focusPlaneDistance);\n  vec4 focusSphereColor = laserLineProfile(focusSphereDistance);\n  vec4 segmentColor = laserLineProfile(segmentDistance);\n\n  // empirical hack to fade out laser line when planes are nearly parallel\n  float focusPlaneAlpha = 1.0 - smoothstep(0.995, 0.999, abs(dot(normal, focusPlane.xyz)));\n  float focusSphereAlpha = 1.0 - smoothstep(0.995, 0.999, abs(dot(normal, normalize(pos - focusSphere.xyz))));\n  float segmentAlpha = 1.0 - smoothstep(0.995, 0.999, abs(dot(normal, segmentPlane.xyz)));\n\n  // combine colors\n  vec4 color = max(\n    focusPlaneColor * focusPlaneAlpha,\n    max(\n      focusSphereColor * focusSphereAlpha,\n      segmentColor * segmentAlpha\n    )\n  );\n\n  gl_FragColor = color * globalAlpha * depthDiscontinuityAlpha;\n}\n"},offscreen:{"composite.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\n\nvarying vec2 vtc;\n\nvoid main() {\n  gl_FragColor = texture2D(tex, vtc);\n}\n","compositeOccluded.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D occludedColorMap;\nuniform float opacity;\n\nvarying vec2 vtc;\n\nvoid main() {\n  vec4 occludedColor = texture2D(occludedColorMap, vtc);\n  gl_FragColor = occludedColor * opacity;\n}\n","compositeTransparentToHUDVisibility.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\n\nvarying vec2 vtc;\n\nvoid main() {\n  gl_FragColor = vec4(1.0 - texture2D(tex, vtc).a);\n}\n","offscreen.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nvarying vec2 vtc;\n\nvoid main(void) {\n  gl_Position = vec4(position.xy, 0.0, 1.0);\n  vtc = position.xy * 0.5 + 0.5;\n}\n"},ssao:{"blur.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/depth.glsl>\n\n#ifndef RADIUS\n#define RADIUS 4\n#endif\n\nuniform sampler2D normalMap;\nuniform sampler2D depthMap;\nuniform sampler2D tex;\n\nuniform vec2 blurSize;\n\nuniform float g_BlurFalloff;\nuniform float projScale;\n\nuniform vec2 nearFar;\n//set z scaling, used to prevent division in ortho mode\nuniform vec2 zScale;\n\nvarying vec2 uv;\n\nfloat BlurFunction(vec2 uv, float r, float center_d, inout float w_total, float sharpness) {\n  float c = texture2D(tex, uv).r;\n  float d = linearDepth(depthMap, uv, nearFar);\n\n  float ddiff = d - center_d;\n\n  float w = exp(-r*r*g_BlurFalloff - ddiff*ddiff*sharpness);\n\n  w_total += w;\n\n  return w*c;\n}\n\nvoid main(void) {\n  float b = 0.0;\n  float w_total = 0.0;\n\n  float center_d = linearDepth(depthMap, uv, nearFar);\n\n  float sharpness = -0.05 * projScale/(center_d*zScale.x+zScale.y);\n  for (int r = -RADIUS; r <= RADIUS; ++r) {\n    float rf = float(r);\n    vec2 uvOffset = uv + rf*blurSize;\n    b += BlurFunction(uvOffset, rf, center_d, w_total, sharpness);\n  }\n\n  gl_FragColor = vec4(b/w_total);\n}\n","ssao.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/depth.glsl>\n\n#ifndef SAMPLES\n#define SAMPLES 4\n#endif\n\nuniform mat4 projMatrixInv;\n\nuniform sampler2D normalMap;\nuniform sampler2D depthMap;\n\nuniform float intensity;\n\nuniform float projScale;\nuniform float radius;\nuniform vec2 nearFar;\nuniform vec4 projInfo;\nuniform vec2 screenDimensions;\n\n//noise texture lookup could be replaced with hash function if WebGL gets XOR functionality\nuniform vec3 pSphere[SAMPLES]; //tap position\nuniform vec2 rnmScale;\nuniform sampler2D rnm; //noise texture\n\n//set z scaling, used to prevent division in ortho mode\nuniform vec2 zScale;\n\nvarying vec2  uv;\nvarying vec4  camPos;\n\nfloat fallOffFunction(float vv, float vn, float bias) {\n  float radius2 = radius * radius;\n\n  // A: From the HPG12 paper\n  // Note large epsilon to avoid overdarkening within cracks\n  // return float(vv < radius2) * max((vn - bias) / (epsilon + vv), 0.0) * radius2 * 0.6;\n\n  // B: Smoother transition to zero (lowers contrast, smoothing out corners). [Recommended]\n  float f = max(radius2 - vv, 0.0); return f * f * f * max(vn-bias, 0.0);\n\n  // C: Medium contrast (which looks better at high radii), no division.  Note that the\n  // contribution still falls off with radius^2, but we've adjusted the rate in a way that is\n  // more computationally efficient and happens to be aesthetically pleasing.\n  // return 4.0 * max(1.0 - vv * invRadius2, 0.0) * max(vn - bias, 0.0);\n\n  // D: Low contrast, no division operation\n  // return 2.0 * float(vv < radius * radius) * max(vn - bias, 0.0);\n}\n\n\n/** Compute the occlusion due to sample point \\a Q about camera-space point \\a C with unit normal \\a n_C */\nfloat aoValueFromPositionsAndNormal(vec3 C, vec3 n_C, vec3 Q) {\n  vec3 v = Q - C;\n  float vv = dot(v, v);\n  float vn = dot(normalize(v), n_C);\n  return fallOffFunction(vv, vn, 0.1);\n}\n\n\n/**\n * Reconstruct camera-space P.xyz from screen-space S = (x, y) in\n * pixels and camera-space z < 0.  Assumes that the upper-left pixel center\n * is at (0.5, 0.5) [but that need not be the location at which the sample tap\n * was placed!]\n *\n * Costs 3 MADD.  Error is on the order of 10^3 at the far plane, partly due to z precision.\n */\nvec3 reconstructCSPosition(vec2 S, float z) {\n  return vec3(( (S.xy) * projInfo.xy + projInfo.zw)*(z*zScale.x+zScale.y), z);\n}\n\nvoid main(void) {\n  //Hash function used in the HPG12 AlchemyAO paper\n  //Not supported in WebGL -> using texture lookup as in old SSAO shader instead\n  //ivec2 ssC = ivec2(gl_FragCoord.xy);\n  //float randomPatternRotationAngle = float((3 * ssC.x ^ ssC.y + ssC.x * ssC.y) * 10);\n  vec3 fres = normalize((texture2D(rnm, uv * rnmScale).xyz * 2.0) - vec3(1.0));\n\n  float currentPixelDepth = linearDepth(depthMap, uv, nearFar);\n\n  if (-currentPixelDepth>nearFar.y || -currentPixelDepth<nearFar.x) {\n    gl_FragColor = vec4(0.0);\n    return;\n  }\n\n  vec3 currentPixelPos = reconstructCSPosition(gl_FragCoord.xy,currentPixelDepth);\n\n  // get the normal of current fragment\n  vec4 norm4 = texture2D(normalMap, uv);\n  vec3 norm = vec3(-1.0) + 2.0 * norm4.xyz;\n  bool isTerrain = norm4.w<0.5;\n\n  float sum = .0;\n\n  vec4 occluderFragment;\n  vec3 ray;\n\n  vec3 tapPixelPos;\n\n  // note: the factor 2.0 should not be necessary, but makes ssao much nicer.\n  // bug or deviation from CE somewhere else?\n  float ps = projScale/(2.0*currentPixelPos.z*zScale.x+zScale.y);\n\n  for(int i = 0; i < SAMPLES; ++i) {\n    // get a vector (randomized inside of a sphere with radius 1.0) from a texture and reflect it\n    //float ssR;\n    //vec2 unitOffset = tapLocation(i, randomPatternRotationAngle, ssR);\n    // get the depth of the occluder fragment\n    //vec2 offset = vec2(-unitOffset*radius*ssR*ps);\n\n    vec2 unitOffset = reflect(pSphere[i], fres).xy;\n    vec2 offset = vec2(-unitOffset*radius*ps);\n\n    //don't use current or very nearby samples\n    if ( abs(offset.x)<2.0 || abs(offset.y)<2.0) continue;\n\n    vec2 tc = vec2(gl_FragCoord.xy + offset);\n    if (tc.x < 0.0 || tc.y < 0.0 || tc.x > screenDimensions.x || tc.y > screenDimensions.y) continue;\n    vec2 tcTap = tc/screenDimensions;\n    float occluderFragmentDepth = linearDepth(depthMap, tcTap, nearFar);\n\n    if (isTerrain) {\n      bool isTerrainTap = texture2D(normalMap, tcTap).w<0.5;\n      if (isTerrainTap) {\n        continue;\n      }\n    }\n\n    tapPixelPos = reconstructCSPosition(tc, occluderFragmentDepth);\n\n    sum+= aoValueFromPositionsAndNormal(currentPixelPos, norm, tapPixelPos);\n  }\n\n  // output the result\n\n  float A = max(1.0-sum*intensity/float(SAMPLES),0.0);\n\n  // Anti-tone map to reduce contrast and drag dark region farther\n  // (x^0.2 + 1.2 * x^4)/2.2\n  A = (pow(A, 0.2) + 1.2 * A*A*A*A) / 2.2;\n\n  //gl_FragColor = vec4(norm/2.0+0.5, 1.0);\n  //gl_FragColor = vec4(-currentPixelDepth/1000.0);\n  //gl_FragColor = vec4(tapPixelPos.x/100.0);\n  gl_FragColor = vec4(A);\n}\n"}},terrainRenderer:{"colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/sceneLighting.glsl>\n#include <util/screenSizePerspective.glsl>\n#include <util/shadow.glsl>\n#include <util/slice.glsl>\n#include <terrainRenderer/overlay.glsl>\n\nuniform vec3 lightDirection;\nuniform vec3 viewDirection;\nuniform sampler2D depthTex;\nuniform int shadowMapNum;\nuniform vec4 shadowMapDistance;\nuniform mat4 shadowMapMatrix[4];\nuniform float depthHalfPixelSz;\nuniform sampler2D ssaoTex;\nuniform vec4 viewportPixelSz;\nuniform sampler2D tex;\nuniform float opacity;\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\nstruct WireframeSettings {\n  float width;\n  float falloff;\n  float subdivision;\n  vec4 color;\n  float wireOpacity;\n  float surfaceOpacity;\n};\n\nuniform WireframeSettings wireframe;\n#endif\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\nvarying vec2 vtc;\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\nvarying vec2 vuv;\n#endif\n\n#ifdef ATMOSPHERE\nvarying vec3 wpos;\nvarying vec3 wview;\nvarying vec3 wnormal;\nvarying vec3 wlight;\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\nuniform vec4 screenSizePerspective;\n\nvarying float screenSizeDistanceToCamera;\nvarying float screenSizeCosAngle;\n#endif\n\nconst vec3 ambient = vec3(0.2,0.2,0.2);\nconst vec3 diffuse = vec3(0.8,0.8,0.8);\nconst float diffuseHardness = 2.5;\nconst float sliceOpacity = 0.2;\n\n#ifdef OVERLAY\nuniform sampler2D overlay0Tex;\nuniform sampler2D overlay1Tex;\nuniform float overlayOpacity;\nvarying vec4 vtcOverlay;\n#endif\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\nfloat lum(vec3 c) {\n  float max = max(max(c.r, c.g), c.b);\n  float min = min(min(c.r, c.g), c.b);\n  return (min + max) * 0.5;\n}\n\n#ifdef ATMOSPHERE\nvec3 atmosphere(vec3 lightPos, vec3 normal, vec3 view) {\n  vec3 surfaceColor   = vec3(0.0);\n  vec3 fuzzySpecColor = vec3(1.0);\n  vec3 subColor       = vec3(0.0);\n  float rollOff       = 1.0;\n\n  vec3 Ln = normalize(lightPos);\n  vec3 Nn = normalize(normal);\n  vec3 Hn = normalize(view + Ln);\n\n  float ldn = dot(Ln, Nn);\n  float diffComp = max(0.0, ldn);\n  float vdn = 1.0 - dot(view, Nn);\n  float ndv = dot(view, Ln);\n\n  vec3 diffContrib = surfaceColor * diffComp;\n  float subLamb = max(0.0, smoothstep(-rollOff, 1.0, ldn) - smoothstep(0.0, 1.0, ldn));\n\n  vec3 subContrib = subLamb * subColor;\n  vec3 vecColor = vec3(vdn);\n\n  vec3 diffuseContrib = (subContrib + diffContrib);\n  vec3 specularContrib = (vecColor * fuzzySpecColor);\n\n  return (diffContrib + specularContrib) * rollOff;\n}\n#endif\n\nvoid main() {\n  vec3 a = ambient;\n\n  float shadow = 0.0;\n#ifdef RECEIVE_SHADOWS\n  shadow = evalShadow(vpos, linearDepth, depthTex, shadowMapNum, shadowMapDistance, shadowMapMatrix, depthHalfPixelSz);\n#endif\n  float vndl = dot(normalize(vnormal), lightDirection);\n  float k = smoothstep(0.0, 1.0, clamp(vndl*diffuseHardness, 0.0, 1.0));\n  vec3 d = (1.0 - shadow/1.8) * diffuse * k;\n\n  float ssao = viewportPixelSz.w < .0 ? 1.0 : texture2D(ssaoTex, (gl_FragCoord.xy - viewportPixelSz.xy) * viewportPixelSz.zw).a;\n\n  vec4 tileColor = texture2D(tex, vtc) * opacity;\n\n#ifdef OVERLAY\n  vec4 overlayColor = getOverlayColor(overlay0Tex, overlay1Tex, vtcOverlay, overlayOpacity);\n\n  // tileColor and overlayTexCols have pre-multiplied alpha\n  tileColor = tileColor * (1.0 - overlayColor.a) + overlayColor;\n#endif\n\n  if (rejectBySlice(vpos)) {\n    tileColor *= sliceOpacity;\n  }\n\n  vec3 atm = vec3(0.0);\n#ifdef ATMOSPHERE\n  float ndotl = max(0.0, min(1.0, vndl));\n  atm = atmosphere(wlight, wnormal, -viewDirection);\n  atm *= max(0.0, min(1.0, (1.0-lum(tileColor.rgb)*1.5))); //avoid atmosphere on bright base maps\n  atm *= max(0.0, min(1.0, ndotl*2.0)); // avoid atmosphere on dark side of the globe\n  atm *= tileColor.a; // premultiply with tile alpha\n#endif\n\n  vec3 albedo = atm + tileColor.rgb;\n  vec3 normal = normalize(vnormal);\n\n  // heuristic shading function used in the old terrain, now used to add ambient lighting\n  float additionalAmbientScale = smoothstep(0.0, 1.0, clamp(vndl*2.5, 0.0, 1.0));\n  vec3 additionalLight = ssao * lightingMainIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;\n\n  gl_FragColor = vec4(evaluateSceneLighting(normal, albedo, shadow, 1.0 - ssao, additionalLight), tileColor.a);\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\n  // This is only used for debug rendering the screenSize perspective\n\n  float perspectiveScale = screenSizePerspectiveScaleFloat(1.0, screenSizeCosAngle, screenSizeDistanceToCamera, screenSizePerspective);\n\n  if (perspectiveScale <= 0.25) {\n    gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 0.0, 1.0), perspectiveScale * 4.0);\n  }\n  else if (perspectiveScale <= 0.5) {\n    gl_FragColor = mix(gl_FragColor, vec4(0.0, 0.0, 1.0, 1.0), (perspectiveScale - 0.25) * 4.0);\n  }\n  else if (perspectiveScale >= 0.99) {\n    gl_FragColor = mix(gl_FragColor, vec4(0.0, 1.0, 0.0, 1.0), 0.2);\n  }\n  else {\n    gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 1.0, 1.0), (perspectiveScale - 0.5) * 2.0);\n  }\n\n#endif\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\n\n  vec2 vuvScaled = vuv * wireframe.subdivision;\n  vec2 vuvMod = fract(vuvScaled);\n\n  vec2 dVuv = fwidth(vuvScaled);\n  dVuv = max(vec2(0.00001), dVuv); // workaround against flickering skirts, see #10245\n\n  vec2 edgeFactors = smoothstep((wireframe.width - wireframe.falloff) * dVuv,\n                                wireframe.width * dVuv, min(vuvMod, 1.0 - vuvMod));\n\n  float edgeFactor = 1.0 - min(edgeFactors.x, edgeFactors.y);\n\n#ifdef WIREFRAME_TEXTURE\n  vec3 wireframeColor = mix(gl_FragColor.rgb, wireframe.color.rgb, edgeFactor * wireframe.color.a);\n  float wireframeAlpha = mix(wireframe.surfaceOpacity, wireframe.wireOpacity, edgeFactor);\n  gl_FragColor = vec4(wireframeColor * wireframeAlpha, wireframeAlpha * gl_FragColor.a);\n#endif\n\n\n#ifdef TILE_BORDERS\n  dVuv = fwidth(vuv);\n  edgeFactors = smoothstep((wireframe.width - wireframe.falloff) * dVuv,\n                            wireframe.width * dVuv, min(vuv, 1.0 - vuv));\n  edgeFactor = 1.0 - min(edgeFactors.x, edgeFactors.y);\n\n  gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 0.0, 1.0), edgeFactor);\n#endif\n\n#endif // defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\n\n  gl_FragColor = highlightSlice(gl_FragColor, vpos);\n}\n","colorPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform vec3 origin;\nuniform vec4 texOffsetAndScale;\nuniform mat4 viewNormal;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\nvarying vec2 vtc;\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\nvarying vec2 vuv;\n#endif\n\n#ifdef ATMOSPHERE\nuniform vec3 lightDirection;\nvarying vec3 wpos;\nvarying vec3 wview;\nvarying vec3 wnormal;\nvarying vec3 wlight;\n#endif\n\n#ifdef OVERLAY\n// these variables combine two possible overlays into one by using a vec4:\n// components x/y are x/y of overlay 0, and components z/w are x/y of overlay 1\nuniform vec4 overlayTexOffset;\nuniform vec4 overlayTexScale;\nvarying vec4 vtcOverlay;\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\n\nuniform vec4 screenSizePerspective;\n\nvarying float screenSizeDistanceToCamera;\nvarying float screenSizeCosAngle;\n\n#endif\n\nvoid main(void) {\n  vpos = position;\n\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vnormal = normalize(vpos + origin);\n#else\n  vnormal = vec3(0.0, 0.0, 1.0); // WARNING: up-axis dependent code\n#endif\n\nvec2 uv = uv0;\nvpos = applySkirts(uv, vpos, vnormal, skirtScale);\n\n#ifdef ATMOSPHERE\n  wpos = (view * vec4(vpos, 1.0)).xyz;\n  wnormal = (viewNormal * vec4(normalize(vpos+origin), 1.0)).xyz;\n  wlight = (view  * vec4(lightDirection, 1.0)).xyz;\n#endif\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\n  vuv = uv;\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\n\n  vec3 viewPos = (view * vec4(vpos, 1.0)).xyz;\n\n  screenSizeDistanceToCamera = length(viewPos);\n\n  vec3 viewSpaceNormal = (viewNormal * vec4(normalize(vpos + origin), 1.0)).xyz;\n  screenSizeCosAngle = abs(viewSpaceNormal.z);\n\n#endif\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef RECEIVE_SHADOWS\n  // Shadowmap's cascading index used to be based on '1.0 / gl_FragCoord.w'\n  // (i.e. the perspective interpolation of 'gl_Position.w'). Precision\n  // issues on iPad/iPhone with the 'w' component require the depth to be\n  // passed as varying to properly drive the cascading shadow map index.\n  linearDepth = gl_Position.w;\n#endif\n\n  vtc = uv * texOffsetAndScale.zw + texOffsetAndScale.xy;\n\n#ifdef OVERLAY\n  vtcOverlay = vec4(uv, uv) * overlayTexScale + overlayTexOffset;\n#endif\n}\n","depthPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/depth.glsl>\n\nvarying float depth;\nvarying vec3 vpos;\n\nvoid main() {\n#ifndef BIAS_SHADOWMAP\n  gl_FragColor = float2rgba(depth);\n#else\n  gl_FragColor = float2rgba(calcFragDepth(depth));\n#endif\n}\n","depthPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform vec3 origin;\nuniform mat4 proj;\nuniform mat4 view;\nuniform vec2 nearFar;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying float depth;\nvarying vec3 vpos;\n\nvoid main(void) {\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec3 normal = normalize(position + origin);\n#else\n  vec3 normal = vec3(0.0, 0.0, 1.0);\n#endif\n\n  vec2 uv = uv0;\n  vpos = applySkirts(uv, position, normal.xyz, skirtScale);\n\n  vec4 eye = view * vec4(vpos, 1.0);\n  gl_Position = proj * eye;\n  depth = (-eye.z - nearFar[0]) / (nearFar[1] - nearFar[0]) ;\n}\n","highlightPass.frag":"#include <util/fsPrecision.glsl>\n#include <util/highlight.glsl>\n#include <terrainRenderer/overlay.glsl>\n\nuniform sampler2D overlay0Tex;\nuniform sampler2D overlay1Tex;\nuniform float overlayOpacity;\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\nvarying vec4 vtcOverlay;\n\nvoid main() {\n  vec4 overlayColor = getOverlayColor(overlay0Tex, overlay1Tex, vtcOverlay, overlayOpacity);\n\n  if (overlayColor.a == 0.0) {\n    // Here we have to write black, instead of discarding the fragment in order to overwrite\n    // the highlights which might have been written by skirts of other tiles.\n    // As a consequence skirts are not visible, but terrain overwrites draped highlights.\n    gl_FragColor = vec4(0.0);\n    return;\n  }\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","highlightPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform vec3 origin;\nuniform mat4 proj;\nuniform mat4 view;\nuniform vec4 overlayTexScale;\nuniform vec4 overlayTexOffset;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec3 vpos;\nvarying vec4 vtcOverlay;\n\nvoid main() {\n  #if VIEWING_MODE == VIEWING_MODE_GLOBAL\n    vec3 vnormal = normalize(position + origin);\n  #else\n    vec3 vnormal = vec3(0.0, 0.0, 1.0); // WARNING: up-axis dependent code\n  #endif\n\n  vec2 uv = uv0;\n  vpos = applySkirts(uv, position, vnormal, skirtScale);\n\n  vtcOverlay = vec4(uv, uv) * overlayTexScale + overlayTexOffset;\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n}\n","normalPass.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\nvoid main() {\n  vec3 normal = normalize(vnormal);\n  if (gl_FrontFacing == false) normal = -normal;\n\n#ifndef ALPHA_ZERO\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 1.0);\n#else\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 0.0);\n#endif\n}\n","normalPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform vec3 origin;\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 viewNormal;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\nvoid main(void) {\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec4 normal = vec4(normalize(position + origin), 1.0);\n#else\n  vec4 normal = vec4(0.0, 0.0, 1.0, 1.0);\n#endif\n\n  vec2 uv = uv0;\n  vpos = applySkirts(uv, position, normal.xyz, skirtScale);\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n  vnormal = normalize((viewNormal * normal).xyz);\n}\n","overlay.glsl":"vec4 getOverlayColor(sampler2D overlay0Tex, sampler2D overlay1Tex, vec4 texCoords, float opacity) {\n  vec4 color = vec4(0.0);\n\n  // read textures outside of conditions, to avoid artifacts likely related to non-uniform flow control:\n  // - https://www.khronos.org/opengl/wiki/Sampler_(GLSL)#Non-uniform_flow_control\n  // - https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/13657\n  vec4 colorInner = texture2D(overlay0Tex, texCoords.xy);\n  vec4 colorOuter = texture2D(overlay1Tex, texCoords.zw);\n\n  if ((texCoords.x > 0.0) && (texCoords.x < 1.0) && (texCoords.y > 0.0) && (texCoords.y < 1.0)) {\n    // inner overlay texture coordinates are within bounds -> sample from inner overlay\n    color = colorInner;\n  } else if ((texCoords.z > 0.0) && (texCoords.z < 1.0) && (texCoords.w > 0.0) && (texCoords.w < 1.0)) {\n    // sample from outer overlay\n    color = colorOuter;\n  }\n\n  return color * opacity;\n}\n","skirts.glsl":'vec3 applySkirts(inout vec2 uv, vec3 vpos, vec3 vnormal, float skirtScale) {\n  float skirtLength = 0.0;\n\n  if (uv.x >= 2.0) {\n    skirtLength = uv.y * skirtScale;\n    // decode original uv-coordinates (see "encodeSkirtPos")\n    vec2 x = vec2(uv.x) - vec2(3.5, 4.5);\n    uv = clamp(vec2(1.5) - abs(x), vec2(0.0), vec2(1.0));\n  }\n\n  return vpos - vnormal * skirtLength;\n}\n'},util:{"alignPixel.glsl":"vec4 alignToPixelCenter(vec4 clipCoord, vec2 widthHeight) {\n  // From clip space to (0 : 1), bias towards right pixel edge\n  vec2 xy = vec2(.500123) + .5 * clipCoord.xy / clipCoord.w;\n\n  // Size of a pixel in range (0 : 1)\n  vec2 pixelSz = vec2(1.0) / widthHeight;\n\n  // Round to nearest pixel center\n  vec2 ij = (floor(xy * widthHeight) + vec2(0.5)) * pixelSz;\n\n  // Convert back to clip space\n  vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;\n\n  return vec4(result, clipCoord.zw);\n}\n\nvec4 alignToPixelOrigin(vec4 clipCoord, vec2 widthHeight) {\n  // From clip space to (0 : 1),\n  vec2 xy = vec2(.5) + .5 * clipCoord.xy / clipCoord.w;\n\n  // Size of a pixel in range (0 : 1)\n  vec2 pixelSz = vec2(1.0) / widthHeight;\n\n  // Round to nearest pixel border, (0 : 1)\n  vec2 ij = floor((xy + .5 * pixelSz) * widthHeight) * pixelSz;\n\n  // Convert back to clip space\n  vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;\n\n  return vec4(result, clipCoord.zw);\n}\n","color.glsl":"vec4 premultiplyAlpha(vec4 v) {\n  return vec4(v.rgb * v.a, v.a);\n}\n\nvec3 rgb2hsv(vec3 c) {\n  vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n  vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\n  vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\n\n  float d = q.x - min(q.w, q.y);\n  float e = 1.0e-10;\n  return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);\n}\n\nvec3 hsv2rgb(vec3 c) {\n  vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\n  vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\n  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\n}\n","depth.glsl":"#include <util/encoding.glsl>\n\n// read linear depth either from native depth texture or custom depth texture encoded in rgba\nfloat linearDepth(sampler2D depthTex, vec2 uv, vec2 nearFar) {\n  return -(rgba2float(texture2D(depthTex, uv)) * (nearFar[1] - nearFar[0]) + nearFar[0]);\n}\n\nfloat calcFragDepth(const in float depth) {\n  // calc polygon offset\n  const float SLOPE_SCALE = 2.0;\n  const float BIAS = 2.0 * .000015259;    // 1 / (2^16 - 1)\n  float m = max(abs(dFdx(depth)), abs(dFdy(depth)));\n  float result = depth + SLOPE_SCALE * m + BIAS;\n  return clamp(result, .0, .999999);\n}\n","doublePrecision.glsl":"// based on https://www.thasler.com/blog/blog/glsl-part2-emu\nvec3 dpAdd(vec3 hiA, vec3 loA, vec3 hiB, vec3 loB) {\n  vec3 t1 = hiA + hiB;\n  vec3 e = t1 - hiA;\n  vec3 t2 = ((hiB - e) + (hiA - (t1 - e))) + loA + loB;\n  return t1 + t2;\n}\n","enableExtensions.glsl":"#define EXTENSIONS_ENABLED\n#extension GL_OES_standard_derivatives : enable\n#extension GL_EXT_shader_texture_lod : enable\n","encoding.glsl":"// This is the maximum float value representable as 32bit fixed point,\n// it is rgba2float(vec4(1)) inlined.\nconst float MAX_RGBA_FLOAT =\n  255.0 / 256.0 +\n  255.0 / 256.0 / 256.0 +\n  255.0 / 256.0 / 256.0 / 256.0 +\n  255.0 / 256.0 / 256.0 / 256.0 / 256.0;\n\n// Factors to convert to fixed point, i.e. factors (256^0, 256^1, 256^2, 256^3)\nconst vec4 fixedPointFactors = vec4(1.0, 256.0, 256.0 * 256.0, 256.0 * 256.0 * 256.0);\n\nvec4 float2rgba(const float value) {\n  // Make sure value is in the domain we can represent\n  float valueInValidDomain = clamp(value, 0.0, MAX_RGBA_FLOAT);\n\n  // Decompose value in 32bit fixed point parts represented as\n  // uint8 rgba components. Decomposition uses the fractional part after multiplying\n  // by a power of 256 (this removes the bits that are represented in the previous\n  // component) and then converts the fractional part to 8bits.\n  vec4 fixedPointU8 = floor(fract(valueInValidDomain * fixedPointFactors) * 256.0);\n\n  // Convert uint8 values (from 0 to 255) to floating point representation for\n  // the shader\n  const float toU8AsFloat = 1.0 / 255.0;\n\n  return fixedPointU8 * toU8AsFloat;\n}\n\n// Factors to convert rgba back to float\nconst vec4 rgba2float_factors = vec4(\n  255.0 / (256.0),\n  255.0 / (256.0 * 256.0),\n  255.0 / (256.0 * 256.0 * 256.0),\n  255.0 / (256.0 * 256.0 * 256.0 * 256.0)\n);\n\nfloat rgba2float(vec4 rgba) {\n  // Convert components from 0->1 back to 0->255 and then\n  // add the components together with their corresponding\n  // fixed point factors, i.e. (256^1, 256^2, 256^3, 256^4)\n  return dot(rgba, rgba2float_factors);\n}\n","fsPrecision.glsl":"#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\nprecision highp sampler2D;\n#else\nprecision mediump float;\nprecision mediump sampler2D;\n#endif\n","highlight.glsl":"vec4 highlightData(vec4 fragCoord, sampler2D depthTex, vec4 viewportPixelSize) {\n  float sceneDepth = texture2D(depthTex, (fragCoord.xy - viewportPixelSize.xy) * viewportPixelSize.zw).r;\n  if (fragCoord.z > sceneDepth + 5e-7) {\n    return vec4(1.0, 1.0, 0.0, 1.0);\n  }\n  else {\n    return vec4(1.0, 0.0, 1.0, 1.0);\n  }\n}\n","hud.glsl":"#include <util/screenSizePerspective.glsl>\n\nattribute vec3 position;\nattribute vec3 normal;\nattribute vec4 auxpos1;\n\nuniform mat4 proj;\n\nuniform mat4 view;\nuniform mat4 viewNormal;\n\nuniform mat4 model;\nuniform mat4 modelNormal;\n\nuniform vec4 viewport;\n\nuniform vec3 camPos;\n\nuniform float polygonOffset;\nuniform float cameraGroundRelative;\nuniform float pixelRatio;\n\nuniform float perDistancePixelRatio;\n\n#ifdef VERTICAL_OFFSET\n\n// [ screenLength, distanceFactor, minWorldLength, maxWorldLength ]\nuniform vec4 verticalOffset;\n\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n// [ divisor, offset, minPixelSize, paddingPixels ]\nuniform vec4 screenSizePerspectiveAlignment;\n\n#endif\n\nuniform sampler2D hudVisibilityTexture;\n\n\n// Corresponds to cos(10 deg), used to compare against dot product of two vectors\nconst float SMALL_OFFSET_ANGLE = 0.984807753012208;\n\nstruct ProjectHUDAux {\n  vec3 posModel;\n  vec3 posView;\n  vec3 vnormal;\n\n  float distanceToCamera;\n  float absCosAngle;\n};\n\n\n/**\n  * Apply the simulated polygon offset for HUD objects that improves\n  * issues with Z-fighting.\n  *\n  * @param posView {vec3} (inout) the position in view space. Will be modified in place.\n  * @param pointGroundDistance {float} the distance from the point geometry to the ground surface.\n  * @param absCosAngle {float} the absolute cosine of the angle between the world-up at the point geometry\n  *   and the view direction.\n  *\n  * Dependencies:\n  *\n  *   Attributes:\n  *     - auxpos1: contains centerOffset and pointGroundDistance\n  *\n  *   Uniforms:\n  *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\n  *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\n  *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\n  *         reduced flickering.\n  *     - viewport: the viewport [x, y, width, height]\n  */\nfloat applyHUDViewDependentPolygonOffset(float pointGroundDistance, float absCosAngle, inout vec3 posView) {\n  float pointGroundSign = sign(pointGroundDistance);\n\n  if (pointGroundSign == 0.0) {\n    pointGroundSign = cameraGroundRelative;\n  }\n\n  // cameraGroundRelative is -1 if camera is below ground, 1 if above ground\n  // groundRelative is 1 if both camera and symbol are on the same side of the ground, -1 otherwise\n  float groundRelative = cameraGroundRelative * pointGroundSign;\n\n  // view angle dependent part of polygon offset emulation\n  // we take the absolute value because the sign that is dropped is\n  // instead introduced using the ground-relative position of the symbol and the camera\n  if (polygonOffset > .0) {\n    float cosAlpha = clamp(absCosAngle, 0.01, 1.0);\n\n    float tanAlpha = sqrt(1.0 - cosAlpha * cosAlpha) / cosAlpha;\n    float factor = (1.0 - tanAlpha / viewport[2]);\n\n    // same side of the terrain\n    if (groundRelative > 0.0) {\n      posView *= factor;\n    }\n    // opposite sides of the terrain\n    else {\n      posView /= factor;\n    }\n  }\n\n  return groundRelative;\n}\n\n/**\n * Apply small vertical offset along world normal to reduce flickering. The offset\n * is distance based is approximately half of a pixel in the plane parallel to the\n * view at the HUD origin.\n *\n * @param normalModel {vec3} the normal in model/world space.\n * @param posModel {vec3} (inout) the position in model/world space. This value will\n *   be updated with the additional vertical offset.\n * @param posView {vec3} (inout) the position in view space. This value is used to\n *   determine the distance to the HUD origin and will also be updated with the\n *   additional vertical offset.\n *\n * Dependencies:\n *\n *   Uniforms:\n *     - perDistancePixelRatio: world units per distance per pixel.\n *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\n *     - viewNormal: the view normal transformation.\n */\nvoid applyHUDVerticalGroundOffset(vec3 normalModel, inout vec3 posModel, inout vec3 posView) {\n  float distanceToCamera = length(posView);\n\n  // Compute offset in world units for a half pixel shift\n  float pixelOffset = distanceToCamera * perDistancePixelRatio * 0.5;\n\n  // Apply offset along normal in the direction away from the ground surface\n  vec3 modelOffset = normalModel * cameraGroundRelative * pixelOffset;\n\n  // Apply the same offset also on the view space position\n  vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;\n\n  posModel += modelOffset;\n  posView += viewOffset;\n}\n\n/**\n  * Project the 3d position of a HUD object from world space to clip space. In addition\n  * to standard model view projection, it also emulates a polygon offset to\n  * help with points above/below ground and icon flickering. The resulting location\n  * is the anchor of the HUD object, i.e. the position that is used also for testing\n  * visibility of the HUD object. Note that the returned projected position is not\n  * aligned to a pixel center or border, it is up to the caller to align if necessary.\n  *\n  * Dependencies:\n  *\n  *   Attributes:\n  *     - position: contains the point world position\n  *     - normal: contains the world normal pointing up at the point\n  *     - auxpos1: contains centerOffset and pointGroundDistance\n  *\n  *   Uniforms:\n  *     - model: the object -> world transformation matrix\n  *     - modelNormal: the object -> world normal transformation matrix (inv transp of model)\n  *     - view: the world -> view transformation matrix\n  *     - viewNormal: the world -> view normal transformation matrix (inv transp of view)\n  *     - proj: the view -> clip projection matrix\n  *     - verticalOffset: a vec4 containing:\n  *         - the screen height of the vertical offset\n  *         - the screen height of the vertical offset as a fraction of camera distance.\n  *         - the minimum world size vertical offset.\n  *         - the maximum world size vertical offset.\n  *       This will do a screen sized offset of the point along its normal (used for line callouts)\n  *     - screenSizePerspectiveAlignment: a vec3 containing\n  *         - the view distance dependent divisor\n  *         - the view distance dependent offset\n  *         - the minimum pixel size\n  *         - the amount of padding in pixels around the region to be scaled (not used for alignment)\n  *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\n  *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\n  *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\n  *         reduced flickering.\n  *     - camPos: the position of the camera in world space\n  *     - viewport: the viewport [x, y, width, height]\n  */\nvec4 projectPositionHUD(out ProjectHUDAux aux) {\n  // centerOffset is in view space and is used to implement world size offsetting\n  // of labels with respect to objects. It also pulls the label towards the viewer\n  // so that the label is visible in front of the object.\n  vec3 centerOffset = auxpos1.xyz;\n\n  // The pointGroundDistance is the distance of the geometry to the ground and is\n  // negative if the point is below the ground, or positive if the point is above\n  // ground.\n  float pointGroundDistance = auxpos1.w;\n\n  aux.posModel = (model * vec4(position, 1.0)).xyz;\n  aux.posView = (view * vec4(aux.posModel, 1.0)).xyz;\n  aux.vnormal = (modelNormal * vec4(normal, 1.0)).xyz;\n\n  applyHUDVerticalGroundOffset(aux.vnormal, aux.posModel, aux.posView);\n\n  // Screen sized offset in world space, used for example for line callouts\n  // Note: keep this implementation in sync with the CPU implementation, see\n  //   - MaterialUtil.verticalOffsetAtDistance\n  //   - HUDMaterial.applyVerticalOffsetTransformation\n\n  aux.distanceToCamera = length(aux.posView);\n\n  vec3 viewDirObjSpace = normalize(camPos - aux.posModel);\n  float cosAngle = dot(aux.vnormal, viewDirObjSpace);\n\n  aux.absCosAngle = abs(cosAngle);\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n#if defined(VERTICAL_OFFSET) || defined(CENTER_OFFSET_UNITS_SCREEN)\n  vec4 perspectiveFactor = screenSizePerspectiveScaleFactor(aux.absCosAngle, aux.distanceToCamera, screenSizePerspectiveAlignment);\n#endif\n\n#endif\n\n#ifdef VERTICAL_OFFSET\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  float verticalOffsetScreenHeight = applyScreenSizePerspectiveScaleFactorFloat(verticalOffset.x, perspectiveFactor);\n#else\n  float verticalOffsetScreenHeight = verticalOffset.x;\n#endif\n\n  float worldOffset = clamp(verticalOffsetScreenHeight * verticalOffset.y * aux.distanceToCamera, verticalOffset.z, verticalOffset.w);\n  vec3 modelOffset = aux.vnormal * worldOffset;\n\n  aux.posModel += modelOffset;\n\n  vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;\n  aux.posView += viewOffset;\n\n  // Since we elevate the object, we need to take that into account\n  // in the distance to ground\n  pointGroundDistance += worldOffset;\n\n#endif\n\n  float groundRelative = applyHUDViewDependentPolygonOffset(pointGroundDistance, aux.absCosAngle, aux.posView);\n\n#ifndef CENTER_OFFSET_UNITS_SCREEN\n  // Apply x/y in view space, but z in screen space (i.e. along posView direction)\n  aux.posView += vec3(centerOffset.x, centerOffset.y, 0.0);\n\n  // Same material all have same z != 0.0 condition so should not lead to\n  // branch fragmentation and will save a normalization if it's not needed\n  if (centerOffset.z != 0.0) {\n    aux.posView -= normalize(aux.posView) * centerOffset.z;\n  }\n#endif\n\n  vec4 posProj = proj * vec4(aux.posView, 1.0);\n\n#ifdef CENTER_OFFSET_UNITS_SCREEN\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  float centerOffsetY = applyScreenSizePerspectiveScaleFactorFloat(centerOffset.y, perspectiveFactor);\n#else\n  float centerOffsetY = centerOffset.y;\n#endif\n\n  posProj.xy += vec2(centerOffset.x, centerOffsetY) * pixelRatio * 2.0 / viewport.zw * posProj.w;\n\n#endif\n\n  // constant part of polygon offset emulation\n  posProj.z -= groundRelative * polygonOffset * posProj.w;\n\n  return posProj;\n}\n\nuniform float uRenderTransparentlyOccludedHUD;\n\n/**\n  * Test for visibility of a HUD object.\n  *\n  * Dependencies:\n  *\n  *   Uniforms:\n  *     - hudVisibilityTexture: the texture that contains the visibility information\n  *     - markerColor: the special marker color that is used to write visibility information\n  *     - viewport: the viewport\n  */\nbool testVisibilityHUD(vec4 posProj) {\n  // For occlusion testing, use the nearest pixel center to avoid\n  // subpixel filtering messing up the color we use to test for\n  vec4 posProjCenter = alignToPixelCenter(posProj, viewport.zw);\n\n  vec4 occlusionPixel = texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w);\n\n  // the red pixel here indicates that the occlusion pixel passed the depth test against solid geometry and was written\n  // the green pixel stores transparency of transparent geometry (1.0 -> fully transparent)\n  // note that we also check against green == 0.0, i.e. transparent geometry that has opaque parts\n\n  // thus we render visible pixels that are occluded by semi-transparent (but not fully transparent!) geometry here\n  if (uRenderTransparentlyOccludedHUD > 0.5) {\n    // multiplying by uRenderTransparentlyOccludedHUD allows us to ignore the second condition if\n    // uRenderTransparentlyOccludedHUD = 0.75\n    return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g * uRenderTransparentlyOccludedHUD < 1.0;\n  }\n  // and visible pixels that are not occluded by semi-transparent geometry here\n  else {\n    return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g == 1.0;\n  }\n\n  // return texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w).r > 0.0;\n}\n","normalEncoding.glsl":"vec3 decodeNormal(vec2 f) {\n    float z = 1.0 - abs(f.x) - abs(f.y);\n    return vec3(f + sign(f) * min(z, 0.0), z);\n}\n","quad.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nvarying vec2 uv;\n\nvoid main(void) {\n  gl_Position = vec4(position.x, position.y, .0, 1.0);\n  uv = position * .5 + vec2(.5);\n}\n","sceneLighting.glsl":"// Scene Lighting Definitions:\n// ================================\n\n// defines:\n//   - SH_ORDER: 1|2|3\n// input:\n//   - normal: vec3\n//   - albedo: vec3\n//   - shadow: float\n//   - ssao: float\n// return:\n//   - color: vec3\n\n// main light\n/////////////////////////////////////////\nuniform vec3 lightingMainDirection;\nuniform vec3 lightingMainIntensity;\n\n// ambient lighting\n/////////////////////////////////////////\n#ifndef SH_ORDER\n  #define SH_ORDER 2\n#endif\n\n#if SH_ORDER == 0\n  uniform vec3 lightingAmbientSH0;\n#elif SH_ORDER == 1\n  uniform vec4 lightingAmbientSH_R;\n  uniform vec4 lightingAmbientSH_G;\n  uniform vec4 lightingAmbientSH_B;\n#elif SH_ORDER == 2\n  uniform vec3 lightingAmbientSH0;\n  uniform vec4 lightingAmbientSH_R1;\n  uniform vec4 lightingAmbientSH_G1;\n  uniform vec4 lightingAmbientSH_B1;\n  uniform vec4 lightingAmbientSH_R2;\n  uniform vec4 lightingAmbientSH_G2;\n  uniform vec4 lightingAmbientSH_B2;\n#endif\n\n// special tweaking\n//////////////////////////////////////////\nuniform float lightingFixedFactor;\nuniform float lightingGlobalFactor;\n\nuniform float ambientBoostFactor;\n\n// evaluation\n//////////////////////////////////////////\n\nvec3 evaluateSceneLighting(vec3 normal, vec3 albedo, float shadow, float ssao, vec3 additionalLight) {\n  // evaluate the main light\n  #if defined(TREE_RENDERING)\n    // Special case for tree rendering:\n    // We shift the Lambert lobe to the back, allowing it to reach part of the hemisphere\n    // facing away from the light. The idea is to get an effect where light is transmitted\n    // through the tree.\n    float minDot = -0.5;\n    float dotRange = 1.0 - minDot;\n    float dotNormalization = 0.66; // guessed & hand tweaked value, for an exact value we could precompute an integral over the sphere\n\n    float dotVal = dotNormalization * (clamp(-dot(normal, lightingMainDirection), 1.0 - dotRange, 1.0) - minDot) * (1.0 / dotRange);\n  #else\n    float dotVal = clamp(-dot(normal, lightingMainDirection), 0.0, 1.0);\n  #endif\n\n  // move lighting towards (1.0, 1.0, 1.0) if requested\n  dotVal = mix(dotVal, 1.0, lightingFixedFactor);\n\n  vec3 mainLight = (1.0 - shadow) * lightingMainIntensity * dotVal;\n\n  // evaluate the sh ambient light\n  #if SH_ORDER == 0\n    vec3 ambientLight = 0.282095 * lightingAmbientSH0;\n  #elif SH_ORDER == 1\n    vec4 sh0 = vec4(\n      0.282095,\n      0.488603 * normal.x,\n      0.488603 * normal.z,\n      0.488603 * normal.y\n    );\n    vec3 ambientLight = vec3(\n      dot(lightingAmbientSH_R, sh0),\n      dot(lightingAmbientSH_G, sh0),\n      dot(lightingAmbientSH_B, sh0)\n    );\n  #elif SH_ORDER == 2\n    vec3 ambientLight = 0.282095 * lightingAmbientSH0;\n\n    vec4 sh1 = vec4(\n      0.488603 * normal.x,\n      0.488603 * normal.z,\n      0.488603 * normal.y,\n      1.092548 * normal.x * normal.y\n    );\n    vec4 sh2 = vec4(\n      1.092548 * normal.y * normal.z,\n      0.315392 * (3.0 * normal.z * normal.z - 1.0),\n      1.092548 * normal.x * normal.z,\n      0.546274 * (normal.x * normal.x - normal.y * normal.y)\n    );\n    ambientLight += vec3(\n      dot(lightingAmbientSH_R1, sh1),\n      dot(lightingAmbientSH_G1, sh1),\n      dot(lightingAmbientSH_B1, sh1)\n    );\n    ambientLight += vec3(\n      dot(lightingAmbientSH_R2, sh2),\n      dot(lightingAmbientSH_G2, sh2),\n      dot(lightingAmbientSH_B2, sh2)\n    );\n  #endif\n  ambientLight *= (1.0 - ssao);\n\n  // inverse gamma correction on the albedo color\n  float gamma = 2.1;\n  vec3 albedoGammaC = pow(albedo, vec3(gamma));\n\n  // physically correct BRDF normalizes by PI\n  const float PI = 3.14159;\n  vec3 totalLight = mainLight + ambientLight + additionalLight;\n  totalLight = min(totalLight, vec3(PI, PI, PI));\n  vec3 outColor = vec3((albedoGammaC / PI) * (totalLight));\n\n  // apply gamma correction to the computed color\n  outColor = pow(outColor, vec3(1.0/gamma));\n\n  return outColor;\n}\n\nvec3 sceneLightingAdditionalLightGlobal(vec3 worldPos, float ssao, out float additionalAmbientScale) {\n  // heuristic lighting model originally used in the terrain shading\n  // now used to generated additional ambient light\n\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n    float vndl = -dot(normalize(worldPos), lightingMainDirection);\n#else\n    float vndl = -dot(vec3(0.0, 0.0, 1.0), lightingMainDirection);\n#endif\n\n  additionalAmbientScale = smoothstep(0.0, 1.0, clamp(vndl * 2.5, 0.0, 1.0));\n  return ssao * lightingMainIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;\n}\n","screenSizePerspective.glsl":"// Note that the implementation here should be kept in sync with the corresponding\n// CPU implementation (used for hitTest etc) in screenSizePerspectiveUtils.ts\n\n/**\n * Compute the screen size perspective lower bound from pre-computed screen\n * size perspective factors (or parameters, since both store the pixel lower\n * bound information in the same place). When computing the minimum size,\n * the padding (e.g. text halo) is scaled with the same factor as the\n * original size scales to reach the minimum size.\n *\n * {\n *    x: N/A\n *    y: N/A\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n */\nfloat screenSizePerspectiveMinSize(float size, vec4 factor) {\n\n  // Original calculation:\n  //   padding = 2 * factor.w\n  //   minSize = factor.z\n  //\n  //   minSize + minSize / size * padding\n  //\n  // Incorporates padding (factor.w, e.g. text halo size) into the\n  // minimum bounds calculation, taking into account that padding\n  // would scale down proportionally to the size.\n  //\n  // Calculation below is the same, but avoids division by zero when\n  // size would be zero, without branching using step.\n  // https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10683\n\n  // nonZeroSize is 1 if size > 0, and 0 otherwise\n  float nonZeroSize = 1.0 - step(size, 0.0);\n\n  return (\n    factor.z * (\n      1.0 +\n      nonZeroSize *                // Multiply by nzs ensures if size is 0, then we ignore\n                                   // proportionally scaled padding\n      2.0 * factor.w / (\n        size + (1.0 - nonZeroSize) // Adding 1 - nzs ensures we divide either by size, or by 1\n      )\n    )\n  );\n}\n\n/**\n * Computes the view angle dependent screen size perspective factor. The goal\n * of this factor is that:\n *\n *   1. There is no perspective when looking top-down\n *   2. There is a smooth and quick transition to full perspective when\n *      tilting.\n */\nfloat screenSizePerspectiveViewAngleDependentFactor(float absCosAngle) {\n  return absCosAngle * absCosAngle * absCosAngle;\n}\n\n/**\n * Precomputes a set of factors that can be used to apply screen size perspective\n * The factors are based on the viewing angle, distance to camera and the screen size\n * perspective parameters:\n * {\n *    x: distanceDivisor,\n *    y: distanceOffset,\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n *\n * The result is a set of factors that can be used to apply the perspective:\n *\n * {\n *    x: distance based relative scale factor (0 -> 1)\n *    y: view dependent scale factor\n *    z: minPixelSize (abs)\n *    w: sizePaddingInPixels (abs)\n * }\n */\nvec4 screenSizePerspectiveScaleFactor(float absCosAngle, float distanceToCamera, vec4 params) {\n  return vec4(min(params.x / (distanceToCamera - params.y), 1.0), screenSizePerspectiveViewAngleDependentFactor(absCosAngle), params.z, params.w);\n}\n\n/**\n * Applies screen size perspective factors to a single dimension size, given the viewing angle,\n * distance to camera and perspective parameters. The factors can be calculated from the screen size\n * perspective parameters using screenSizePerspectiveScaleFactorFloat.\n *\n * Note that for single scale application, the screenSizePerspectiveScaleFloat can be used, which\n * will call this method, providing it the factors calculated from screenSizePerspectiveScaleFactorFloat.\n */\n\nfloat applyScreenSizePerspectiveScaleFactorFloat(float size, vec4 factor) {\n  return max(mix(size * factor.x, size, factor.y), screenSizePerspectiveMinSize(size, factor));\n}\n\n/**\n * Applies screen size perspective parameters to a single dimension size, given the viewing angle,\n * distance to camera and perspective parameters\n * {\n *    x: distanceDivisor,\n *    y: distanceOffset,\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n */\nfloat screenSizePerspectiveScaleFloat(float size, float absCosAngle, float distanceToCamera, vec4 params) {\n  return applyScreenSizePerspectiveScaleFactorFloat(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params));\n}\n\n/**\n * Applies screen size perspective factors to a vec2 size (width/height), given the viewing angle,\n * distance to camera and perspective parameters. The factors can be calculated from the screen size\n * perspective parameters using screenSizePerspectiveScaleFactorVec2.\n *\n * Note that for single scale application, the screenSizePerspectiveScaleVec2 can be used, which\n * will call this method, providing it the factors calculated from screenSizePerspectiveScaleFactorVec2.\n */\nvec2 applyScreenSizePerspectiveScaleFactorVec2(vec2 size, vec4 factor) {\n  return mix(size * clamp(factor.x, screenSizePerspectiveMinSize(size.y, factor) / size.y, 1.0), size, factor.y);\n}\n\n/**\n * Applies screen size perspective parameters to a vec2 size (width/height), given the viewing angle,\n * distance to camera and perspective parameters\n * {\n *    x: distanceDivisor,\n *    y: distanceOffset,\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n */\nvec2 screenSizePerspectiveScaleVec2(vec2 size, float absCosAngle, float distanceToCamera, vec4 params) {\n  return applyScreenSizePerspectiveScaleFactorVec2(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params));\n}\n","shadow.glsl":'#include <util/encoding.glsl>\n\n// "matrix" parameter used to have const qualifier as well, but IE11 couldn\'t deal with it at time of writing.\n// once IE11 is fine with it, const should probably be re-introduced\nfloat evalShadow(const in vec3 vpos, const in float depth, const in sampler2D depthTex, const int num, const in vec4 distance, in mat4 matrix[4], const in float halfPxSz) {\n  //choose correct cascade\n  int i = depth < distance[1] ? 0 : depth < distance[2] ? 1 : depth < distance[3] ? 2 : 3;\n\n  if (i >= num) { return .0; }\n\n  mat4 mat = i == 0 ? matrix[0] : i == 1 ? matrix[1] : i == 2 ? matrix[2] : matrix[3];\n\n  vec4 lv = mat * vec4(vpos, 1.0);\n  lv.xy /= lv.w;\n\n  //vertex completely outside? -> no shadow\n  vec3 lvpos = .5 * lv.xyz + vec3(.5);\n  if (lvpos.z >= 1.0) { return .0; }\n  if (lvpos.x < .0 || lvpos.x > 1.0 || lvpos.y < .0 || lvpos.y > 1.0) { return .0; }\n\n  //calc coord in cascade texture\n  vec2 uv = vec2(float(i - 2 * (i / 2)) *.5, float(i / 2) * .5) + .5 * lvpos.xy;\n\n  float texSize = .5 / halfPxSz;\n\n  //filter, offset by half pixels\n  vec2 st = fract((vec2(halfPxSz) + uv) * texSize);\n\n  float s00 = rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, -halfPxSz))) < lvpos.z ? 1.0 : .0;\n  float s10 = rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, -halfPxSz))) < lvpos.z ? 1.0 : .0;\n  float s11 = rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, halfPxSz))) < lvpos.z ? 1.0 : .0;\n  float s01 = rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, halfPxSz))) < lvpos.z ? 1.0 : .0;\n\n  return mix(mix(s00, s10, st.x), mix(s01, s11, st.x), st.y);\n}\n',"slice.glsl":"#ifdef SLICE\nuniform vec3 slicePlaneOrigin;\nuniform vec3 slicePlaneBasis1;\nuniform vec3 slicePlaneBasis2;\n\nstruct SliceFactors {\n  float front;\n  float side0;\n  float side1;\n  float side2;\n  float side3;\n};\n\nSliceFactors calculateSliceFactors(vec3 pos) {\n  vec3 rel = pos - slicePlaneOrigin;\n\n  vec3 slicePlaneNormal = -cross(slicePlaneBasis1, slicePlaneBasis2);\n  float slicePlaneW = -dot(slicePlaneNormal, slicePlaneOrigin);\n\n  float basis1Len2 = dot(slicePlaneBasis1, slicePlaneBasis1);\n  float basis2Len2 = dot(slicePlaneBasis2, slicePlaneBasis2);\n\n  float basis1Dot = dot(slicePlaneBasis1, rel);\n  float basis2Dot = dot(slicePlaneBasis2, rel);\n\n  return SliceFactors(\n    dot(slicePlaneNormal, pos) + slicePlaneW,\n    -basis1Dot - basis1Len2,\n    basis1Dot - basis1Len2,\n    -basis2Dot - basis2Len2,\n    basis2Dot - basis2Len2\n  );\n}\n\nbool sliceByFactors(SliceFactors factors) {\n  return factors.front < 0.0\n    && factors.side0 < 0.0\n    && factors.side1 < 0.0\n    && factors.side2 < 0.0\n    && factors.side3 < 0.0;\n}\n\nbool sliceByPlane(vec3 pos) {\n  return sliceByFactors(calculateSliceFactors(pos));\n}\n\n#ifdef EXTENSIONS_ENABLED\n\nvec4 applySliceHighlight(vec4 color, vec3 pos) {\n  SliceFactors factors = calculateSliceFactors(pos);\n\n  if (sliceByFactors(factors)) {\n    return color;\n  }\n\n  const float HIGHLIGHT_WIDTH = 1.0;\n  const vec4 HIGHLIGHT_COLOR = vec4(0.0, 0.0, 0.0, 0.3);\n\n  factors.front /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.front);\n  factors.side0 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side0);\n  factors.side1 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side1);\n  factors.side2 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side2);\n  factors.side3 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side3);\n\n  float highlightFactor = (1.0 - step(0.5, factors.front))\n    * (1.0 - step(0.5, factors.side0))\n    * (1.0 - step(0.5, factors.side1))\n    * (1.0 - step(0.5, factors.side2))\n    * (1.0 - step(0.5, factors.side3));\n\n  return mix(color, vec4(HIGHLIGHT_COLOR.rgb, color.a), highlightFactor * HIGHLIGHT_COLOR.a);\n}\n\n#else // EXTENSIONS_ENABLED\n\n// GL_OES_standard_derivatives must be enabled for applySliceHighlight\n\n#endif // EXTENSIONS_ENABLED\n\n#define rejectBySlice(_pos_) sliceByPlane(_pos_)\n#define discardBySlice(_pos_) { if (sliceByPlane(_pos_)) discard; }\n#define highlightSlice(_color_, _pos_) applySliceHighlight(_color_, _pos_)\n\n#else // SLICE\n\n#define rejectBySlice(_pos_) false\n#define discardBySlice(_pos_) {}\n#define highlightSlice(_color_, _pos_) (_color_)\n\n#endif // SLICE\n","visualVariables.glsl":"#if defined(VV_SIZE)\n  #define VV_CUSTOM_MODEL_MATRIX\n#endif\n\n#if defined(VV_SIZE)\n  uniform vec3 vvSizeMinSize;\n  uniform vec3 vvSizeMaxSize;\n  uniform vec3 vvSizeOffset;\n  uniform vec3 vvSizeFactor;\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\n  uniform vec3 vvSizeValue;\n#endif\n\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  uniform mat3 vvSymbolRotationMatrix;\n#endif\n\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  uniform vec3 vvSymbolAnchor;\n#endif\n\n#ifdef VV_COLOR\n  #define VV_COLOR_N 8\n  uniform float vvColorValues[VV_COLOR_N];\n  uniform vec4 vvColorColors[VV_COLOR_N];\n#endif\n\n// Evaluation of size\n#if defined(VV_SIZE)\n  vec3 vvGetScale(vec4 featureAttribute) {\n    return clamp(vvSizeOffset + featureAttribute.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize);\n  }\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\n  vec3 vvGetScale(vec4 featureAttribute) {\n    return vvSizeValue;\n  }\n#endif\n\n// Applying the model matrix\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  vec4 vvTransformPosition(vec3 position, vec4 featureAttribute) {\n    return vec4(vvSymbolRotationMatrix * (vvGetScale(featureAttribute) * (position + vvSymbolAnchor)), 1.0);\n  }\n\n  vec4 vvTransformNormal(vec3 normal, vec4 featureAttribute) {\n    // Normal transform is the inverse transpose of model transform\n    return vec4(vvSymbolRotationMatrix * normal / vvGetScale(featureAttribute), 1.0);\n  }\n#endif\n\n#ifdef VV_COLOR\n  vec4 vvGetColor(vec4 featureAttribute, float values[VV_COLOR_N], vec4 colors[VV_COLOR_N]) {\n    float value = featureAttribute.y;\n    if (value <= values[0]) {\n      return colors[0];\n    }\n\n    for (int i = 1; i < VV_COLOR_N; ++i) {\n      if (values[i] >= value) {\n        float f = (value - values[i-1]) / (values[i] - values[i-1]);\n        return mix(colors[i-1], colors[i], f);\n      }\n    }\n\n    return colors[VV_COLOR_N - 1];\n  }\n#endif\n","vsPrecision.glsl":"precision highp float;\nprecision highp sampler2D;\n"}}}.apply(null,i))||(e.exports=r)},W0kZ:function(e,n,t){var i,r;i=[t.dj.c(e.i),n],void 0===(r=function(e,n){return function(){function e(){this._count=0}return e.prototype.gen=function(e){return null==e&&(e="a"),e+"_"+this._count++},e}()}.apply(null,i))||(e.exports=r)},W2ph:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("ma1f"),t("rg9i"),t("qsST"),t("1RVI")],void 0===(r=function(e,n,t,i,r,o){function a(e,n,i){for(var r="",o=0;o<i;){var a=e[n+o];if(a<128)r+=String.fromCharCode(a),o++;else if(a>=192&&a<224){if(o+1>=i)throw new t("utf8-decode-error","UTF-8 Decode failed. Two byte character was truncated.");var l=(31&a)<<6|63&e[n+o+1];r+=String.fromCharCode(l),o+=2}else if(a>=224&&a<240){if(o+2>=i)throw new t("utf8-decode-error","UTF-8 Decode failed. Multi byte character was truncated.");l=(15&a)<<12|(63&e[n+o+1])<<6|63&e[n+o+2];r+=String.fromCharCode(l),o+=3}else{if(!(a>=240&&a<248))throw new t("utf8-decode-error","UTF-8 Decode failed. Invalid multi byte sequence.");if(o+3>=i)throw new t("utf8-decode-error","UTF-8 Decode failed. Multi byte character was truncated.");if((l=(7&a)<<18|(63&e[n+o+1])<<12|(63&e[n+o+2])<<6|63&e[n+o+3])>=65536){var s=55296+(l-65536>>10),c=56320+(1023&l);r+=String.fromCharCode(s,c)}else r+=String.fromCharCode(l);o+=4}}return r}function l(e,t){for(var i={byteOffset:0,byteCount:0,fields:Object.create(null)},r=0,o=0;o<t.length;o++){var a=t[o],l=a.valueType||a.type,s=n.valueType2ArrayBufferReader[l];i.fields[a.property]=s(e,r),r+=n.valueType2TypedArrayClassMap[l].BYTES_PER_ELEMENT}return i.byteCount=r,i}function s(e,n,i){var r,o,l=[],s=0;for(o=0;o<e;o+=1){if((r=n[o])>0){if(l.push(a(i,s,r-1)),0!==i[s+r-1])throw new t("string-array-error","Invalid string array: missing null termination.")}else l.push(null);s+=r}return l}function c(e,t){return new(0,n.valueType2TypedArrayClassMap[t.valueType])(e,t.byteOffset,t.count*t.valuesPerElement)}function d(e,n){return new Uint8Array(e,n.byteOffset,n.byteCount)}function u(e,n,r){for(var o=null!=n.header?l(e,n.header):{byteOffset:0,byteCount:0,fields:{count:r}},a={header:o,byteOffset:o.byteCount,byteCount:0,entries:Object.create(null)},s=o.byteCount,c=0;c<n.ordering.length;c++){var d=n.ordering[c],u=i.clone(n[d]);if(u.count=o.fields.count,"String"===u.valueType){if(u.byteOffset=s,u.byteCount=o.fields[d+"ByteCount"],"UTF-8"!==u.encoding)throw new t("unsupported-encoding","Unsupported String encoding.",{encoding:u.encoding})}else{if(!p(u.valueType))throw new t("unsupported-value-type","Unsupported binary valueType",{valueType:u.valueType});var f=v(u.valueType);s+=s%f!=0?f-s%f:0,u.byteOffset=s,u.byteCount=f*u.valuesPerElement*u.count}s+=u.byteCount,a.entries[d]=u}return a.byteCount=s-a.byteOffset,a}function f(e,n,i){if(n!==e&&h.error("Invalid "+i+" buffer size\n expected: "+e+", actual: "+n+")"),n<e)throw new t("buffer-too-small","Binary buffer is too small",{expectedSize:e,actualSize:n})}function p(e){return n.valueType2TypedArrayClassMap.hasOwnProperty(e)}function v(e){return p(e)&&n.valueType2TypedArrayClassMap[e].BYTES_PER_ELEMENT}Object.defineProperty(n,"__esModule",{value:!0});var h=r.getLogger("esri.views.3d.layers.i3s.I3SBinaryReader");n.readHeader=l,n.readStringArray=s,n.createTypedView=c,n.createRawView=d,n.createAttributeDataIndex=u,n.createGeometryDataIndex=function(e,n,t){var r=l(e,n&&n.header),o=r.byteCount,a={header:r,byteOffset:r.byteCount,byteCount:0,vertexAttributes:i.clone(n.vertexAttributes)},s=a.vertexAttributes;t||null==s.region||delete s.region;for(var c=r.fields,d=null!=c.vertexCount?c.vertexCount:c.count,u=0;u<n.ordering.length;u++){var p=n.ordering[u];null!=s[p]&&(s[p].byteOffset=o,s[p].count=d,o+=v(s[p].valueType)*s[p].valuesPerElement*d)}var h=c.faceCount;if(n.faces&&h){a.faces=i.clone(n.faces);var m=a.faces;for(u=0;u<n.ordering.length;u++){var g=n.ordering[u];null!=m[g]&&(m[g].byteOffset=o,m[g].count=h,o+=v(m[g].valueType)*m[g].valuesPerElement*h)}}var y=c.featureCount;if(n.featureAttributes&&n.featureAttributeOrder&&y){a.featureAttributes=i.clone(n.featureAttributes);var x=a.featureAttributes;for(u=0;u<n.featureAttributeOrder.length;u++){var S=n.featureAttributeOrder[u];x[S].byteOffset=o,x[S].count=y;var b=v(x[S].valueType);"UInt64"===x[S].valueType&&(b=8),o+=b*x[S].valuesPerElement*y}}return f(o,e.byteLength,"geometry"),a.byteCount=o-a.byteOffset,a},n.readBinaryAttribute=function(e,n,i){if("lepcc-rgb"===e.encoding)return o.decodeRGB(n);if("lepcc-intensity"===e.encoding)return o.decodeIntensity(n);if(null!=e.encoding&&""!==e.encoding)throw new t("unknown-attribute-storage-info-encoding","Unknown Attribute Storage Info Encoding");e["attributeByteCounts "]&&!e.attributeByteCounts&&(h.warn("Warning: Trailing space in 'attributeByteCounts '."),e.attributeByteCounts=e["attributeByteCounts "]),"ObjectIds"===e.ordering[0]&&e.hasOwnProperty("objectIds")&&(h.warn("Warning: Case error in objectIds"),e.ordering[0]="objectIds");var r=u(n,e,i);f(r.byteOffset+r.byteCount,n.byteLength,"attribute");var a=r.entries.attributeValues||r.entries.objectIds;if(a){if("String"===a.valueType){var l=r.entries.attributeByteCounts,p=c(n,l),v=d(n,a);return s(l.count,p,v)}return c(n,a)}throw new t("bad-attribute-storage-info","Bad attributeStorageInfo specification.")},n.valueType2TypedArrayClassMap={Float32:Float32Array,Float64:Float64Array,UInt8:Uint8Array,Int8:Int8Array,UInt16:Uint16Array,Int16:Int16Array,UInt32:Uint32Array,Int32:Int32Array},n.valueType2ArrayBufferReader={Float32:function(e,n){return new DataView(e,0).getFloat32(n,!0)},Float64:function(e,n){return new DataView(e,0).getFloat64(n,!0)},UInt8:function(e,n){return new DataView(e,0).getUint8(n)},Int8:function(e,n){return new DataView(e,0).getInt8(n)},UInt16:function(e,n){return new DataView(e,0).getUint16(n,!0)},Int16:function(e,n){return new DataView(e,0).getInt16(n,!0)},UInt32:function(e,n){return new DataView(e,0).getUint32(n,!0)},Int32:function(e,n){return new DataView(e,0).getInt32(n,!0)}},n.isValueType=p,n.getBytesPerValue=v}.apply(null,i))||(e.exports=r)},WsO6:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("9opi"),t("qKT0"),t("BcWh"),t("7MDj"),t("NfRO"),t("qsST"),t("SZNs"),t("qMld"),t("Vx27")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d){return function(e){function n(n){var t=e.call(this)||this;return t.layer=null,t.parent=null,t.view=null,t}return t(n,e),n.prototype.initialize=function(){var e=this;this.addResolvingPromise(this.layer),this.when().catch(function(n){if("layerview:create-error"!==n.name){var t=e.layer&&e.layer.id||"no id",i=e.layer&&e.layer.title||"no title";return l.getLogger(e.declaredClass).error("#resolve()","Failed to resolve layer view (layer title: '"+i+"', id: '"+t+"')",n),c.reject(n)}})},n.prototype.destroy=function(){this.layer=this.view=this.parent=null},Object.defineProperty(n.prototype,"suspended",{get:function(){return!this.canResume()},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"updating",{get:function(){return!this.suspended&&this.isUpdating()},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"visible",{get:function(){return!0===this.get("layer.visible")},set:function(e){void 0!==e?this._override("visible",e):this._clearOverride("visible")},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"fullOpacity",{get:function(){var e=function(e){return null==e?1:e};return e(this.get("layer.opacity"))*e(this.get("parent.fullOpacity"))},enumerable:!0,configurable:!0}),n.prototype.canResume=function(){return!this.get("parent.suspended")&&this.get("view.ready")&&this.get("layer.loaded")&&this.visible||!1},n.prototype.isUpdating=function(){return!1},i([d.property()],n.prototype,"layer",void 0),i([d.property()],n.prototype,"parent",void 0),i([d.property({readOnly:!0,dependsOn:["view","visible","layer.loaded","parent.suspended"]})],n.prototype,"suspended",null),i([d.property({type:Boolean,dependsOn:["suspended"],readOnly:!0})],n.prototype,"updating",null),i([d.property()],n.prototype,"view",void 0),i([d.property({dependsOn:["layer.visible"]})],n.prototype,"visible",null),i([d.property({dependsOn:["layer.opacity","parent.fullOpacity"]})],n.prototype,"fullOpacity",null),i([d.subclass("esri.views.layers.LayerView")],n)}(d.declared(o,r,a.Identifiable,s))}.apply(null,i))||(e.exports=r)},ZJC8:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("FXVB"),t("1m5D"),t("0LE5"),t("Rdxj"),t("AzkI"),t("rjU6"),t("Cvn+"),t("xsp2"),t("W0kZ"),t("05NA"),t("CIy2")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u,f){var p=f.assert,v=i.mat4f64.create(),h=function(){function e(n){void 0===n&&(n={}),this._objectTransformation=i.mat4f64.create(),this._bvObjectSpace=new m,this._bvWorldSpace=new m,this._bvDirty=!0,this._hasVolatileTransformation=!1,this._allComponentsHiddenDirty=!0,this._allComponentsVisibleDirty=!0,this.id=e._idGen.gen(n.idHint),this.name=n.name,this.castShadow=null==n.castShadow||n.castShadow,this.metadata=n.metadata,this.objectTransformation=i.mat4f64.create(),this._initializeGeometryRecords(n.geometries,n.materials,n.transformations,n.origins)}return Object.defineProperty(e.prototype,"objectTransformation",{get:function(){return this._objectTransformation},set:function(e){t.mat4.copy(this._objectTransformation,e),this._invalidateBoundingVolume(),this._notifyDirty("objTransformation")},enumerable:!0,configurable:!0}),e.prototype._initializeGeometryRecords=function(e,n,t,r){if(!Array.isArray(e))return this.geometryRecords=[],void(this.geometries=[]);p(n.length===e.length,"Object3D: materials don't match geometries"),p(t.length===e.length,"Object3D: transformations don't match geometries"),this.geometryRecords=new Array(e.length),this.geometries=e.slice();for(var o=0;o<e.length;o++){this.geometryRecords[o]=new s(e[o],n[o],i.mat4f64.clone(t[o]),{},r&&r[o])}this._hasVolatileTransformation=!1},Object.defineProperty(e.prototype,"parentLayer",{get:function(){return this._parentLayer},set:function(e){p(null==this._parentLayer||null==e,"Object3D can only be added to a single Layer"),this._parentLayer=e},enumerable:!0,configurable:!0}),e.prototype.getNumGeometryRecords=function(){return this.geometryRecords.length},e.prototype.getFirstGeometryIndex=function(e){var n=this.geometries.indexOf(e);return p(n>-1,"Object3D.getFirstGeometryIndex: geometry not found"),n},e.prototype.findGeometryRecords=function(e){for(var n=[],t=0;t<this.geometries.length;t++)this.geometries[t]===e&&n.push(this.geometryRecords[t]);return n},e.prototype.getGeometryRecord=function(e){return p(e>=0&&e<this.geometryRecords.length,"Object3d.getGeometryDataByIndex: index out of range"),this.geometryRecords[e]},e.prototype.getGeometryRecords=function(){return this.geometryRecords},e.prototype.addGeometry=function(e,n,t,r,o,a){void 0===t&&(t=v),this.geometries.push(e);var l=new s(e,n,i.mat4f64.clone(t),r||{},o,a);return this.geometryRecords.push(l),this._hasVolatileTransformation=this.geometryRecords.some(function(e){return!!e.shaderTransformation}),this._notifyDirty("objGeometryAdded",l),this._invalidateBoundingVolume(),this._allComponentsHiddenDirty=!0,this._allComponentsVisibleDirty=!0,l},e.prototype.hasGeometry=function(e){return this.geometries.indexOf(e)>-1},e.prototype.removeGeometry=function(e){var n=this.geometryRecords.splice(e,1)[0];return this._hasVolatileTransformation=this.geometryRecords.some(function(e){return!!e.shaderTransformation}),this.geometries.splice(e,1),this._notifyDirty("objGeometryRemoved",n),this._invalidateBoundingVolume(),this._allComponentsHiddenDirty=!0,this._allComponentsVisibleDirty=!0,n},e.prototype.removeAllGeometries=function(){for(;this.getNumGeometryRecords()>0;)this.removeGeometry(0)},e.prototype.geometryVertexAttrsUpdated=function(e){this._notifyDirty("vertexAttrsUpdated",this.geometryRecords[e]),this._invalidateBoundingVolume()},e.prototype.areAllComponentsHidden=function(){if(this._allComponentsHiddenDirty){this._allComponentsHiddenDirty=!1,this._allComponentsHidden=!0;for(var e=0,n=this.geometryRecords;e<n.length;e++){var t=n[e],i=t.instanceParameters.componentVisibilities,r=t.geometry.data.componentOffsets;if(!l.isAllHidden(i,r)){this._allComponentsHidden=!1;break}}}return this._allComponentsHidden},e.prototype.areAllComponentsVisible=function(){if(this._allComponentsVisibleDirty){this._allComponentsVisibleDirty=!1,this._allComponentsVisible=!0;for(var e=0,n=this.geometryRecords;e<n.length;e++){var t=n[e],i=t.instanceParameters.componentVisibilities,r=t.geometry.data.componentOffsets;if(!l.isAllVisible(i,r)){this._allComponentsVisible=!1;break}}}return this._allComponentsVisible},e.prototype.hasComponents=function(){for(var e=!1,n=0;n<this.geometries.length;n++){var t=this.geometries[n];if(e=l.hasComponents(t.data.componentOffsets))break}return e},e.prototype.setComponentVisibility=function(e,n,t){var i=e.geometry,r=e.instanceParameters.componentVisibilities,o=i.data.componentOffsets,a=l.updateVisibility(r,o,n,t);e.instanceParameters.componentVisibilities=a,this._notifyDirty("visibilityChanged",e),this._allComponentsHiddenDirty=!0,this._allComponentsVisibleDirty=!0},e.prototype.setHidden=function(e,n){e.instanceParameters.hidden=!!n,this._notifyDirty("visibilityChanged",e)},e.prototype.isHidden=function(e){return!!e.instanceParameters.hidden},e.prototype.getComponentVisibility=function(e,n){var t=e.instanceParameters.componentVisibilities;return l.getVisibility(t,n)},e.prototype.hideAllComponents=function(){if(this._allComponentsHiddenDirty||!this._allComponentsHidden){for(var e=0,n=this.geometryRecords;e<n.length;e++){var t=n[e],i=t.instanceParameters.componentVisibilities,r=l.hideAllComponents(i);t.instanceParameters.componentVisibilities=r}this._notifyDirty("visibilityChanged"),this._allComponentsHiddenDirty=!1,this._allComponentsVisibleDirty=!1,this._allComponentsHidden=!0,this._allComponentsVisible=!1}},e.prototype.unhideAllComponents=function(){if(this._allComponentsVisibleDirty||!this._allComponentsVisible){for(var e=0,n=this.geometryRecords;e<n.length;e++){var t=n[e],i=t.instanceParameters.componentVisibilities,r=l.unhideAllComponents(i);t.instanceParameters.componentVisibilities=r}this._notifyDirty("visibilityChanged"),this._allComponentsHiddenDirty=!1,this._allComponentsVisibleDirty=!1,this._allComponentsHidden=!1,this._allComponentsVisible=!0}},e.prototype._setComponentHighlight=function(e,n,t,i){var r=e.instanceParameters.componentHighlights,o=l.addHighlight(r,n,t,i);e.instanceParameters.componentHighlights=o},e.prototype.setComponentHighlight=function(e,n,t){var i=c.generateHighlightId();return this._setComponentHighlight(e,n,t,i),this._notifyDirty("componentHighlightChanged"),i},e.prototype.highlightAllComponents=function(e){for(var n=c.generateHighlightId(),t=0,i=this.geometryRecords;t<i.length;t++){var r=i[t];this._setComponentHighlight(r,null,e,n)}return this._notifyDirty("componentHighlightChanged"),n},e.prototype.removeHighlights=function(e){for(var n=0,t=this.geometryRecords;n<t.length;n++){var i=t[n].instanceParameters,r=i.componentHighlights,o=l.removeHighlight(r,e);i.componentHighlights=o}this._notifyDirty("componentHighlightChanged")},e.prototype.getComponentFromTriangleNr=function(e,n){p(e>=0&&e<this.geometryRecords.length,"Object3d.getComponentFromTriangleNr: index out of range");var t=this.geometryRecords[e].geometry.data.componentOffsets;return l.componentFind(t,3*n)},e.prototype.setGeometryTransformation=function(e,n){p(e>=0&&e<this.geometryRecords.length,"Object3d.setGeometryTransformation: index out of range");var t=this.geometryRecords[e],r=new s(t.geometry,t.material,i.mat4f64.clone(n),t.instanceParameters);this.geometryRecords[e]=r,this._notifyDirty("objGeometryReplaced",[t,r]),this._invalidateBoundingVolume()},e.prototype.getCombinedStaticTransformation=function(e,n){return n=n||i.mat4f64.create(),t.mat4.multiply(n,this.objectTransformation,e.getStaticTransformation()),n},e.prototype.getCombinedShaderTransformation=function(e,n){return n=n||i.mat4f64.create(),t.mat4.multiply(n,this.objectTransformation,e.getShaderTransformation()),n},e.prototype.hasVolativeTransformation=function(){return this._hasVolatileTransformation},e.prototype.getCastShadow=function(){return this.castShadow},e.prototype.setCastShadow=function(e){this.castShadow=e},e.prototype.getMetadata=function(){return this.metadata},e.prototype.getName=function(){return this.name},e.prototype.getBBMin=function(e){return this._validateBoundingVolume(),e?this._bvObjectSpace.bbMin:this._bvWorldSpace.bbMin},e.prototype.getBBMax=function(e){return this._validateBoundingVolume(),e?this._bvObjectSpace.bbMax:this._bvWorldSpace.bbMax},e.prototype.getCenter=function(e){return this._validateBoundingVolume(),e?this._bvObjectSpace.center:this._bvWorldSpace.center},e.prototype.getBSRadius=function(e){return this._validateBoundingVolume(),e?this._bvObjectSpace.bsRadius:this._bvWorldSpace.bsRadius},e.prototype._validateBoundingVolume=function(){if(this._bvDirty||this._hasVolatileTransformation){this._bvObjectSpace.init(),this._bvWorldSpace.init();for(var e=0;e<this.geometryRecords.length;++e){var n=this.geometries[e],t=this.geometryRecords[e],i=n.boundingInfo;this._calculateTransformedBoundingVolume(i,this._bvObjectSpace,t.getShaderTransformation()),this._calculateTransformedBoundingVolume(i,this._bvWorldSpace,this.getCombinedShaderTransformation(t))}r.vec3.lerp(this._bvObjectSpace.center,this._bvObjectSpace.bbMin,this._bvObjectSpace.bbMax,.5),r.vec3.lerp(this._bvWorldSpace.center,this._bvWorldSpace.bbMin,this._bvWorldSpace.bbMax,.5);var l=o.vec3f64.create(),s=o.vec3f64.create(),c=a.maxScale(this.objectTransformation);for(e=0;e<this.geometryRecords.length;++e){n=this.geometries[e];var d=this.geometryRecords[e].getShaderTransformation(),u=a.maxScale(d);i=n.boundingInfo;r.vec3.transformMat4(l,i.getCenter(),d);var f=r.vec3.distance(l,this._bvObjectSpace.center),p=i.getBSRadius()*u;this._bvObjectSpace.bsRadius=Math.max(this._bvObjectSpace.bsRadius,f+p),r.vec3.transformMat4(s,l,this.objectTransformation);var v=r.vec3.distance(s,this._bvWorldSpace.center),h=p*c;this._bvWorldSpace.bsRadius=Math.max(this._bvWorldSpace.bsRadius,v+h)}this._bvDirty=!1}},e.prototype._calculateTransformedBoundingVolume=function(e,n,t){var i=e.getBBMin(),a=e.getBBMax(),l=o.vec3f64.clone(i),s=o.vec3f64.clone(a);r.vec3.transformMat4(l,l,t),r.vec3.transformMat4(s,s,t);for(var c=0;c<3;++c)n.bbMin[c]=Math.min(n.bbMin[c],l[c],s[c]),n.bbMax[c]=Math.max(n.bbMax[c],l[c],s[c]);for(c=0;c<3;++c){r.vec3.copy(l,i),r.vec3.copy(s,a),l[c]=a[c],s[c]=i[c],r.vec3.transformMat4(l,l,t),r.vec3.transformMat4(s,s,t);for(var d=0;d<3;++d)n.bbMin[d]=Math.min(n.bbMin[d],l[d],s[d]),n.bbMax[d]=Math.max(n.bbMax[d],l[d],s[d])}},e.prototype._invalidateBoundingVolume=function(){this._bvDirty=!0,this._parentLayer&&this._parentLayer.notifyObjectBBChanged(this,{center:this._bvWorldSpace.center,radius:this._bvWorldSpace.bsRadius})},e.prototype._notifyDirty=function(e,n,t,i){if(this._parentLayer){t=t||u.OBJECT;var r=i||this;this._parentLayer.notifyDirty(e,n,t,r)}},e._idGen=new d,e}(),m=function(){function e(){this.bbMin=o.vec3f64.create(),this.bbMax=o.vec3f64.create(),this.center=o.vec3f64.create(),this.bsRadius=0}return e.prototype.init=function(){r.vec3.set(this.bbMin,Number.MAX_VALUE,Number.MAX_VALUE,Number.MAX_VALUE),r.vec3.set(this.bbMax,-Number.MAX_VALUE,-Number.MAX_VALUE,-Number.MAX_VALUE),r.vec3.set(this.center,0,0,0),this.bsRadius=0},e.prototype.getCenter=function(){return this.center},e.prototype.getBSRadius=function(){return this.bsRadius},e}();return h}.apply(null,i))||(e.exports=r)},fdzS:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("gKSc")],void 0===(r=function(e,n,t){Object.defineProperty(n,"__esModule",{value:!0}),n.quatf32=t}.apply(null,i))||(e.exports=r)},fw2w:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("0J3i"),t("ma1f"),t("qsST"),t("qMld"),t("Vt+U"),t("aYWh"),t("Z4y+"),t("nrlZ"),t("vtMp"),t("xuSL")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u){function f(e){return"polygon"===e.type}function p(e){return"polygon"===e[0].type}function v(e){return"polyline"===e[0].type}function h(e){return f(e)?e.rings:e.paths}function m(e,n){return Math.ceil((e-n)/(2*n))}function g(e,n){for(var t=0,i=h(e);t<i.length;t++)for(var r=0,o=i[t];r<o.length;r++){o[r][0]+=n}return e}function y(e){for(var n=[],t=0,i=0,r=0;r<e.length;r++){for(var o=e[r],a=null,l=0;l<o.length;l++)a=o[l],n.push(a),0===l?i=t=a[0]:(t=Math.min(t,a[0]),i=Math.max(i,a[0]));a&&n.push([(t+i)/2,0])}return n}function x(e,n){if(!(e instanceof l||e instanceof a)){var t="straightLineDensify: the input geometry is neither polyline nor polygon";throw w.error(t),new i(t)}for(var r=[],o=0,s=h(e);o<s.length;o++){var c=s[o],d=[];r.push(d),d.push([c[0][0],c[0][1]]);for(var u=0;u<c.length-1;u++){var p=c[u][0],v=c[u][1],m=c[u+1][0],g=c[u+1][1],y=Math.sqrt((m-p)*(m-p)+(g-v)*(g-v)),x=(g-v)/y,S=(m-p)/y,b=y/n;if(b>1){for(var _=1;_<=b-1;_++){var P=_*n,C=S*P+p,O=x*P+v;d.push([C,O])}var E=(y+Math.floor(b-1)*n)/2,A=S*E+p,T=x*E+v;d.push([A,T])}d.push([m,g])}}return f(e)?new a({rings:r,spatialReference:e.spatialReference}):new l({paths:r,spatialReference:e.spatialReference})}function S(e,n,t){if(n){var i=x(e,1e6);e=d.webMercatorToGeographic(i,!0)}return t&&(e=g(e,t)),e}function b(e,n,t){var i;if(Array.isArray(e)){if((i=e[0])>n){var r=m(i,n);e[0]=i+r*(-2*n)}else if(i<t){r=m(i,t);e[0]=i+r*(-2*t)}}else if((i=e.x)>n){r=m(i,n);e=e.clone().offset(r*(-2*n),0)}else if(i<t){r=m(i,t);e=e.clone().offset(r*(-2*t),0)}return e}function _(e,n){for(var t=-1,i=0;i<n.cutIndexes.length;i++)!function(i){for(var r=n.cutIndexes[i],o=n.geometries[i],a=h(o),l=0;l<a.length;l++)!function(e){var n=a[e];n.some(function(t){if(t[0]<180)return!0;for(var i=0,r=0;r<n.length;r++){var a=n[r][0];i=a>i?a:i}for(var l=-360*m(i=Number(i.toFixed(9)),180),s=0;s<n.length;s++){var c=o.getPoint(e,s);o.setPoint(e,s,c.clone().offset(l,0))}return!0})}(l);if(r===t){if(p(e))for(var s=0,c=h(o);s<c.length;s++){var d=c[s];e[r]=e[r].addRing(d)}else if(v(e))for(var u=0,f=h(o);u<f.length;u++){var g=f[u];e[r]=e[r].addPath(g)}}else t=r,e[r]=o}(i);return e}function P(){return C||(C=new u({url:t.geometryServiceUrl})),C}Object.defineProperty(n,"__esModule",{value:!0});var C,w=r.getLogger("esri.geometry.support.normalizeUtils"),O={102100:{maxX:20037508.342788905,minX:-20037508.342788905,plus180Line:new l({paths:[[[20037508.342788905,-20037508.342788905],[20037508.342788905,20037508.342788905]]],spatialReference:s.WebMercator}),minus180Line:new l({paths:[[[-20037508.342788905,-20037508.342788905],[-20037508.342788905,20037508.342788905]]],spatialReference:s.WebMercator})},4326:{maxX:180,minX:-180,plus180Line:new l({paths:[[[180,-180],[180,180]]],spatialReference:s.WebMercator}),minus180Line:new l({paths:[[[-180,-180],[-180,180]]],spatialReference:s.WebMercator})}};n.straightLineDensify=x,n.normalizeCentralMeridian=function e(n,t,i){if(!Array.isArray(n))return e([n],t);t||(t=P());for(var r,s,u,f,p,v,h,y,x=0,C=[],w=[],E=0,A=n;E<A.length;E++){var T=A[E];if(T)if(r||(r=T.spatialReference,s=c.getInfo(r),u=r.isWebMercator,f=O[v=u?102100:4326].maxX,p=O[v].minX,h=O[v].plus180Line,y=O[v].minus180Line),s)if("mesh"===T.type)w.push(T);else if("point"===T.type)w.push(b(T.clone(),f,p));else if("multipoint"===T.type){var R=T.clone();R.points=R.points.map(function(e){return b(e,f,p)}),w.push(R)}else if("extent"===T.type){var I=(D=T.clone())._normalize(!1,!1,s);w.push(I.rings?new a(I):I)}else if(T.extent){var D,M=m((D=T.extent).xmin,p)*(2*f),z=0===M?T.clone():g(T.clone(),M);D.offset(M,0),D.intersects(h)&&D.xmax!==f?(x=D.xmax>x?D.xmax:x,z=S(z,u),C.push(z),w.push("cut")):D.intersects(y)&&D.xmin!==p?(x=D.xmax*(2*f)>x?D.xmax*(2*f):x,z=S(z,u,360),C.push(z),w.push("cut")):w.push(z)}else w.push(T.clone());else w.push(T);else w.push(T)}for(var L=m(x,f),N=-90,V=L,F=new l;L>0;){var U=360*L-180;F.addPath([[U,N],[U,-1*N]]),N*=-1,L--}if(C.length>0&&V>0)return t.cut(C,F,i).then(function(e){return _(C,e)}).then(function(e){for(var r=[],o=[],a=0;a<w.length;a++){var l=w[a];if("cut"!==l)o.push(l);else{var s=e.shift(),c=n[a];"polygon"===c.type&&c.rings&&c.rings.length>1&&s.rings.length>=c.rings.length?(r.push(s),o.push("simplify")):o.push(u?d.geographicToWebMercator(s):s)}}return r.length?t.simplify(r,i).then(function(e){for(var n=[],t=0;t<o.length;t++){var i=o[t];"simplify"!==i?n.push(i):n.push(u?d.geographicToWebMercator(e.shift()):e.shift())}return n}):o});for(var j=[],B=0;B<w.length;B++){var G=w[B];if("cut"!==G)j.push(G);else{var H=C.shift();j.push(!0===u?d.geographicToWebMercator(H):H)}}return o.resolve(j)},n.getDenormalizedExtent=function(e){var n;if(!e)return null;var t=e.extent;if(!t)return null;var i=e.spatialReference&&c.getInfo(e.spatialReference);if(!i)return t;var r,o=i.valid,a=o[0],l=o[1],s=2*l,d=t.width,u=t.xmin,f=t.xmax;if(u=(n=[f,u])[0],f=n[1],"extent"===e.type||0===d||d<=l||d>s||u<a||f>l)return t;switch(e.type){case"polygon":if(!(e.rings.length>1))return t;r=y(e.rings);break;case"polyline":if(!(e.paths.length>1))return t;r=y(e.paths);break;case"multipoint":r=e.points}for(var p=t.clone(),v=0;v<r.length;v++){var h=r[v][0];h<0?(h+=l,f=Math.max(h,f)):(h-=l,u=Math.min(h,u))}return p.xmin=u,p.xmax=f,p.width<d?(p.xmin-=l,p.xmax-=l,p):t},n.normalizeMapX=function(e,n){var t=c.getInfo(n);if(t){var i=t.valid,r=i[0],o=i[1],a=o-r;if(e<r)for(;e<r;)e+=a;if(e>o)for(;e>o;)e-=a}return e}}.apply(null,i))||(e.exports=r)},gKSc:function(e,n,t){var i,r;i=[t.dj.c(e.i),n],void 0===(r=function(e,n){Object.defineProperty(n,"__esModule",{value:!0}),n.create=function(){var e=new Float32Array(4);return e[3]=1,e},n.clone=function(e){var n=new Float32Array(4);return n[0]=e[0],n[1]=e[1],n[2]=e[2],n[3]=e[3],n},n.fromValues=function(e,n,t,i){var r=new Float32Array(4);return r[0]=e,r[1]=n,r[2]=t,r[3]=i,r},n.createView=function(e,n){return new Float32Array(e,n,4)}}.apply(null,i))||(e.exports=r)},kFFy:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("FXVB"),t("oZZu"),t("1m5D"),t("0LE5"),t("vlC2"),t("Rdxj"),t("2fXB"),t("WRgd"),t("aWgr"),t("aWgr"),t("QyYG"),t("9DjX"),t("2A3h"),t("s6rJ"),t("116h"),t("QFi0"),t("qbr3"),t("z2+Q")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u,f,p,v,h,m,g,y,x){function S(e){return e?256:64}function b(e,n,t,i,r){if(t.drawScreenSpace)return t.fixedSize*n*i;var o=S(r)*n*i;return t.drawFixedSize?Math.min(t.fixedSize/2,o):t.screenMinSize>0?Math.min(Math.max(t.screenMinSize*n*i,e/2),o):Math.min(e/2,o)}function _(e,n,t,i,r){return t.drawScreenSpace?0:b(e,n,t,i,r)}function P(e,n,t){return null==t&&(t=l.vec3f64.create()),t[0]=e.origin[0]+e.coordinates[3*n],t[1]=e.origin[1]+e.coordinates[3*n+1],t[2]=e.origin[2]+e.coordinates[3*n+2],t}var C=r.mat4f64.create(),w={positions:[{name:"aPosition",count:3,type:5126,offset:0,stride:12,normalized:!1}],colors:[{name:"aColor",count:3,type:5121,offset:0,stride:3,normalized:!0}]},O=function(){function e(){this.didRender=!1,this.needsRender=!0,this.layerUid="",this._useFixedSizes=!1,this._scaleFactor=1,this._minSizePx=0,this._useRealWorldSymbolSizes=!1,this._size=0,this._sizePx=0,this._slicePlaneEnabled=!1,this._clipBox=c.create(c.POSITIVE_INFINITY),this._programRep=null,this._needsPrograms=!0,this._programWorld=null,this._programScreen=null,this._programWorldDepth=null,this._programScreenDepth=null,this.tempMatrix4=i.mat4f32.create(),this.tempVec3=a.vec3f32.create(),this.nodes=[]}return e.prototype.initializeRenderContext=function(e){var n=e.rctx;this._programRep=new v(n),this.needsRender=!0,this._needsPrograms=!0},e.prototype.uninitializeRenderContext=function(e){this._programRep.dispose(),this._programRep=null,this._programWorld=null,this._programScreen=null,this._programWorldDepth=null,this._programScreenDepth=null},e.prototype.intersect=function(e,n,t,i,r){var a=l.vec3f64.create(),v=l.vec3f64.create(),h=l.vec3f64.create(),m=l.vec3f64.create(),g=u.plane.create(),y=e.camera.perScreenPixelRatio/2,x=e.camera.near,S=this._getSizeParams();o.vec3.subtract(v,i,t);var w=1/o.vec3.length(v);o.vec3.scale(v,v,w),o.vec3.negate(h,v),s.vec4.set(g,v[0],v[1],v[2],-o.vec3.dot(v,t));var O={},E={},A=[],T=c.create(),R=c.create(this._clipBox);c.offset(R,-t[0],-t[1],-t[2],R);for(var I=0,D=this.nodes;I<D.length;I++){var M=D[I],z=M.splatSize*this._scaleFactor,L=f.minimumDistancePlane(M.obb,g),N=f.maximumDistancePlane(M.obb,g);if(L-=_(z,L+x,S,y,M.isLeaf),!((N-=_(z,N+x,S,y,M.isLeaf))<0)&&!(null!=O.dist&&null!=E.dist&&O.dist<L*w&&E.dist>N*w)){var V=b(z,N+x,S,y,M.isLeaf);if(f.intersectLine(M.obb,t,v,V)){var F=V*V;f.toAaBoundingBox(M.obb,T),c.offset(T,-t[0],-t[1],-t[2],T);var U=!c.contains(R,T);o.vec3.subtract(m,M.origin,t);for(var j=M.coordinates.length/3,B=0;B<j;B++)if(a[0]=m[0]+M.coordinates[3*B],a[1]=m[1]+M.coordinates[3*B+1],a[2]=m[2]+M.coordinates[3*B+2],!U||c.containsPoint(R,a)){var G=o.vec3.dot(a,v),H=o.vec3.squaredLength(a)-G*G;if(!(H>F)){var k=G+x,W=_(z,k,S,y,M.isLeaf);if(!(G-W<0)){var X=b(z,k-=W,S,y,M.isLeaf);if(!(H>X*X)){var q=this.layerUid+"/"+M.id+"/"+B,Z=(G-W)*w;if(null==O.dist||Z<O.dist){var Y=O;(null==n||n(t,i,Z))&&(Y.point=P(M,B,Y.point),Y.dist=Z,Y.normal=h,Y.pointId=q,Y.layerUid=this.layerUid)}if(null==E.dist||Z>E.dist){Y=E;(null==n||n(t,i,Z))&&(Y.point=P(M,B,Y.point),Y.dist=Z,Y.normal=h,Y.pointId=q,Y.layerUid=this.layerUid)}if((null==n||n(t,i,Z))&&e.enable.storeAll){var Q={};Q.point=P(M,B,Q.point),Q.dist=Z,Q.normal=h,Q.pointId=q,Q.layerUid=this.layerUid,A.push(Q)}}}}}}}}if(null!=O.dist){var K=e.results.min;if(null==K.dist||O.dist<K.dist){var J={type:"external",point:O.point,metadata:{pointId:O.pointId,layerUid:O.layerUid}};K.set(J,O.pointId,O.dist,O.normal,C,void 0),K.intersector="PointRenderer"}}if(null!=E.dist){var $=e.results.max;if(null==$.dist||E.dist>$.dist){J={type:"external",point:E.point,metadata:{pointId:E.pointId,layerUid:E.layerUid}};$.set(J,E.pointId,E.dist,E.normal,C,void 0),$.intersector="PointRenderer"}}if(e.enable.storeAll)for(var ee=d.ray.fromPoints(t,i),ne=0,te=A;ne<te.length;ne++){J={type:"external",point:(Y=te[ne]).point,metadata:{pointId:Y.pointId,layerUid:Y.layerUid}};var ie=new p.IntersectorResult(ee);ie.set(J,Y.pointId,Y.dist,Y.normal,C,void 0),ie.intersector="PointRenderer",e.results.all.push(ie)}},e.prototype.render=function(e){if(0!==e.pass&&1!==e.pass)return!1;for(var n=1===e.pass,i=e.rctx,r=0,a=this.nodes;r<a.length;r++){null==(g=a[r]).vao&&this._initNode(e,g)}this._selectPrograms();var l=this._getSizeParams(),s=n?l.drawScreenSpace?this._programScreenDepth:this._programWorldDepth:l.drawScreenSpace?this._programScreen:this._programWorld;if(null==s||0===this.nodes.length)return!0;var d=this._clipBox,u=!c.equals(d,c.POSITIVE_INFINITY,function(e,n){return e===n});u||(o.vec3.set(this.tempVec3,-1/0,-1/0,-1/0),s.setUniform3fv("uClipMin",this.tempVec3),o.vec3.set(this.tempVec3,1/0,1/0,1/0),s.setUniform3fv("uClipMax",this.tempVec3)),i.bindProgram(s),i.setPipelineState(this._pipelineState),s.setUniformMatrix4fv("uProjectionMatrix",e.camera.projectionMatrix),n&&s.setUniform2f("nearFar",e.camera.near,e.camera.far);var f=e.camera.pixelRatio;l.drawFixedSize&&s.setUniform2f("uPointScale",l.fixedSize*f,e.camera.fullHeight);for(var p=this._slicePlaneEnabled?e.sliceHelper&&e.sliceHelper.plane:null,v=0,m=this.nodes;v<m.length;v++){var g=m[v];if(s.setUniform2f("uScreenMinMaxSize",l.screenMinSize*f,S(g.isLeaf)*f),!l.drawFixedSize){var y=g.splatSize*this._scaleFactor;s.setUniform2f("uPointScale",y*f,e.camera.fullHeight/f)}var x=g.origin;u&&(o.vec3.set(this.tempVec3,d[0]-x[0],d[1]-x[1],d[2]-x[2]),s.setUniform3fv("uClipMin",this.tempVec3),o.vec3.set(this.tempVec3,d[3]-x[0],d[4]-x[1],d[5]-x[2]),s.setUniform3fv("uClipMax",this.tempVec3)),t.mat4.identity(this.tempMatrix4),t.mat4.translate(this.tempMatrix4,this.tempMatrix4,x),t.mat4.multiply(this.tempMatrix4,e.camera.viewMatrix,this.tempMatrix4),s.setUniformMatrix4fv("uModelViewMatrix",this.tempMatrix4),p&&h.bindSlicePlane(x,p,s),i.bindVAO(g.vao),i.drawArrays(0,0,g.coordinates.length/3)}return!0},Object.defineProperty(e.prototype,"useFixedSizes",{get:function(){return this._useFixedSizes},set:function(e){this._useFixedSizes!==e&&(this._useFixedSizes=e,this._requestRender())},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"scaleFactor",{get:function(){return this._scaleFactor},set:function(e){this._scaleFactor!==e&&(this._scaleFactor=e,this._requestRender())},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"minSizePx",{get:function(){return this._minSizePx},set:function(e){this._minSizePx!==e&&(this._minSizePx=e,this._requestRender())},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"useRealWorldSymbolSizes",{get:function(){return this._useRealWorldSymbolSizes},set:function(e){this._useRealWorldSymbolSizes!==e&&(this._useRealWorldSymbolSizes=e,this._requestRender())},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"size",{get:function(){return this._size},set:function(e){this._size!==e&&(this._size=e,this._requestRender())},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"sizePx",{get:function(){return this._sizePx},set:function(e){this._sizePx!==e&&(this._sizePx=e,this._requestRender())},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"clippingBox",{set:function(e){c.set(this._clipBox,e||c.POSITIVE_INFINITY)},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"slicePlaneEnabled",{get:function(){return this._slicePlaneEnabled},set:function(e){this._slicePlaneEnabled!==e&&(this._slicePlaneEnabled=e,this._requestRender(),this._needsPrograms=!0)},enumerable:!0,configurable:!0}),Object.defineProperty(e.prototype,"intersectionHandlerId",{get:function(){return this.layerUid},enumerable:!0,configurable:!0}),e.prototype.addNode=function(e){this.nodes.push(e),this._requestRender()},e.prototype.removeNode=function(e){var n=null;return this.nodes=this.nodes.filter(function(t){return t.id!==e||(n=t,t.vao&&(t.vao.dispose(!0),t.vao=null),!1)}),this._requestRender(),n},e.prototype.removeAll=function(){this.nodes.forEach(function(e){e.vao&&(e.vao.dispose(!0),e.vao=null)}),this.nodes=[],this._requestRender()},e.prototype._initNode=function(e,n){var t=e.rctx;n.vao=new x(t,m.program.attributes,w,{positions:g.createVertex(t,35044,n.coordinates),colors:g.createVertex(t,35044,n.rgb)})},e.prototype._requestRender=function(){this.didRender=!1,this.needsRender=!0},e.prototype._getSizeParams=function(){var e=this._useFixedSizes,n=e&&!this._useRealWorldSymbolSizes,t=n?this._sizePx:this._size,i=this._minSizePx;return e&&(i=0),{drawScreenSpace:n,drawFixedSize:e,fixedSize:t,screenMinSize:i}},e.prototype._selectPrograms=function(){this._needsPrograms&&(this._needsPrograms=!1,this._programWorld=this._programRep.getProgram(m.program,{slicePlaneEnabled:this._slicePlaneEnabled}),this._programScreen=this._programRep.getProgram(m.program,{drawScreenSize:!0,slicePlaneEnabled:this._slicePlaneEnabled}),this._programWorldDepth=this._programRep.getProgram(m.program,{depthPass:!0,slicePlaneEnabled:this._slicePlaneEnabled}),this._programScreenDepth=this._programRep.getProgram(m.program,{drawScreenSize:!0,depthPass:!0,slicePlaneEnabled:this._slicePlaneEnabled}),this._pipelineState=y.makePipelineState({depthTest:{func:513},depthWrite:y.defaultDepthWriteParams,colorWrite:y.defaultColorWriteParams}))},e}();return(O||(O={})).isInstanceOfNode=function(e){return e.hasOwnProperty("splatSize")},O}.apply(null,i))||(e.exports=r)},ku25:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("zp6E"),t("KY0m"),t("ma1f"),t("qMld"),t("rusB"),t("jfWY"),t("FXVB"),t("O7NG"),t("Z4y+"),t("WRgd"),t("vtMp"),t("uajq"),t("IpeC"),t("W2ph"),t("mmEe"),t("JjCO")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u,f,p,v,h,m,g){function y(e){return e&&parseInt(e.substring(e.lastIndexOf("/")+1,e.length),10)}function x(e,n){var t,i=n[0],r=n[1],o=n[2],a=n[3],l=0;i<e[0]&&(l+=(t=e[0]-i)*t);r<e[1]&&(l+=(t=e[1]-r)*t);o<e[2]&&(l+=(t=e[2]-o)*t);i>e[3]&&(l+=(t=i-e[3])*t);r>e[4]&&(l+=(t=r-e[4])*t);o>e[5]&&(l+=(t=o-e[5])*t);if(l>a*a)return 0;if(l>0)return 1;var s=1/0;return i-e[0]<s&&(s=i-e[0]),r-e[1]<s&&(s=r-e[1]),o-e[2]<s&&(s=o-e[2]),e[3]-i<s&&(s=e[3]-i),e[4]-r<s&&(s=e[4]-r),e[5]-o<s&&(s=e[5]-o),s>a?2:1}function S(e,n,t){for(var i=[],r=t&&t.missingFields,o=t&&t.originalFields,a=0,l=e;a<l.length;a++){for(var s=l[a],c=s.toLowerCase(),d=!1,u=0,f=n;u<f.length;u++){var p=f[u];if(c===p.name.toLowerCase()){i.push(p.name),d=!0,o&&o.push(s);break}}!d&&r&&r.push(s)}return i}function b(e,n){return e.filter(function(e){return e.toLowerCase()!==n.toLowerCase()}).concat([n])}function _(e,n,t,i){n.sort(function(e,n){return e.attributes[t]-n.attributes[t]});var r=n.map(function(e){return e.attributes[t]}),o=[],a=S(i,e.fields,{originalFields:o});return C(e,r,a).then(function(e){for(var t=0;t<n.length;t++){var i=n[t],r=e[t];i.attributes={};for(var l=0;l<o.length;l++)i.attributes[o[l]]=r[a[l]]}return n})}function P(e,n){for(var t=[],i=0,r=e;i<r.length;i++){var o=r[i];o in n.attributes||t.push(o)}return t}function C(e,n,t){if(null!=e.maxRecordCount&&n.length>e.maxRecordCount){var i=E(n,e.maxRecordCount);return o.all(i.map(function(n){return C(e,n,t)})).then(A)}var a=new v({objectIds:n,outFields:t,orderByFields:[e.objectIdField]});return new p(e.parsedUrl.path).execute(a).then(function(e){return e&&e.features&&e.features.length===n.length?e.features.map(function(e){return e.attributes}):o.reject(new r("scenelayer:feature-not-in-associated-layer","Feature not found in associated feature layer"))})}function w(e,n,i,a,s){for(var c=[],d=0;d<n.attributeData.length;d++){var u=n.attributeData[d],f=e[d];if(f&&-1!==a.indexOf(f.name)){var p=l.makeAbsolute(u.href,n.baseUrl);c.push({url:p,storageInfo:f})}}return o.eachAlways(c.map(function(e){return t(e.url,{responseType:"array-buffer"}).then(function(n){return h.readBinaryAttribute(e.storageInfo,n.data)})})).then(function(e){var n=[];if(!s.ignoreUnavailableFields&&e.some(function(e){return null==e.value})){for(var t=[],a=0;a<e.length;a++)null==e[a].value&&t.push({name:c[a].storageInfo.name,error:e[a].error});return o.reject(new r("scenelayer:attribute-request-failed","Request for scene layer attributes failed",{failedAttributes:t}))}for(var l=0,d=i;l<d.length;l++){var u=d[l],f={};for(a=0;a<e.length;a++)null!=e[a].value&&(f[c[a].storageInfo.name]=O(e[a].value,u));n.push(f)}return n})}function O(e,n){var t=e[n];return a.isInt16Array(e)?t===U?null:t:a.isInt32Array(e)?t===j?null:t:t!=t?null:t}function E(e,n){for(var t=e.length,i=Math.ceil(t/n),r=[],o=0;o<i;o++){var a=Math.floor(t*o/i),l=Math.floor(t*(o+1)/i);r.push(e.slice(a,l))}return r}function A(e){for(var n=[],t=0,i=e;t<i.length;t++){var r=i[t];n=n.concat(r)}return n}function T(e){var n=new d(y(e.store.indexCRS||e.store.geographicCRS));return n.equals(e.spatialReference)?e.spatialReference:n}function R(e){var n=new d(y(e.store.vertexCRS||e.store.projectedCRS));return n.equals(e.spatialReference)?e.spatialReference:n}function I(e,n,t){if(!f.canProject(e,n))throw new r("layerview:spatial-reference-incompatible","The spatial reference of this scene layer is incompatible with the spatial reference of the view",{});if("local"===t&&e.isGeographic)throw new r("layerview:local-gcs-not-supported","Geographic coordinate systems are not supported in local scenes",{})}function D(e,n,t){var i=T(e),r=R(e);I(i,n,t),I(r,n,t)}function M(e){return!(null!=e.geometryType&&"triangles"!==e.geometryType||null!=e.topology&&"PerAttributeArray"!==e.topology||null==e.vertexAttributes||null==e.vertexAttributes.position)}function z(e){return!(null==e.geometryType||"points"!==e.geometryType||null!=e.topology&&"PerAttributeArray"!==e.topology||null!=e.encoding&&""!==e.encoding&&"lepcc-xyz"!==e.encoding||null==e.vertexAttributes||null==e.vertexAttributes.position)}function L(e){return"simple"===e.type||"class-breaks"===e.type||"unique-value"===e.type}function N(e){return"mesh-3d"===e.type}Object.defineProperty(n,"__esModule",{value:!0}),n.DDS_ENCODING_STRING="image/vnd-ms.dds",n.BROWSER_SUPPORTED_IMAGE_ENCODING_STRINGS=["image/jpeg","image/png"],n.extractWkid=y,n.getAppropriateTextureEncoding=function(e,t){if(Array.isArray(e)){if(t){var i=e.indexOf(n.DDS_ENCODING_STRING);if(i>-1)return i}for(var r=0;r<e.length;r++)if(n.BROWSER_SUPPORTED_IMAGE_ENCODING_STRINGS.indexOf(e[r])>-1)return r;throw new Error("Could not find appropriate texture encoding (among "+e.toString()+")")}return-1},n.findIntersectingNodes=function(e,n,t,i,r,o){r.traverse(t,function(t){var r=t.mbs;if(n!==i&&(r=F,m.mbsToMbs(t.mbs,i,r,n)),0!==x(e,r))return o(t),!0})},n.filterInPlace=function(e,n,t){for(var i=0,r=0,o=0;o<n.length&&i<e.length;o++)e[i]===n[o]&&(t(o)&&(e[r]=e[i],r++),i++);e.length=r};var V=u.create();n.getClipAABB=function(e,n){var t=s.mat4.copy(g.sm4d.get(),n.objectTransformation),i=n.getGeometryRecords()[0].getShaderTransformation();if(s.mat4.multiply(t,t,i),0===t[1]&&0===t[2]&&0===t[3]&&0===t[4]&&0===t[6]&&0===t[7]&&0===t[8]&&0===t[9]&&0===t[11]&&1===t[15])return V[0]=(e[0]-t[12])/t[0],V[1]=(e[1]-t[13])/t[5],V[2]=(e[2]-t[14])/t[10],V[3]=(e[3]-t[12])/t[0],V[4]=(e[4]-t[13])/t[5],V[5]=(e[5]-t[14])/t[10],V};var F=c.vec4f64.create();n.intersectBoundingBoxWithMbs=x,n.findFieldsCaseInsensitive=S,n.whenGraphicAttributes=function(e,n,t,a,l,s){var c=!0===(s&&s.populateObjectId),d=s.ignoreUnavailableFields?void 0:[],u=1===a.length&&"*"===a[0];!u&&c&&(a=b(a,t));var f=u?a:S(a,e.fields,{missingFields:d});if(d&&0!==d.length)return o.reject(new r("scenelayer:unknown-fields","This scene layer does not have the requested fields",{unknownFields:d}));if(0===n.length)return o.resolve(n);var p=e.associatedLayer,v=e.attributeStorageInfo,h=u?e.fields.map(function(e){return e.name}):f;if(p)return _(p,n,t,h);var m=P(h,n[0]);if(0===m.length)return o.resolve(n);if(v){var g=l(n);return g?o.all(g.map(function(e){return w(v,e.node,e.indices,m,s).then(function(n){for(var t=0;t<e.graphics.length;t++){for(var i=0,r=h;i<r.length;i++){var o=r[i];o in n[t]||(n[t][o]=e.graphics[t].attributes[o])}e.graphics[t].attributes=n[t]}return e.graphics})})).then(i.flatten):o.reject(new r("scenelayer:features-not-loaded","Tried to query attributes for unloaded features"))}return o.reject(new r("scenelayer:no-attribute-source","This scene layer does not have a source for attributes available"))};var U=-Math.pow(2,15),j=-Math.pow(2,31);n.getCachedAttributeValue=O,n.convertFlatRangesToOffsets=function(e,n,t){void 0===t&&(t=2);for(var i=null!=n?n:e.length/t,o=new Uint32Array(i+1),a=0;a<i;a++){var l=e[a*t],s=3*l;o[a]=s;var c=(a-1)*t+1;if(c>=0&&l-1!==e[c])throw new r("Face ranges are not continuous")}var d=3*(e[(i-1)*t+1]+1);return o[o.length-1]=d,o},n.getIndexCrs=T,n.getVertexCrs=R,n.getCacheKeySuffix=function(e,n){return n===m.SphericalECEFSpatialReference?"@ECEF":e.equals(n)?"":null!=n.wkid?"@"+n.wkid:null},n.checkSpatialReference=I,n.checkSpatialReferences=D,n.checkSceneLayerValid=function(e){if(null==e.store||null==e.store.defaultGeometrySchema||!M(e.store.defaultGeometrySchema))throw new r("scenelayer:unsupported-geometry-schema","The geometry schema of this scene layer is not supported.",{})},n.checkSceneLayerCompatibleWithView=function(e,n){D(e,n.spatialReference,n.viewingMode)},n.checkPointCloudLayerValid=function(e){if(null==e.store||null==e.store.defaultGeometrySchema||!z(e.store.defaultGeometrySchema))throw new r("pointcloud:unsupported-geometry-schema","The geometry schema of this point cloud scene layer is not supported.",{})},n.checkPointCloudLayerCompatibleWithView=function(e,n){I(e.spatialReference,n.spatialReference,n.viewingMode)},n.rendererNeedsTextures=function(e){if(null==e||!L(e))return!0;if(("unique-value"===e.type||"class-breaks"===e.type)&&null==e.defaultSymbol)return!0;var n=e.getSymbols();if(0===n.length)return!0;for(var t=0,i=n;t<i.length;t++){var r=i[t];if(!N(r)||0===r.symbolLayers.length)return!0;for(var o=0,a=r.symbolLayers.items;o<a.length;o++){var l=a[o];if("fill"!==l.type||null==l.material||"replace"!==l.material.colorMixMode)return!0}}return!1};var B=function(){this.edges=null,this.material=null,this.castShadows=!0};n.SymbolInfo=B,n.getSymbolInfo=function(e){for(var n=new B,t=!1,i=!1,r=0,o=e.symbolLayers.items;r<o.length;r++){var a=o[r];if("fill"===a.type&&a.enabled){var l=a.material,s=a.edges;if(l&&!t){var c=l.color;n.material={color:c?[c.r/255,c.g/255,c.b/255]:null,alpha:c?c.a:null,colorMixMode:l.colorMixMode},n.castShadows=a.castShadows,t=!0}s&&!i&&(n.edges=a.edges,i=!0)}}return n}}.apply(null,i))||(e.exports=r)},lvSe:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("9opi"),t("qKT0"),t("zp6E"),t("KY0m"),t("KY0m"),t("qsST"),t("qMld"),t("jBNx"),t("8uEs"),t("8MXS"),t("Vx27"),t("0LE5"),t("vlC2"),t("WRgd"),t("tZaU"),t("sSIw"),t("Ondo"),t("wCvz"),t("ku25"),t("F8B7"),t("OA8v"),t("qSbo"),t("kFFy"),t("8Ntk"),t("aWgr"),t("QyYG"),t("mmEe")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u,f,p,v,h,m,g,y,x,S,b,_,P,C,w,O,E,A){function T(e){return 5*e.coordinates.length+128}var R=l.getLogger("esri.views.3d.layers.PointCloudLayerView3D"),I=O.plane.create();return function(e){function n(){var n=null!==e&&e.apply(this,arguments)||this;return n.maximumPointCount=4e6,n.slicePlaneEnabled=!1,n._renderer=null,n._rendererAdded=!1,n._renderedNodes=new Set,n._updateViewNeeded=!0,n._lodFactor=1,n._worker=new x.PointCloudWorker,n._maxLoggedBoxWarnings=5,n._pageMultiplier=1,n._indexQueue=[],n._workQueue=[],n._idleQueue=new m.PromiseQueue,n._indexPagesLoading=new Map,n._loadingNodes=new Map,n._layerIsVisible=!1,n._totalWork=0,n._index=null,n._loadingInitNodePage=!1,n._nodeIdArray=[],n}return t(n,e),Object.defineProperty(n.prototype,"pointScale",{get:function(){var e=P.getSplatSizeAlgorithm(this.layer.renderer);return e&&null!=e.scaleFactor?e.scaleFactor:1},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"useRealWorldSymbolSizes",{get:function(){var e=P.getFixedSizeAlgorithm(this.layer.renderer);return!(!e||null==e.useRealWorldSymbolSizes)&&e.useRealWorldSymbolSizes},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"pointSize",{get:function(){var e=P.getFixedSizeAlgorithm(this.layer.renderer);return e&&null!=e.size?e.size:0},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"inverseDensity",{get:function(){return this.layer.renderer?96/this.layer.renderer.pointsPerInch:5},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"_clippingBox",{get:function(){var e=h.create(),n=this.view.renderSpatialReference;return A.extentToBoundingBox(this.view.clippingArea,e,n)?e:null},enumerable:!0,configurable:!0}),Object.defineProperty(n.prototype,"_elevationOffset",{get:function(){var e=this.layer.elevationInfo;if(e&&"absolute-height"===e.mode){var n=d.getMetersPerVerticalUnitForSR(this.layer.spatialReference),t=g.getMetersPerUnit(e.unit);return(e.offset||0)*t/n}return 0},enumerable:!0,configurable:!0}),n.prototype.initialize=function(){var e=this;S.checkPointCloudLayerValid(this.layer),S.checkPointCloudLayerCompatibleWithView(this.layer,this.view),this._initRenderer();var n=this._initNodePages(),t=this.view.resourceController.memoryController;this._memCache=t.getMemCache(this.layer.uid),this.handles.add(u.init(this,"_clippingBox",function(){return e._setUpdateViewNeeded()})),this.handles.add(u.init(this,"_elevationOffset",function(){return e._elevationOffsetChanged()})),this.handles.add(u.init(this.layer,"renderer",function(){return e._rendererChanged()})),this.handles.add(u.init(this.layer,"filters",function(){return e._filterChanged()})),this.handles.add(u.init(this,"clippingArea",function(){e._setUpdateViewNeeded()})),this.handles.add(this.view.state.watch("camera",function(){return e._setUpdateViewNeeded()})),t.events.on("quality-changed",function(){return e._setUpdateViewNeeded()}),this.addResolvingPromise(n);var i=this.view.resourceController.scheduler;this.when(function(){e.handles.add([i.registerTask(2,function(n){return e._process(n)},function(){return e._needsUpdate()}),i.registerIdleStateCallbacks(function(){return e._idleBegin()},function(){return e._idleEnd()}),u.init(e,"suspended",function(n){n?e._clearNodeState():e._setUpdateViewNeeded()})])})},n.prototype._setUpdateViewNeeded=function(){this._updateViewNeeded=!0,this._updateLoading()},n.prototype.destroy=function(){this._cancelNodeLoading(),this._worker.destroy(),this._worker=null,this._destroyRenderer(),this._memCache.destroy(),this._memCache=null},n.prototype._initRenderer=function(){var e=this;this._renderer=new C,this._renderer.layerUid=this.layer.uid,this.handles.add(u.init(this,"_clippingBox",function(n){return e._renderer.clippingBox=n})),this.handles.add(u.init(this,"suspended",function(n){return e._setPointsVisible(!n)})),this.handles.add(u.init(this,"pointScale",function(n){return e._renderer.scaleFactor=n})),this._renderer.minSizePx=Math.sqrt(2),this.handles.add(u.init(this,"useRealWorldSymbolSizes",function(n){return e._renderer.useRealWorldSymbolSizes=n})),this.handles.add(u.init(this,"pointSize",function(n){var t=c.pt2px(n);e._renderer.size=n,e._renderer.sizePx=t})),this.handles.add(u.init(this,"slicePlaneEnabled",function(n){return e._renderer.slicePlaneEnabled=n})),this.handles.add(u.init(this,["inverseDensity","maximumPointCount"],function(){return e._setUpdateViewNeeded()})),this.handles.add(u.init(this.view,"qualitySettings.sceneService.pointCloud.lodFactor",function(n){e._lodFactor=n,e._setUpdateViewNeeded()}))},n.prototype._destroyRenderer=function(){this._renderer.removeAll(),this._setPointsVisible(!1)},n.prototype._setPointsVisible=function(e){e&&!this._rendererAdded?(this.view._stage.addRenderPlugin([5],this._renderer),this._rendererAdded=!0):!e&&this._rendererAdded&&(this.view._stage.removeRenderPlugin(this._renderer),this._rendererAdded=!1)},n.prototype._rendererChanged=function(){this._clearNodeState(),this._memCache.clear(),this._renderer.useFixedSizes=P.rendererUsesFixedSizes(this.layer.renderer),this._setUpdateViewNeeded()},n.prototype._filterChanged=function(){this._clearNodeState(),this._memCache.clear(),this._setUpdateViewNeeded()},n.prototype._elevationOffsetChanged=function(){this._clearNodeState(),this._memCache.clear(),this._initNodePages()},n.prototype.displayNodes=function(e){this._workQueue=b.nodeDiff(o.keysOfSet(this._renderedNodes),e,this._index),b.sortFrontToBack(this._workQueue,this.view.state.camera.viewForward,this._index),b.splitWorkEntries(this._workQueue,8,this._index),this._updateQueues(),this._totalWork=this._computeWork(),this._updateLoading(),this._layerIsVisible=e.length>0||this._loadingInitNodePage,this.notifyChange("suspended")},n.prototype.cancelLoading=function(){this._cancelNodeLoading(),this._cancelIndexLoading()},n.prototype._cancelNodeLoading=function(){var e=[];this._loadingNodes.forEach(function(n){return e.push(n)}),this._loadingNodes.clear();for(var n=0,t=e;n<t.length;n++)t[n].cancel();this._workQueue=[],this._idleQueue.cancelAll(),this._totalWork=this._computeWork(),this._updateLoading()},n.prototype._updateQueues=function(){var e=this,n=new Set;this._workQueue.forEach(function(e){e.load.forEach(function(e){n.add(e)})});var t=[],i=new Map;this._loadingNodes.forEach(function(e,r){n.has(r)?i.set(r,e):t.push(e)}),this._loadingNodes=i;for(var r=0,o=t;r<o.length;r++)o[r].cancel();this._workQueue=this._workQueue.filter(function(n){for(var t=0,i=n.load;t<i.length;t++){var r=i[t];if(e._loadingNodes.has(r))return!1}return!0}),this._totalWork=this._computeWork(),this._updateLoading()},n.prototype._cancelIndexLoading=function(){this._indexQueue=[],this._indexPagesLoading.forEach(function(e){return e.cancel()}),this._indexPagesLoading.clear(),this._totalWork=this._computeWork(),this._updateLoading()},n.prototype._clearNodeState=function(){var e=this;this._renderedNodes.forEach(function(n){return e._removeFromRenderer(n)}),this._cancelNodeLoading()},n.prototype._idleBegin=function(){this._setUpdateViewNeeded()},n.prototype._idleEnd=function(){this._setUpdateViewNeeded()},n.prototype._needsUpdate=function(){return this.suspended?this._updateViewNeeded:this._updateViewNeeded||this._indexQueue.length>0||this._workQueue.length>0||this._idleQueue.length>0},n.prototype._process=function(e){var n=this;if(this.suspended){if(this._updateViewNeeded){this._updateViewNeeded=!1;var t=this._isRootNodeVisible();t!==this._layerIsVisible&&(this._layerIsVisible=t,this.notifyChange("suspended"))}}else{for(e.run(function(){return n._updateWorkQueues()});this._indexQueue.length>0&&e.run(function(){return n._processIndexQueue()}););for(this._processWorkQueue(e);this._idleQueue.length>0&&e.run(function(){return n._idleQueue.process()}););}},n.prototype._processIndexQueue=function(){var e=this,n=this._indexQueue.shift();return this._indexPagesLoading.set(n,this._loadNodePage(n)),this._indexPagesLoading.get(n).then(function(t){e._index.addPage(n,t,e._elevationOffset),e._setUpdateViewNeeded()}).then(function(){e._indexPagesLoading.delete(n)},function(){e._indexPagesLoading.delete(n)}),!0},n.prototype._processWorkQueue=function(e){for(;!e.done;){var n=this._scheduleWorkEntry();if(!n)return;this._processWorkEntry(n),e.madeProgress()}},n.prototype._scheduleWorkEntry=function(){var e=this;if(this._loadingNodes.size>=8)return null;for(var n=0;n<this._workQueue.length;++n){var t=this._workQueue[n];if(!a.find(t.remove,function(n){return!e._renderedNodes.has(n)})){for(var i=n;i>0;--i)this._workQueue[i]=this._workQueue[i-1];return this._workQueue.shift(),t}}return null},n.prototype._processWorkEntry=function(e){var n=this;if(0!==e.load.length)s.all(e.load.map(function(e){var t=n._memCache.pop(e.toString());return t?n._loadingNodes.set(e,s.resolve(t)):n._loadingNodes.has(e)||n._loadingNodes.set(e,n.loadNode(e)),n._loadingNodes.get(e)})).then(function(t){for(var i=0;i<e.load.length;i++)if(t[i]){var r=n._setupRendererData(e.load[i],t[i]);n._addToRenderer(r)}for(i=0;i<e.remove.length;i++)n._removeFromRenderer(e.remove[i])}).catch(function(){}).then(function(){for(var t=0;t<e.load.length;t++)n._loadingNodes.delete(e.load[t]);n._updateLoading()}),this._updateLoading();else for(var t=0;t<e.remove.length;t++)this._removeFromRenderer(e.remove[t])},n.prototype._computeWork=function(){for(var e=0,n=0;n<this._workQueue.length;n++)e+=this._workQueue[n].load.length;return e+=this._loadingNodes.size,e+=(this._indexQueue.length+this._indexPagesLoading.size)*this._index.pageSize,(e+=this._loadingInitNodePage?100:0)+(this._updateViewNeeded?100:0)},Object.defineProperty(n.prototype,"updatingPercentageValue",{get:function(){var e=this._computeWork();return 100*Math.min(this._totalWork,e)/this._totalWork},enumerable:!0,configurable:!0}),n.prototype._updateLoading=function(){this.notifyChange("updating"),this.notifyChange("updatingPercentageValue")},n.prototype.canResume=function(){return this.inherited(arguments)&&this._layerIsVisible},n.prototype.isUpdating=function(){return this._computeWork()>0},n.prototype._initNodePages=function(){var e=this,n=this.layer.store.index,t=n.nodesPerPage||n.nodePerIndexBlock;return this._index=new _(this.layer.spatialReference,this.view.renderCoordsHelper.spatialReference,t),this._cancelIndexLoading(),this._traverseVisible=this._index.createVisibilityTraverse(),this._loadingInitNodePage=!0,this._layerIsVisible=!0,this.notifyChange("suspended"),this._updateLoading(),this._pageMultiplier=null!=n.nodesPerPage?1:n.nodePerIndexBlock,this._loadNodePage(0).then(function(n){e._index.addPage(0,n,e._elevationOffset),e._loadingInitNodePage=!1,e._setUpdateViewNeeded()})},n.prototype._loadNodePage=function(e){var n=this,t=this.baseUrl+"/nodepages/"+e*this._pageMultiplier;return this._requestJSON(t).then(function(t){return t.data.nodes.map(function(t,i){return{resourceId:null!=t.resourceId?t.resourceId:e*n._index.pageSize+i,obb:t.obb,firstChild:t.firstChild,childCount:t.childCount,vertexCount:null!=t.vertexCount?t.vertexCount:t.pointCount,lodThreshold:null!=t.lodThreshold?t.lodThreshold:t.effectiveArea}})})},n.prototype._updateWorkQueues=function(){if(!this._updateViewNeeded)return!1;for(var e=this.inverseDensity/this._lodFactor*this._getLodMemoryFactor(),n=this.maximumPointCount*this._lodFactor*this._getLodMemoryFactor(),t=this._computeNodesForMinimumDensity(e),i=this._computePointCount(t),r=Math.sqrt(i/(.75*n));i>n;)e*=r,t=this._computeNodesForMinimumDensity(e),i=this._computePointCount(t),r=Math.sqrt(2);return this.displayNodes(t),this._updateViewNeeded=!1,this._updateLoading(),!0},n.prototype._computePointCount=function(e){for(var n=0,t=0;t<e.length;t++){var i=this._index.getNode(e[t]);i&&(n+=i.vertexCount)}return n},n.prototype._getLodMemoryFactor=function(){return this.view.resourceController.memoryController.memoryFactor},n.prototype._isRootNodeVisible=function(){var e=!1;return this._traverseVisible({frustumPlanes:this.view.state.camera.frustum.planes,clippingBox:this._clippingBox},{predicate:function(n,t,i){return e=i,!1},pageMiss:function(e,n){}}),e},n.prototype._computeNodesForMinimumDensity=function(e){var n=this,t=this.view.state.camera,i=t.frustum,r=this._clippingBox,o=t.viewForward,a=p.vec3.dot(o,t.eye),l=O.plane.fromNormalAndOffset(o,-a,I),s=t.perScreenPixelRatio/2,c=e*e,d=this._nodeIdArray;return d.length=0,this._traverseVisible({frustumPlanes:i.planes,clippingBox:r},{predicate:function(e,t,i){if(!i)return!1;if(0===t.childCount)return d.push(e),!1;var r=n._index.getRenderObb(e);return!(n._computeAveragePixelArea(r,t.lodThreshold,t.vertexCount,l,s)<=c&&(d.push(e),1))},pageMiss:function(e,t){d.push(e),n._indexQueue.indexOf(t)<0&&n._indexQueue.push(t)}}),d},n.prototype._computeAveragePixelArea=function(e,n,t,i,r){var o=Math.max(1e-7,E.minimumDistancePlane(e,i));return n/(o*o)/(4*r*r)/t},n.prototype.loadNode=function(e){var n=this,t=this._index.getNode(e),i=P.getRendererInfo(this.layer),r=P.getFilterInfo(this.layer),o=t.resourceId,a=[],l=function(e){var t=n.loadAttribute(o,e);return a.push(t),t};return this._idleQueue.push().then(function(){var e=n.loadGeometry(o);a.push(e);var t=l(i.primaryAttribute),c=l(i.modulationAttribute),d=r.map(function(e){return l(e.attributeInfo)});return s.all([e,t,c,s.all(d)])}).then(function(t){var o=t[0],a=t[1],l=t[2],s=t[3],c=[o];a&&c.push(a),l&&c.push(l);for(var d=0,u=s;d<u.length;d++){var f=u[d];c.push(f)}var p={geometryBuffer:o,primaryAttribute:a,modulationAttribute:l,filterAttributes:s,schema:n.layer.store.defaultGeometrySchema,rendererInfo:i,filterInfo:r,obb:n._index.getRenderObb(e),elevationOffset:n._elevationOffset,inSR:n.layer.spatialReference.toJSON(),outSR:n.view.renderCoordsHelper.spatialReference.toJSON()};return n._worker.transform(p,c)}).catch(function(e){if(null==e||"CancelError"!==e.name&&"AbortError"!==e.name)R.error(e);else for(var n=0,t=a;n<t.length;n++){t[n].cancel()}return s.reject(e)})},n.prototype.loadGeometry=function(e){var n=this.baseUrl+"/nodes/"+e+"/geometries/0";return this._requestBinary(n).then(function(e){return e.data})},n.prototype.loadAttribute=function(e,n){if(!n||!n.storageInfo)return s.resolve(null);var t=n.storageInfo.key,i=this.baseUrl+"/nodes/"+e+"/attributes/"+t;return this._requestBinary(i).then(function(e){return e.data})},n.prototype._requestJSON=function(e){return r(e,{query:{f:"json"},responseType:"json"})},n.prototype._requestBinary=function(e){return r(e,{responseType:"array-buffer"})},n.prototype._removeFromRenderer=function(e){if(this._renderedNodes.has(e)){var n=this._renderer.removeNode(e);this._renderedNodes.delete(e),this._memCache.put(n.id.toString(),n,T(n))}},n.prototype._addToRenderer=function(e){this._renderedNodes.has(e.id)||(this._renderedNodes.add(e.id),this._renderer.addNode(e))},n.prototype._setupRendererData=function(e,n){var t=this._index.getNode(e),i=Math.sqrt(t.lodThreshold/t.vertexCount),r=this._index.getRenderObb(e);if(C.isInstanceOfNode(n))return n.splatSize=i,n.obb=r,n.origin=v.vec3f32.clone(n.obb.center),n;if(n.obb.halfSize[0]>r.halfSize[0]||n.obb.halfSize[1]>r.halfSize[1]||n.obb.halfSize[2]>r.halfSize[2]){if(this._maxLoggedBoxWarnings>0){var o=function(e){return"["+e.halfSize.join(", ")+"]"};R.warn("Node "+e+" reported bounding box too small. got "+o(r)+" but points cover "+o(n.obb)),0==--this._maxLoggedBoxWarnings&&R.warn("  Too many bounding box errors, stopping reporting for this layer.")}this._index.setRenderObb(e,n.obb)}return{id:e,coordinates:n.points,origin:v.vec3f32.clone(r.center),rgb:n.rgb,splatSize:i,obb:r,isLeaf:0===t.childCount}},n.prototype.getUsedMemory=function(){var e=this;return o.keysOfSet(this._renderedNodes).reduce(function(n,t){return n+15*e._index.getNode(t).vertexCount+128},0)},n.prototype.getUnloadedMemory=function(){var e=this,n=this._renderedNodes.size;if(n<4)return 0;for(var t=o.keysOfSet(this._renderedNodes).reduce(function(n,t){return n+e._index.getNode(t).vertexCount}),i=this._loadingNodes.size,r=0;r<this._workQueue.length;r++)i+=this._workQueue[r].load.length,i-=this._workQueue[r].remove.length;return i<0?0:i*t/n*15+128*i},n.prototype.ignoresMemoryFactor=function(){return!1},n.prototype.getStats=function(){var e=this;return{"Rendered Nodes":this._renderedNodes.size,"Rendered Points":o.keysOfSet(this._renderedNodes).reduce(function(n,t){return n+e._index.getNode(t).vertexCount},0),"Loading Nodes":this._loadingNodes.size,"Index Queue":this._indexQueue.length,"Work Queue":this._workQueue.length,"Idle Queue":this._idleQueue.length}},i([f.property()],n.prototype,"layer",void 0),i([f.property({readOnly:!0,aliasOf:"layer.parsedUrl.path"})],n.prototype,"baseUrl",void 0),i([f.property({readOnly:!0,dependsOn:["layer.renderer"]})],n.prototype,"pointScale",null),i([f.property({readOnly:!0,dependsOn:["layer.renderer"]})],n.prototype,"useRealWorldSymbolSizes",null),i([f.property({readOnly:!0,dependsOn:["layer.renderer"]})],n.prototype,"pointSize",null),i([f.property({readOnly:!0,dependsOn:["layer.renderer"]})],n.prototype,"inverseDensity",null),i([f.property()],n.prototype,"maximumPointCount",void 0),i([f.property({readOnly:!0,dependsOn:["view.clippingArea"]})],n.prototype,"_clippingBox",null),i([f.property({readOnly:!0,dependsOn:["layer.elevationInfo"]})],n.prototype,"_elevationOffset",null),i([f.property({type:Boolean})],n.prototype,"slicePlaneEnabled",void 0),i([f.property(w.updatingPercentage)],n.prototype,"updatingPercentage",void 0),i([f.property({readOnly:!0})],n.prototype,"updatingPercentageValue",null),i([f.subclass("esri.views.3d.layers.PointCloudLayerView3D")],n)}(f.declared(y))}.apply(null,i))||(e.exports=r)},mCA8:function(e,n,t){var i,r;i=[t.dj.c(e.i),n],void 0===(r=function(e,n){function t(e,n,t,i,a,s,c,d,u,f,p){return r(e,i,a),_(i,a)<w?1:(m(c,i,a),S(c,c),o(n,i,c,s)<w?2:(m(d,a,s),S(d,d),m(u,s,i),S(u,u),x(t,d,c),S(t,t),l(n,t,c,d,u,f),0))}function i(e,n,t,i,r,o,s,c,d,u){a(e,n,t,i,r,A,T),void 0!==A[0]&&(m(R,A,t),S(R,R),m(I,A,i),S(I,I),m(D,A,r),S(D,D),x(M,I,o),S(M,M),x(z,D,s),S(z,z),x(L,R,c),S(L,L),l(e,M,o,I,R,d),l(e,z,s,D,I,d),l(e,L,c,R,D,d)),void 0!==T[0]&&(m(R,T,t),S(R,R),m(I,T,i),S(I,I),m(D,T,r),S(D,D),x(M,I,o),S(M,M),x(z,D,s),S(z,z),x(L,R,c),S(L,L),l(e,M,o,I,R,d),l(e,z,s,D,I,d),l(e,L,c,R,D,d))}function r(e,n,t){for(var i=_(e.maxVert[0],e.minVert[0]),r=0,o=1;o<7;++o){var a=_(e.maxVert[o],e.minVert[o]);a>i&&(i=a,r=o)}y(n,e.minVert[r]),y(t,e.maxVert[r])}function o(e,n,t,i){for(var r=e.data,o=e.offsetIdx,a=e.strideIdx,l=Number.NEGATIVE_INFINITY,s=0,c=o;c<r.length;c+=a){N[0]=r[c]-n[0],N[1]=r[c+1]-n[1],N[2]=r[c+2]-n[2];var d=t[0]*N[0]+t[1]*N[1]+t[2]*N[2],u=t[0]*t[0]+t[1]*t[1]+t[2]*t[2],f=N[0]*N[0]+N[1]*N[1]+N[2]*N[2]-d*d/u;f>l&&(l=f,s=c)}return y(i,r,s),l}function a(e,n,t,i,r,o,a){c(e,n,V,a,o);var l=P(t,n);V[1]-w<=l&&(o[0]=void 0),V[0]+w>=l&&(a[0]=void 0)}function l(e,n,t,i,r,o){if(!(b(n)<w)){x(F,t,n),x(U,i,n),x(j,r,n),s(e,n,V),G[1]=V[0],B[1]=V[1],H[1]=B[1]-G[1];for(var a=[t,i,r],l=[F,U,j],c=0;c<3;++c){s(e,a[c],V),G[0]=V[0],B[0]=V[1],s(e,l[c],V),G[2]=V[0],B[2]=V[1],H[0]=B[0]-G[0],H[2]=B[2]-G[2];var d=v(H);d<o.quality&&(y(o.b0,a[c]),y(o.b1,n),y(o.b2,l[c]),o.quality=d)}}}function s(e,n,t){var i=e.data,r=e.offsetIdx,o=e.strideIdx;t[0]=Number.POSITIVE_INFINITY,t[1]=Number.NEGATIVE_INFINITY;for(var a=r;a<i.length;a+=o){var l=i[a]*n[0]+i[a+1]*n[1]+i[a+2]*n[2];t[0]=Math.min(t[0],l),t[1]=Math.max(t[1],l)}}function c(e,n,t,i,r){var o=e.data,a=e.offsetIdx,l=e.strideIdx;y(i,o,a),y(r,i),t[0]=P(k,n),t[1]=t[0];for(var s=a+l;s<o.length;s+=l){var c=o[s]*n[0]+o[s+1]*n[1]+o[s+2]*n[2];c<t[0]&&(t[0]=c,y(i,o,s)),c>t[1]&&(t[1]=c,y(r,o,s))}}function d(e,n,t){y(t.center,e),g(t.halfSize,n,.5),t.quaternion[0]=0,t.quaternion[1]=0,t.quaternion[2]=0,t.quaternion[3]=1}function u(e,n,t){y(W,n),Math.abs(n[0])>Math.abs(n[1])&&Math.abs(n[0])>Math.abs(n[2])?W[0]=0:Math.abs(n[1])>Math.abs(n[2])?W[1]=0:W[2]=0,b(W)<w&&(W[0]=W[1]=W[2]=1),x(X,n,W),S(X,X),x(q,n,X),S(q,q),f(e,n,X,q,Z,Y),m(Q,Y,Z),p(n,X,q,Z,Y,Q,t)}function f(e,n,t,i,r,o){s(e,n,V),r[0]=V[0],o[0]=V[1],s(e,t,V),r[1]=V[0],o[1]=V[1],s(e,i,V),r[2]=V[0],o[2]=V[1]}function p(e,n,t,i,r,o,a){J[0]=e[0],J[1]=e[1],J[2]=e[2],J[3]=n[0],J[4]=n[1],J[5]=n[2],J[6]=t[0],J[7]=t[1],J[8]=t[2],C(a.quaternion,J),h($,i,r),g($,$,.5),g(a.center,e,$[0]),g(K,n,$[1]),h(a.center,a.center,K),g(K,t,$[2]),h(a.center,a.center,K),g(a.halfSize,o,.5)}function v(e){return e[0]*e[1]+e[0]*e[2]+e[1]*e[2]}function h(e,n,t){e[0]=n[0]+t[0],e[1]=n[1]+t[1],e[2]=n[2]+t[2]}function m(e,n,t){e[0]=n[0]-t[0],e[1]=n[1]-t[1],e[2]=n[2]-t[2]}function g(e,n,t){e[0]=n[0]*t,e[1]=n[1]*t,e[2]=n[2]*t}function y(e,n,t){void 0===t&&(t=0),e[0]=n[t+0],e[1]=n[t+1],e[2]=n[t+2]}function x(e,n,t){var i=n[0],r=n[1],o=n[2],a=t[0],l=t[1],s=t[2];e[0]=r*s-o*l,e[1]=o*a-i*s,e[2]=i*l-r*a}function S(e,n){var t=n[0]*n[0]+n[1]*n[1]+n[2]*n[2];if(t>0){var i=1/Math.sqrt(t);e[0]=n[0]*i,e[1]=n[1]*i,e[2]=n[2]*i}}function b(e){return e[0]*e[0]+e[1]*e[1]+e[2]*e[2]}function _(e,n){var t=n[0]-e[0],i=n[1]-e[1],r=n[2]-e[2];return t*t+i*i+r*r}function P(e,n){return e[0]*n[0]+e[1]*n[1]+e[2]*n[2]}function C(e,n){var t=n[0]+n[4]+n[8];if(t>0){var i=Math.sqrt(t+1);e[3]=.5*i,i=.5/i,e[0]=(n[5]-n[7])*i,e[1]=(n[6]-n[2])*i,e[2]=(n[1]-n[3])*i}else{var r=0;n[4]>n[0]&&(r=1),n[8]>n[3*r+r]&&(r=2);var o=(r+1)%3,a=(r+2)%3;i=Math.sqrt(n[3*r+r]-n[3*o+o]-n[3*a+a]+1);e[r]=.5*i,i=.5/i,e[3]=(n[3*o+a]-n[3*a+o])*i,e[o]=(n[3*o+r]+n[3*r+o])*i,e[a]=(n[3*a+r]+n[3*r+a])*i}}Object.defineProperty(n,"__esModule",{value:!0});var w=1e-6,O=[0,0,0],E=[0,0,0];n.computeOBB=function(e,n){var r=e.data,o=e.strideIdx,a=r.length/o;if(!(a<=0)){var l=new ne(e);h(O,l.minProj,l.maxProj),g(O,O,.5),m(E,l.maxProj,l.minProj);var s=v(E),c=new te;c.quality=s,a<14&&(e={data:new Float64Array(l.buffer,112,42),size:3,offsetIdx:0,strideIdx:3});var y=[0,0,0],x=[0,0,0],S=[0,0,0],b=[0,0,0],_=[0,0,0],P=[0,0,0],C=[0,0,0];switch(t(l,e,C,y,x,S,b,_,P,c)){case 1:return void d(O,E,n);case 2:return void u(e,b,n)}i(e,C,y,x,S,b,_,P,c),f(e,c.b0,c.b1,c.b2,Z,Y);var w=[0,0,0];m(w,Y,Z),c.quality=v(w),c.quality<s?p(c.b0,c.b1,c.b2,Z,Y,w,n):d(O,E,n)}};var A=[0,0,0],T=[0,0,0],R=[0,0,0],I=[0,0,0],D=[0,0,0],M=[0,0,0],z=[0,0,0],L=[0,0,0],N=[0,0,0],V=[0,0],F=[0,0,0],U=[0,0,0],j=[0,0,0],B=[0,0,0],G=[0,0,0],H=[0,0,0],k=[0,0,0],W=[0,0,0],X=[0,0,0],q=[0,0,0],Z=[0,0,0],Y=[0,0,0],Q=[0,0,0],K=[0,0,0],J=[1,0,0,0,1,0,0,0,1],$=[0,0,0],ee=7,ne=function(e){this.minVert=new Array(ee),this.maxVert=new Array(ee);var n=64*ee;this.buffer=new ArrayBuffer(n);var t=0;this.minProj=new Float64Array(this.buffer,t,ee),t+=8*ee,this.maxProj=new Float64Array(this.buffer,t,ee),t+=8*ee;for(var i=0;i<ee;++i)this.minVert[i]=new Float64Array(this.buffer,t,3),t+=24;for(i=0;i<ee;++i)this.maxVert[i]=new Float64Array(this.buffer,t,3),t+=24;for(i=0;i<ee;++i)this.minProj[i]=Number.POSITIVE_INFINITY,this.maxProj[i]=Number.NEGATIVE_INFINITY;var r=new Array(ee),o=new Array(ee),a=e.data,l=e.offsetIdx,s=e.strideIdx;for(i=l;i<a.length;i+=s){var c=a[i];c<this.minProj[0]&&(this.minProj[0]=c,r[0]=i),c>this.maxProj[0]&&(this.maxProj[0]=c,o[0]=i),(c=a[i+1])<this.minProj[1]&&(this.minProj[1]=c,r[1]=i),c>this.maxProj[1]&&(this.maxProj[1]=c,o[1]=i),(c=a[i+2])<this.minProj[2]&&(this.minProj[2]=c,r[2]=i),c>this.maxProj[2]&&(this.maxProj[2]=c,o[2]=i),(c=a[i]+a[i+1]+a[i+2])<this.minProj[3]&&(this.minProj[3]=c,r[3]=i),c>this.maxProj[3]&&(this.maxProj[3]=c,o[3]=i),(c=a[i]+a[i+1]-a[i+2])<this.minProj[4]&&(this.minProj[4]=c,r[4]=i),c>this.maxProj[4]&&(this.maxProj[4]=c,o[4]=i),(c=a[i]-a[i+1]+a[i+2])<this.minProj[5]&&(this.minProj[5]=c,r[5]=i),c>this.maxProj[5]&&(this.maxProj[5]=c,o[5]=i),(c=a[i]-a[i+1]-a[i+2])<this.minProj[6]&&(this.minProj[6]=c,r[6]=i),c>this.maxProj[6]&&(this.maxProj[6]=c,o[6]=i)}for(i=0;i<ee;++i){var d=r[i];y(this.minVert[i],a,d),d=o[i],y(this.maxVert[i],a,d)}},te=function(){this.b0=[1,0,0],this.b1=[0,1,0],this.b2=[0,0,1],this.quality=0}}.apply(null,i))||(e.exports=r)},qSbo:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("O0KB"),t("qasq"),t("mkxQ"),t("W2ph")],void 0===(r=function(e,n,t,i,r,o){function a(e){for(var n=0,t=0,i=e||[];t<i.length;t++)n|=1<<i[t];return n}function l(e,n){for(var t=0,i=e;t<i.length;t++){var r=i[t];if(r.name===n&&null!=r.attributeValues&&"UInt8"===r.attributeValues.valueType&&3===r.attributeValues.valuesPerElement)return{storageInfo:r,useElevation:!1}}return null}function s(e,n){for(var t=0,i=e;t<i.length;t++){var r=i[t];if(r.name===n){var o="embedded-elevation"===r.encoding;return{storageInfo:o?null:r,useElevation:o}}}return"elevation"===n.toLowerCase()?{storageInfo:null,useElevation:!0}:null}function c(e,n,t,i){if(e&&e.useElevation){for(var r=new Float64Array(i),a=0;a<i;a++)r[a]=t[3*a+2];return r}return e&&n?o.readBinaryAttribute(e.storageInfo,n,i):null}function d(e){return null==e||"none"===e?null:"low-four-bit"===e?function(e){return 15&e}:"high-four-bit"===e?function(e){return(240&e)>>4}:"absolute-value"===e?function(e){return Math.abs(e)}:"modulo-ten"===e?function(e){return e%10}:null}Object.defineProperty(n,"__esModule",{value:!0}),n.getRendererInfo=function(e){var n=e.renderer,t=n&&n.type,i=n&&e.renderer.toJSON()||null,r=null,o=!1;"point-cloud-unique-value"===t?r=s(e.attributeStorageInfo,n.field):"point-cloud-stretch"===t?r=s(e.attributeStorageInfo,n.field):"point-cloud-class-breaks"===t?r=s(e.attributeStorageInfo,n.field):o="point-cloud-rgb"===t?null!=(r=l(e.attributeStorageInfo,n.field)):null!=(r=l(e.attributeStorageInfo,"RGB"));var a=null;return n&&n.colorModulation&&(a=s(e.attributeStorageInfo,n.colorModulation.field)),{rendererJSON:i,isRGBRenderer:o,primaryAttribute:r,modulationAttribute:a}},n.getFilterInfo=function(e){var n=e.filters;return n?n.map(function(n){return{filterJSON:n.toJSON(),attributeInfo:s(e.attributeStorageInfo,n.field)}}):[]},n.evaluateRenderer=function(e,n,o,a,l){var s=e.rendererJSON,u=e.isRGBRenderer,f=e.primaryAttribute,p=e.modulationAttribute,v=c(f,n,a,l),h=c(p,o,a,l),m=null,g=null;if(v&&u)m=v;else if(v&&"pointCloudUniqueValueRenderer"===s.type){var y=(g=r.fromJSON(s)).colorUniqueValueInfos;m=new Uint8Array(3*l);for(var x=d(g.fieldTransformType),S=0;S<l;S++)for(var b=(C=x?x(v[S]):v[S])+"",_=0;_<y.length;_++)if(y[_].values.indexOf(b)>=0){m[3*S]=y[_].color.r,m[3*S+1]=y[_].color.g,m[3*S+2]=y[_].color.b;break}}else if(v&&"pointCloudStretchRenderer"===s.type){var P=(g=i.fromJSON(s)).stops;for(m=new Uint8Array(3*l),x=d(g.fieldTransformType),S=0;S<l;S++){var C=x?x(v[S]):v[S],w=P.length-1;if(C<P[0].value)m[3*S]=P[0].color.r,m[3*S+1]=P[0].color.g,m[3*S+2]=P[0].color.b;else if(C>=P[w].value)m[3*S]=P[w].color.r,m[3*S+1]=P[w].color.g,m[3*S+2]=P[w].color.b;else for(_=1;_<P.length;_++)if(C<P[_].value){var O=(C-P[_-1].value)/(P[_].value-P[_-1].value);m[3*S]=P[_].color.r*O+P[_-1].color.r*(1-O),m[3*S+1]=P[_].color.g*O+P[_-1].color.g*(1-O),m[3*S+2]=P[_].color.b*O+P[_-1].color.b*(1-O);break}}}else if(v&&"pointCloudClassBreaksRenderer"===s.type){var E=(g=t.fromJSON(s)).colorClassBreakInfos;for(m=new Uint8Array(3*l),x=d(g.fieldTransformType),S=0;S<l;S++)for(C=x?x(v[S]):v[S],_=0;_<E.length;_++)if(C>=E[_].minValue&&C<=E[_].maxValue){m[3*S]=E[_].color.r,m[3*S+1]=E[_].color.g,m[3*S+2]=E[_].color.b;break}}else for(m=new Uint8Array(3*l),S=0;S<m.length;S++)m[S]=255;if(h&&g&&g.colorModulation){var A=g.colorModulation.minValue,T=g.colorModulation.maxValue;for(S=0;S<l;S++){var R=(C=h[S])>=T?1:C<=A?.3:.3+.7*(C-A)/(T-A);m[3*S]=R*m[3*S],m[3*S+1]=R*m[3*S+1],m[3*S+2]=R*m[3*S+2]}}return m},n.filterInPlace=function(e,n,t,i){for(var r=e.length/3,o=i.map(function(n,i){return c(t[i].attributeInfo,n,e,r)}),l=0,s=0;s<r;s++){for(var d=!0,u=0;u<t.length&&d;u++){var f=t[u].filterJSON,p=o[u][s];switch(f.type){case"pointCloudValueFilter":var v="exclude"===f.mode;-1!==f.values.indexOf(p)===v&&(d=!1);break;case"pointCloudBitfieldFilter":var h=a(f.requiredSetBits),m=a(f.requiredClearBits);(p&h)===h&&0==(p&m)||(d=!1);break;case"pointCloudReturnFilter":for(var g=15&p,y=p>>>4&15,x=y>1,S=1===g,b=g===y,_=!1,P=0,C=f.includedReturns;P<C.length;P++){var w=C[P];if("last"===w&&b||"firstOfMany"===w&&S&&x||"lastOfMany"===w&&b&&x||"single"===w&&!x){_=!0;break}}_||(d=!1)}}d&&(e[3*l]=e[3*s],e[3*l+1]=e[3*s+1],e[3*l+2]=e[3*s+2],n[3*l]=n[3*s],n[3*l+1]=n[3*s+1],n[3*l+2]=n[3*s+2],l++)}return l},n.getSplatSizeAlgorithm=function(e){var n=e&&e.pointSizeAlgorithm;return n&&"splat"===n.type?n:null},n.getFixedSizeAlgorithm=function(e){var n=e&&e.pointSizeAlgorithm;return n&&"fixed-size"===n.type?n:null},n.rendererUsesFixedSizes=function(e){var n=e&&e.pointSizeAlgorithm;return!(!n||!n.type)&&"fixed-size"===n.type}}.apply(null,i))||(e.exports=r)},qbr3:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("2Atf")],void 0===(r=function(e,n,t){function i(e){return b.intern(e)}function r(e){return _.intern(e)}function o(e){return P.intern(e)}function a(e){return C.intern(e)}function l(e){return w.intern(e)}function s(e){return O.intern(e)}function c(e){return E.intern(e)}function d(e){return A.intern(e)}function u(e){return"["+e.join(",")+"]"}function f(e){return e?u([e.srcRgb,e.srcAlpha,e.dstRgb,e.dstAlpha,e.opRgb,e.opAlpha,e.color.r,e.color.g,e.color.b,e.color.a]):null}function p(e){return e?u([e.face,e.mode]):null}function v(e){return e?u([e.factor,e.units]):null}function h(e){return e?u([e.func]):null}function m(e){return e?u([e.function.func,e.function.ref,e.function.mask,e.operation.fail,e.operation.zFail,e.operation.zPass]):null}function g(e){return e?u([e.zNear,e.zFar]):null}function y(e){return e?u([e.r,e.g,e.b,e.a]):null}function x(e){return e?u([e.mask]):null}Object.defineProperty(n,"__esModule",{value:!0}),n.simpleBlendingParams=function(e,n,t,i){return void 0===t&&(t=32774),void 0===i&&(i=[0,0,0,0]),{srcRgb:e,srcAlpha:e,dstRgb:n,dstAlpha:n,opRgb:t,opAlpha:t,color:{r:i[0],g:i[1],b:i[2],a:i[3]}}},n.separateBlendingParams=function(e,n,t,i,r,o,a){return void 0===r&&(r=32774),void 0===o&&(o=32774),void 0===a&&(a=[0,0,0,0]),{srcRgb:e,srcAlpha:n,dstRgb:t,dstAlpha:i,opRgb:r,opAlpha:o,color:{r:a[0],g:a[1],b:a[2],a:a[3]}}},n.backFaceCullingParams={face:1029,mode:2305},n.defaultDepthWriteParams={zNear:0,zFar:1},n.defaultColorWriteParams={r:!0,g:!0,b:!0,a:!0},n.makeBlending=i,n.makeCulling=r,n.makePolygonOffset=o,n.makeDepthTest=a,n.makeStencilTest=l,n.makeDepthWrite=s,n.makeColorWrite=c,n.makeStencilWrite=d,n.makePipelineState=function(e){return T.intern(e)};var S=function(){function e(e,n){this.makeKey=e,this.makeRef=n,this.interns=new Map}return e.prototype.intern=function(e){if(!e)return null;var n=this.makeKey(e),t=this.interns;return t.has(n)||t.set(n,this.makeRef(e)),t.get(n)},e}(),b=new S(f,function(e){return t({__tag:"Blending"},e)}),_=new S(p,function(e){return t({__tag:"Culling"},e)}),P=new S(v,function(e){return t({__tag:"PolygonOffset"},e)}),C=new S(h,function(e){return t({__tag:"DepthTest"},e)}),w=new S(m,function(e){return t({__tag:"StencilTest"},e)}),O=new S(g,function(e){return t({__tag:"DepthWrite"},e)}),E=new S(y,function(e){return t({__tag:"ColorWrite"},e)}),A=new S(x,function(e){return t({__tag:"StencilWrite"},e)}),T=new S(function(e){return e?u([f(e.blending),p(e.culling),v(e.polygonOffset),h(e.depthTest),m(e.stencilTest),g(e.depthWrite),y(e.colorWrite),x(e.stencilWrite)]):null},function(e){return{blending:i(e.blending),culling:r(e.culling),polygonOffset:o(e.polygonOffset),depthTest:a(e.depthTest),stencilTest:l(e.stencilTest),depthWrite:s(e.depthWrite),colorWrite:c(e.colorWrite),stencilWrite:d(e.stencilWrite)}}),R=function(){function e(e){this._pipelineInvalid=!0,this._blendingInvalid=!0,this._cullingInvalid=!0,this._polygonOffsetInvalid=!0,this._depthTestInvalid=!0,this._stencilTestInvalid=!0,this._depthWriteInvalid=!0,this._colorWriteInvalid=!0,this._stencilWriteInvalid=!0,this._stateSetters=e}return e.prototype.setPipeline=function(e){(this._pipelineInvalid||e!==this._pipeline)&&(this.setBlending(e.blending),this.setCulling(e.culling),this.setPolygonOffset(e.polygonOffset),this.setDepthTest(e.depthTest),this.setStencilTest(e.stencilTest),this.setDepthWrite(e.depthWrite),this.setColorWrite(e.colorWrite),this.setStencilWrite(e.stencilWrite),this._pipeline=e),this._pipelineInvalid=!1},e.prototype.invalidateBlending=function(){this._blendingInvalid=!0,this._pipelineInvalid=!0},e.prototype.invalidateCulling=function(){this._cullingInvalid=!0,this._pipelineInvalid=!0},e.prototype.invalidatePolygonOffset=function(){this._polygonOffsetInvalid=!0,this._pipelineInvalid=!0},e.prototype.invalidateDepthTest=function(){this._depthTestInvalid=!0,this._pipelineInvalid=!0},e.prototype.invalidateStencilTest=function(){this._stencilTestInvalid=!0,this._pipelineInvalid=!0},e.prototype.invalidateDepthWrite=function(){this._depthWriteInvalid=!0,this._pipelineInvalid=!0},e.prototype.invalidateColorWrite=function(){this._colorWriteInvalid=!0,this._pipelineInvalid=!0},e.prototype.invalidateStencilWrite=function(){this._stencilTestInvalid=!0,this._pipelineInvalid=!0},e.prototype.setBlending=function(e){this._blending=this.setSubState(e,this._blending,this._blendingInvalid,this._stateSetters.setBlending),this._blendingInvalid=!1},e.prototype.setCulling=function(e){this._culling=this.setSubState(e,this._culling,this._cullingInvalid,this._stateSetters.setCulling),this._cullingInvalid=!1},e.prototype.setPolygonOffset=function(e){this._polygonOffset=this.setSubState(e,this._polygonOffset,this._polygonOffsetInvalid,this._stateSetters.setPolygonOffset),this._polygonOffsetInvalid=!1},e.prototype.setDepthTest=function(e){this._depthTest=this.setSubState(e,this._depthTest,this._depthTestInvalid,this._stateSetters.setDepthTest),this._depthTestInvalid=!1},e.prototype.setStencilTest=function(e){this._stencilTest=this.setSubState(e,this._stencilTest,this._stencilTestInvalid,this._stateSetters.setStencilTest),this._stencilTestInvalid=!1},e.prototype.setDepthWrite=function(e){this._depthWrite=this.setSubState(e,this._depthWrite,this._depthWriteInvalid,this._stateSetters.setDepthWrite),this._depthWriteInvalid=!1},e.prototype.setColorWrite=function(e){this._colorWrite=this.setSubState(e,this._colorWrite,this._colorWriteInvalid,this._stateSetters.setColorWrite),this._colorWriteInvalid=!1},e.prototype.setStencilWrite=function(e){this._stencilWrite=this.setSubState(e,this._stencilWrite,this._stencilWriteInvalid,this._stateSetters.setStencilWrite),this._stencilTestInvalid=!1},e.prototype.setSubState=function(e,n,t,i){return(t||e!==n)&&(i(e),this._pipelineInvalid=!0),e},e}();n.StateTracker=R}.apply(null,i))||(e.exports=r)},s6rJ:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("FXVB"),t("oZZu"),t("1m5D"),t("0LE5"),t("Rdxj"),t("2fXB"),t("WRgd"),t("AzkI"),t("rjU6"),t("1f+t"),t("+wMf"),t("CIy2")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u,f,p){function v(e,n,t,i,r){var o=x(n,t,E);if(s.setMin(w,e.getBBMin()),s.setMax(w,e.getBBMax()),S(w,n,o,i)){var a=e.getPrimitiveIndices(),l=e.getIndices(),c=e.getPosition(),d=a?a.length:l.length/3;if(d>N){var u=e.getChildren();if(void 0!==u){for(var f=0;f<8;++f)void 0!==u[f]&&v(u[f],n,t,i,r);return}}m(n,t,0,d,l,c,a,r)}}function h(e,n,t,i,r,o){var a=x(t,i,E),l=e.componentCount,c=e.componentOffsets,u=e.getIndices(O.POSITION),f=e.getAttribute(O.POSITION),p=e.boundingInfo;if(!p||(s.setMin(w,p.getBBMin()),s.setMax(w,p.getBBMax()),S(w,t,a,r)))for(var v=0;v<l;v++)if(!n||d.getVisibility(n,v)){if(e.getComponentAABB)if(!S(e.getComponentAABB(v,w),t,a,r))continue;m(t,i,c[v]/3,c[v+1]/3,u,f,void 0,o)}}function m(e,n,t,i,r,o,a,l){if(a)return g(e,n,t,i,r,o,a,l);for(var s=o.data,c=o.offsetIdx,d=o.strideIdx,u=e[0],f=e[1],p=e[2],v=n[0]-u,h=n[1]-f,m=n[2]-p,x=t,S=3*t;x<i;++x){var b=c+d*r[S++],_=s[b++],P=s[b++],C=s[b];b=c+d*r[S++];var w=s[b++],O=s[b++],E=s[b];b=c+d*r[S++];var R=w-_,I=O-P,D=E-C,M=s[b++]-_,z=s[b++]-P,L=s[b]-C,N=h*L-z*m,V=m*M-L*v,F=v*z-M*h,U=R*N+I*V+D*F;if(!(Math.abs(U)<=A)){var j=u-_,B=f-P,G=p-C,H=j*N+B*V+G*F;if(U>0){if(H<0||H>U)continue}else if(H>0||H<U)continue;var k=B*D-I*G,W=G*R-D*j,X=j*I-R*B,q=v*k+h*W+m*X;if(U>0){if(q<0||H+q>U)continue}else if(q>0||H+q<U)continue;var Z=(M*k+z*W+L*X)/U;Z>=0&&l(Z,y(R,I,D,M,z,L,T),x)}}}function g(e,n,t,i,r,o,a,l){for(var s=o.data,c=o.offsetIdx,d=o.strideIdx,u=e[0],f=e[1],p=e[2],v=n[0]-u,h=n[1]-f,m=n[2]-p,g=t;g<i;++g){var x=a[g],S=3*x,b=c+d*r[S++],_=s[b++],P=s[b++],C=s[b];b=c+d*r[S++];var w=s[b++],O=s[b++],E=s[b];b=c+d*r[S];var R=w-_,I=O-P,D=E-C,M=s[b++]-_,z=s[b++]-P,L=s[b]-C,N=h*L-z*m,V=m*M-L*v,F=v*z-M*h,U=R*N+I*V+D*F;if(!(Math.abs(U)<=A)){var j=u-_,B=f-P,G=p-C,H=j*N+B*V+G*F;if(U>0){if(H<0||H>U)continue}else if(H>0||H<U)continue;var k=B*D-I*G,W=G*R-D*j,X=j*I-R*B,q=v*k+h*W+m*X;if(U>0){if(q<0||H+q>U)continue}else if(q>0||H+q<U)continue;var Z=(M*k+z*W+L*X)/U;Z>=0&&l(Z,y(R,I,D,M,z,L,T),x)}}}function y(e,n,t,i,r,a,l){return o.vec3.set(R,e,n,t),o.vec3.set(I,i,r,a),o.vec3.cross(l,R,I),o.vec3.normalize(l,l),l}function x(e,n,t){return o.vec3.set(t,1/(n[0]-e[0]),1/(n[1]-e[1]),1/(n[2]-e[2]))}function S(e,n,t,i){var r=(e[0]-i-n[0])*t[0],o=(e[3]+i-n[0])*t[0],a=Math.min(r,o),l=Math.max(r,o),s=(e[1]-i-n[1])*t[1],c=(e[4]+i-n[1])*t[1];if((a=Math.max(a,Math.min(s,c)))>(l=Math.min(l,Math.max(s,c))))return!1;var d=(e[2]-i-n[2])*t[2],u=(e[5]+i-n[2])*t[2];return(a=Math.max(a,Math.min(d,u)))<=(l=Math.min(l,Math.max(d,u)))}function b(e,n,t,i,r){return f.scale(e,i,t,r)}function _(e,n,t,i){return void 0===i&&(i=V),i.screenLength=e.screenLength,i.perDistance=Math.tan(.5*n)/(.5*t),i.minWorldLength=e.minWorldLength,i.maxWorldLength=e.maxWorldLength,i}function P(e){var n=[];return e.forEach(function(e){return n.push(e)}),n}Object.defineProperty(n,"__esModule",{value:!0});var C=r.mat4f64.create(),w=s.create(),O=p.VertexAttrConstants;n.IDENTITY=r.mat4f64.create(),n.intersectTriangleGeometry=function(e,n,t,i,r,o,a,l){var s=n&&n.componentVisibilities,c=i.tolerance;if(e.componentCount>1)h(e,s,r,o,c,a);else if(!s||d.getVisibility(s,0))if(e.boundingInfo)p.assert("triangle"===e.data.primitiveType),v(e.boundingInfo,r,o,c,a);else{var u=e.getIndices(O.POSITION),f=e.getAttribute(O.POSITION);m(r,o,0,u.length/3,u,f,void 0,a)}};var E=a.vec3f64.create(),A=Math.pow(2,-52),T=a.vec3f64.create();n.intersectTriangles=m;var R=a.vec3f64.create(),I=a.vec3f64.create();n.computeNormal=y,n.intersectAabbInvDir=S,n.transformToWorld=function(e,n,t){return l.vec4.set(t,e[0]-n[0],e[1]-n[1],e[2]-n[2],1)},n.transformToView=function(e,n,i,r){return t.mat4.translate(C,i,n),i=C,l.vec4.transformMat4(r,e,i)},n.transformToProjection=function(e,n,t,i){return i[0]=e[0]+t[0],i[1]=e[1]+t[1],i[2]=e[2]+t[2],i[3]=e[3],l.vec4.transformMat4(i,i,n)},n.transformToNDC=function(e,n){return l.vec4.scale(n,e,1/Math.abs(e[3]))},n.applyScreenSizePerspectiveScale=b,n.verticalOffsetAtDistance=function(e,n,t,i,r){var o=(t.screenLength||0)*e.pixelRatio;r&&(o=b(o,0,n,i,r));var a=o*Math.tan(.5*e.fovY)/(.5*e.fullHeight);return c.clamp(a*n,t.minWorldLength||0,null!=t.maxWorldLength?t.maxWorldLength:1/0)},n.aquireIfNotUndefined=function(e,n,t){if(void 0!==e)return n.aquire(e,t)},n.releaseIfNotUndefined=function(e,n){void 0!==e&&n.release(e)};var D=i.mat4f32.create();n.bindView=function(e,n,i){t.mat4.translate(D,n,e),i.setUniform3fv("localOrigin",e),i.setUniformMatrix4fv("view",D)},n.bindCamPos=function(e,n,t){t.setUniform3f("camPos",n[3]-e[0],n[7]-e[1],n[11]-e[2])};var M=a.vec3f64.create(),z=a.vec3f64.create();n.bindViewOriginDouble=function(e,n){u.encodeDoubleArraySplit(e,M,z,3),n.setUniform3fv("viewOriginHi",M),n.setUniform3fv("viewOriginLo",z)};var L=a.vec3f64.create();n.bindSlicePlane=function(e,n,t){o.vec3.subtract(L,n.origin,e),t.setUniform3fv("slicePlaneOrigin",L),t.setUniform3fv("slicePlaneBasis1",n.basis1),t.setUniform3fv("slicePlaneBasis2",n.basis2)},n.bindVerticalOffset=function(e,n,t){if(e){var i=_(e,n.fovY,n.viewport[3]),r=n.pixelRatio||1;t.setUniform4f("verticalOffset",i.screenLength*r,i.perDistance,i.minWorldLength,i.maxWorldLength)}},n.bindHighlightRendering=function(e,n,t){e.bindTexture(n.highlightDepthTexture,5),t.setUniform1i("depthTex",5),t.setUniform4f("highlightViewportPixelSz",0,0,1/n.viewport[2],1/n.viewport[3])},n.bindScreenSizePerspective=function(e,n,t){if(void 0===t&&(t="screenSizePerspectiveAlignment"),e){var i=e.parameters,r=e.paddingPixelsOverride;n.setUniform4f(t,i.divisor,i.offset,i.minPixelSize,r)}},n.copyParameters=function e(n,t){var i=t?e(t):{};for(var r in n){var o=n[r];o&&o.forEach&&(o=P(o)),null==o&&r in i||(i[r]=o)}return i},n.updateParameters=function(e,n){var t=!1;for(var i in n){var r=n[i];void 0!==r&&(t=!0,Array.isArray(r)?e[i]=r.slice():e[i]=r)}return t},function(e){function n(e){return(e.shadowMappingEnabled?1:0)|(e.ssaoEnabled?2:0)}e.create=function(e,t){for(var i=[],r=0;r<2;r++)for(var o=0;o<2;o++){var a=n({shadowMappingEnabled:1===r,ssaoEnabled:1===o}),l=n({shadowMappingEnabled:1===r,ssaoEnabled:1===o&&e.receiveSSAO});i[a]=i[l]||t({receiveShadows:1===r,receiveSSAO:1===o&&e.receiveSSAO})}return{programs:i.filter(function(e){return null!=e}),byParameter:i}},e.lookup=function(e,t){return e.byParameter[n(t)]},e.programs=function(e){return e.programs}}(n.BindParametersMap||(n.BindParametersMap={})),n.intersectDrapedRenderLineGeometry=function(e,n,t,i,r,o,a,l,s){if(i.enable.selectionMode){for(var d=e.getAttribute(O.POSITION).data,u=e.getAttribute(O.SIZE),f=u&&u.data[0],p=o[0],v=o[1],h=((f+a)/2+4)*e.pixelRatio,m=Number.MAX_VALUE,g=0;g<d.length-5;g+=3){var y=d[g],x=d[g+1],S=p-y,b=v-x,_=d[g+3]-y,P=d[g+4]-x,C=_*S+P*b,w=_*_+P*P,E=c.clamp(C/w,0,1),A=_*E-S,T=P*E-b,R=A*A+T*T;R<m&&(m=R)}m<h*h&&l()}},n.colorMixModes={multiply:1,ignore:2,replace:3,tint:4};var N=1e3,V={screenLength:0,perDistance:0,minWorldLength:0,maxWorldLength:0}}.apply(null,i))||(e.exports=r)},tZaU:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("idNY"),t("qMld")],void 0===(r=function(e,n,t,i){Object.defineProperty(n,"__esModule",{value:!0});var r=function(){function e(){this._deferreds=[],this._values=[]}return e.prototype.push=function(e){var n=this;return i.create(function(t,i){n._deferreds.push({resolve:t,reject:i}),n._values.push(e)})},e.prototype.unshift=function(e){var n=this;return i.create(function(t,i){n._deferreds.unshift({resolve:t,reject:i}),n._values.unshift(e)})},Object.defineProperty(e.prototype,"length",{get:function(){return this._deferreds.length},enumerable:!0,configurable:!0}),e.prototype.process=function(){return 0!==this.length&&(this._deferreds.shift().resolve(this._values.shift()),!0)},e.prototype.cancelAll=function(){for(var e=new t,n=0,i=this._deferreds;n<i.length;n++)i[n].reject(e);this._deferreds.length=0,this._values.length=0},e}();n.PromiseQueue=r}.apply(null,i))||(e.exports=r)},w1v0:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("qKT0"),t("9opi"),t("TMur"),t("jZlN"),t("ycL1"),t("0+sO"),t("Vx27"),t("Z4y+"),t("Lzvl"),t("KQcO")],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u){var f=new l.default({esriGeometryPoint:"point",esriGeometryMultipoint:"multipoint",esriGeometryPolyline:"polyline",esriGeometryPolygon:"polygon",esriGeometryEnvelope:"extent"}),p=function(e){function n(n){var t=e.call(this,n)||this;return t.displayFieldName=null,t.exceededTransferLimit=!1,t.features=[],t.fields=null,t.geometryType=null,t.hasM=!1,t.hasZ=!1,t.queryGeometry=null,t.spatialReference=null,t}return i(n,e),n.prototype.readFeatures=function(e,n){for(var t=c.fromJSON(n.spatialReference),i=[],r=0;r<e.length;r++){var a=e[r],l=o.fromJSON(a),s=a.geometry&&a.geometry.spatialReference;l.geometry&&!s&&(l.geometry.spatialReference=t),i.push(l)}return i},n.prototype.writeGeometryType=function(e,n,t,i){if(e)f.write(e,n,t,i);else{var r=this.features;if(r)for(var o=0,a=r;o<a.length;o++){var l=a[o];if(l&&l.geometry)return void f.write(l.geometry.type,n,t,i)}}},n.prototype.writeSpatialReference=function(e,n,t,i){if(e)n.spatialReference=e.toJSON();else{var r=this.features;if(r)for(var o=0,a=r;o<a.length;o++){var l=a[o];l&&l.geometry&&l.geometry.spatialReference&&(n.spatialReference=l.geometry.spatialReference.toJSON())}}},n.prototype.toJSON=function(e){var n=this.write(null);if(n.features&&Array.isArray(e)&&e.length>0)for(var t=0;t<n.features.length;t++){var i=n.features[t];if(i.geometry){var r=e&&e[t];i.geometry=r&&r.toJSON()||i.geometry}}return n},n.prototype.quantize=function(e){for(var n=e.scale,t=n[0],i=n[1],r=e.translate,o=r[0],a=r[1],l=this.features,s=this._getQuantizationFunction(this.geometryType,function(e){return Math.round((e-o)/t)},function(e){return Math.round((a-e)/i)}),c=0,d=l.length;c<d;c++)s(l[c].geometry)||(l.splice(c,1),c--,d--);return this.transform=e,this},n.prototype.unquantize=function(){var e=this,n=e.geometryType,t=e.features,i=e.transform;if(!i)return this;for(var r=i.translate,o=r[0],a=r[1],l=i.scale,s=l[0],c=l[1],d=this._getHydrationFunction(n,function(e){return e*s+o},function(e){return a-e*c}),u=0,f=t;u<f.length;u++){var p=f[u].geometry;p&&d(p)}return this},n.prototype._quantizePoints=function(e,n,t){for(var i,r,o=[],a=0,l=e.length;a<l;a++){var s=e[a];if(a>0){var c=n(s[0]),d=t(s[1]);c===i&&d===r||(o.push([c-i,d-r]),i=c,r=d)}else i=n(s[0]),r=t(s[1]),o.push([i,r])}return o.length>0?o:null},n.prototype._getQuantizationFunction=function(e,n,t){var i=this;return"point"===e?function(e){return e.x=n(e.x),e.y=t(e.y),e}:"polyline"===e||"polygon"===e?function(e){for(var r=d.isPolygon(e)?e.rings:e.paths,o=[],a=0,l=r.length;a<l;a++){var s=r[a],c=i._quantizePoints(s,n,t);c&&o.push(c)}return o.length>0?(d.isPolygon(e)?e.rings=o:e.paths=o,e):null}:"multipoint"===e?function(e){var r;return(r=i._quantizePoints(e.points,n,t)).length>0?(e.points=r,e):null}:"extent"===e?function(e){return e}:void 0},n.prototype._getHydrationFunction=function(e,n,t){return"point"===e?function(e){e.x=n(e.x),e.y=t(e.y)}:"polyline"===e||"polygon"===e?function(e){for(var i,r,o=d.isPolygon(e)?e.rings:e.paths,a=0,l=o.length;a<l;a++)for(var s=o[a],c=0,u=s.length;c<u;c++){var f=s[c];c>0?(i+=f[0],r+=f[1]):(i=f[0],r=f[1]),f[0]=n(i),f[1]=t(r)}}:"extent"===e?function(e){e.xmin=n(e.xmin),e.ymin=t(e.ymin),e.xmax=n(e.xmax),e.ymax=t(e.ymax)}:"multipoint"===e?function(e){for(var i,r,o=e.points,a=0,l=o.length;a<l;a++){var s=o[a];a>0?(i+=s[0],r+=s[1]):(i=s[0],r=s[1]),s[0]=n(i),s[1]=t(r)}}:void 0},t([s.property({type:String,json:{write:!0}})],n.prototype,"displayFieldName",void 0),t([s.property({type:Boolean,json:{write:{overridePolicy:function(e){return{enabled:e}}}}})],n.prototype,"exceededTransferLimit",void 0),t([s.property({type:[o],json:{write:!0}})],n.prototype,"features",void 0),t([s.reader("features")],n.prototype,"readFeatures",null),t([s.property({type:[u],json:{write:!0}})],n.prototype,"fields",void 0),t([s.property({type:["point","multipoint","polyline","polygon","extent","mesh"],json:{read:{reader:f.read}}})],n.prototype,"geometryType",void 0),t([s.writer("geometryType")],n.prototype,"writeGeometryType",null),t([s.property({type:Boolean,json:{write:{overridePolicy:function(e){return{enabled:e}}}}})],n.prototype,"hasM",void 0),t([s.property({type:Boolean,json:{write:{overridePolicy:function(e){return{enabled:e}}}}})],n.prototype,"hasZ",void 0),t([s.property({types:r.geometryTypes,json:{read:d.fromJSON,write:!0}})],n.prototype,"queryGeometry",void 0),t([s.property({type:c,json:{write:!0}})],n.prototype,"spatialReference",void 0),t([s.writer("spatialReference")],n.prototype,"writeSpatialReference",null),t([s.property({json:{write:!0}})],n.prototype,"transform",void 0),t([s.subclass("esri.tasks.support.FeatureSet")],n)}(s.declared(a));return p.prototype.toJSON.isDefaultToJSON=!0,p||(p={}),p}.apply(null,i))||(e.exports=r)},wCvz:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("xhoE"),t("qMld"),t("ADZV"),t("8V7H"),t("EuvN"),t("fdzS"),t("0LE5"),t("vlC2"),t("Z4y+"),t("W2ph"),t("1RVI"),t("qSbo"),t("mmEe"),t.dj.m(e)],void 0===(r=function(e,n,t,i,r,o,a,l,s,c,d,u,f,p,v,h){Object.defineProperty(n,"__esModule",{value:!0});var m=function(){function e(){}return e.prototype._process=function(e){var n=this._transform(e);return i.resolve({result:n,transferList:[n.points.buffer,n.rgb.buffer]})},e.prototype._transform=function(e){var n=this.readGeometry(e.schema,e.geometryBuffer),t=n.length/3,i=p.evaluateRenderer(e.rendererInfo,e.primaryAttribute,e.modulationAttribute,n,t);e.filterInfo&&e.filterInfo.length>0&&(t=p.filterInPlace(n,i,e.filterInfo,e.filterAttributes)),3*t<i.length&&(i=new Uint8Array(i.buffer.slice(0,3*t))),this._applyElevationOffsetInPlace(n,t,e.elevationOffset);var r=this._transformCoordinates(n,t,e.obb,d.fromJSON(e.inSR),d.fromJSON(e.outSR));return{obb:e.obb,points:r,rgb:i}},e.prototype.readGeometry=function(e,n){if(null==e.encoding||""===e.encoding){for(var t=u.createGeometryDataIndex(n,e,!1),i=u.createTypedView(n,t.vertexAttributes.position),r=t.header.fields,o=[r.offsetX,r.offsetY,r.offsetZ],a=[r.scaleX,r.scaleY,r.scaleZ],l=i.length/3,s=new Float64Array(3*l),c=0;c<l;c++)s[3*c]=i[3*c]*a[0]+o[0],s[3*c+1]=i[3*c+1]*a[1]+o[1],s[3*c+2]=i[3*c+2]*a[2]+o[2];return s}if("lepcc-xyz"===e.encoding)return f.decodeXYZ(n).result},e.prototype._transformCoordinates=function(e,n,t,i,r){if(!v.bufferToBuffer(e,i,0,e,r,0,n))throw Error("Can't reproject");var o=c.vec3f32.fromValues(t.center[0],t.center[1],t.center[2]),l=c.vec3f32.create(),d=c.vec3f32.create();a.quat.conjugate(g,t.quaternion);for(var u=new Float32Array(3*n),f=0;f<n;f++)l[0]=e[3*f]-o[0],l[1]=e[3*f+1]-o[1],l[2]=e[3*f+2]-o[2],s.vec3.transformQuat(d,l,g),t.halfSize[0]=Math.max(t.halfSize[0],Math.abs(d[0])),t.halfSize[1]=Math.max(t.halfSize[1],Math.abs(d[1])),t.halfSize[2]=Math.max(t.halfSize[2],Math.abs(d[2])),u[3*f]=l[0],u[3*f+1]=l[1],u[3*f+2]=l[2];return u},e.prototype._applyElevationOffsetInPlace=function(e,n,t){if(0!==t)for(var i=0;i<n;i++)e[3*i+2]+=t},e}(),g=l.quatf32.create(),y=function(n){function a(){var t=n.call(this)||this;return t._thread=void 0,o.open(r.getAbsMid("./PointCloudWorker",e,h)).then(function(e){void 0===t._thread?t._thread=e:e.close()}),t}return t(a,n),a.prototype.destroy=function(){this._thread&&this._thread.close(),this._thread=null},a.prototype.transform=function(e,n){return this._thread?this._thread.invoke("_process",e,{transferList:n}):i.resolve(this._transform(e))},a}(m);n.PointCloudWorker=y,n.default=function(){return new m}}.apply(null,i))||(e.exports=r)},weYu:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("xf8T"),t("SgdR"),t("jaBu"),t("qysZ"),t("VIrK"),t("bH65")],void 0===(r=function(e,n,t,i,r,o,a,l){function s(e,n,t){t*=.5;var i=Math.sin(t);return e[0]=i*n[0],e[1]=i*n[1],e[2]=i*n[2],e[3]=Math.cos(t),e}function c(e,n,t){var i=n[0],r=n[1],o=n[2],a=n[3],l=t[0],s=t[1],c=t[2],d=t[3];return e[0]=i*d+a*l+r*c-o*s,e[1]=r*d+a*s+o*l-i*c,e[2]=o*d+a*c+i*s-r*l,e[3]=a*d-i*l-r*s-o*c,e}function d(e,n,t,i){var r,a,l,s,c,d=n[0],u=n[1],f=n[2],p=n[3],v=t[0],h=t[1],m=t[2],g=t[3];return(a=d*v+u*h+f*m+p*g)<0&&(a=-a,v=-v,h=-h,m=-m,g=-g),1-a>o.EPSILON?(r=Math.acos(a),l=Math.sin(r),s=Math.sin((1-i)*r)/l,c=Math.sin(i*r)/l):(s=1-i,c=i),e[0]=s*d+c*v,e[1]=s*u+c*h,e[2]=s*f+c*m,e[3]=s*p+c*g,e}function u(e,n){var t,i=n[0]+n[4]+n[8];if(i>0)t=Math.sqrt(i+1),e[3]=.5*t,t=.5/t,e[0]=(n[5]-n[7])*t,e[1]=(n[6]-n[2])*t,e[2]=(n[1]-n[3])*t;else{var r=0;n[4]>n[0]&&(r=1),n[8]>n[3*r+r]&&(r=2);var o=(r+1)%3,a=(r+2)%3;t=Math.sqrt(n[3*r+r]-n[3*o+o]-n[3*a+a]+1),e[r]=.5*t,t=.5/t,e[3]=(n[3*o+a]-n[3*a+o])*t,e[o]=(n[3*o+r]+n[3*r+o])*t,e[a]=(n[3*a+r]+n[3*r+a])*t}return e}Object.defineProperty(n,"__esModule",{value:!0}),n.identity=function(e){return e[0]=0,e[1]=0,e[2]=0,e[3]=1,e},n.setAxisAngle=s,n.getAxisAngle=function(e,n){var t=2*Math.acos(n[3]),i=Math.sin(t/2);return i>o.EPSILON?(e[0]=n[0]/i,e[1]=n[1]/i,e[2]=n[2]/i):(e[0]=1,e[1]=0,e[2]=0),t},n.multiply=c,n.rotateX=function(e,n,t){t*=.5;var i=n[0],r=n[1],o=n[2],a=n[3],l=Math.sin(t),s=Math.cos(t);return e[0]=i*s+a*l,e[1]=r*s+o*l,e[2]=o*s-r*l,e[3]=a*s-i*l,e},n.rotateY=function(e,n,t){t*=.5;var i=n[0],r=n[1],o=n[2],a=n[3],l=Math.sin(t),s=Math.cos(t);return e[0]=i*s-o*l,e[1]=r*s+a*l,e[2]=o*s+i*l,e[3]=a*s-r*l,e},n.rotateZ=function(e,n,t){t*=.5;var i=n[0],r=n[1],o=n[2],a=n[3],l=Math.sin(t),s=Math.cos(t);return e[0]=i*s+r*l,e[1]=r*s-i*l,e[2]=o*s+a*l,e[3]=a*s-o*l,e},n.calculateW=function(e,n){var t=n[0],i=n[1],r=n[2];return e[0]=t,e[1]=i,e[2]=r,e[3]=Math.sqrt(Math.abs(1-t*t-i*i-r*r)),e},n.slerp=d,n.random=function(e){var n=o.RANDOM(),t=o.RANDOM(),i=o.RANDOM(),r=Math.sqrt(1-n),a=Math.sqrt(n);return e[0]=r*Math.sin(2*Math.PI*t),e[1]=r*Math.cos(2*Math.PI*t),e[2]=a*Math.sin(2*Math.PI*i),e[3]=a*Math.cos(2*Math.PI*i),e},n.invert=function(e,n){var t=n[0],i=n[1],r=n[2],o=n[3],a=t*t+i*i+r*r+o*o,l=a?1/a:0;return e[0]=-t*l,e[1]=-i*l,e[2]=-r*l,e[3]=o*l,e},n.conjugate=function(e,n){return e[0]=-n[0],e[1]=-n[1],e[2]=-n[2],e[3]=n[3],e},n.fromMat3=u,n.fromEuler=function(e,n,t,i){var r=.5*Math.PI/180;n*=r,t*=r,i*=r;var o=Math.sin(n),a=Math.cos(n),l=Math.sin(t),s=Math.cos(t),c=Math.sin(i),d=Math.cos(i);return e[0]=o*s*d-a*l*c,e[1]=a*l*d+o*s*c,e[2]=a*s*c-o*l*d,e[3]=a*s*d+o*l*c,e},n.str=function(e){return"quat("+e[0]+", "+e[1]+", "+e[2]+", "+e[3]+")"},n.copy=l.copy,n.set=l.set,n.add=l.add,n.mul=c,n.scale=l.scale,n.dot=l.dot,n.lerp=l.lerp,n.length=l.length,n.len=n.length,n.squaredLength=l.squaredLength,n.sqrLen=n.squaredLength,n.normalize=l.normalize,n.exactEquals=l.exactEquals,n.equals=l.equals,n.rotationTo=function(e,t,i){var r=a.dot(t,i);return r<-.999999?(a.cross(f,p,t),a.len(f)<1e-6&&a.cross(f,v,t),a.normalize(f,f),s(e,f,Math.PI),e):r>.999999?(e[0]=0,e[1]=0,e[2]=0,e[3]=1,e):(a.cross(f,t,i),e[0]=f[0],e[1]=f[1],e[2]=f[2],e[3]=1+r,n.normalize(e,e))};var f=r.create(),p=r.fromValues(1,0,0),v=r.fromValues(0,1,0);n.sqlerp=function(e,n,t,i,r,o){return d(h,n,r,o),d(m,t,i,o),d(e,h,m,2*o*(1-o)),e};var h=i.create(),m=i.create();n.setAxes=function(e,t,i,r){var o=g;return o[0]=i[0],o[3]=i[1],o[6]=i[2],o[1]=r[0],o[4]=r[1],o[7]=r[2],o[2]=-t[0],o[5]=-t[1],o[8]=-t[2],n.normalize(e,u(e,o))};var g=t.create()}.apply(null,i))||(e.exports=r)},xsp2:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("W0kZ")],void 0===(r=function(e,n,t){Object.defineProperty(n,"__esModule",{value:!0});var i=new t;n.generateHighlightId=function(){return i.gen("highlight")}}.apply(null,i))||(e.exports=r)},zbgD:function(e,n,t){var i,r;i=[t.dj.c(e.i),n,t("VVgn"),t("IROT")],void 0===(r=function(e,n,t,i){Object.defineProperty(n,"__esModule",{value:!0});var r=new i(function(e){var n=t;return e.split("/").forEach(function(e){n&&(n=n[e])}),n});n.resolveIncludes=function(e){return r.resolveIncludes(e)}}.apply(null,i))||(e.exports=r)}}]);